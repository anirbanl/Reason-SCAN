{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "from typing import Tuple\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.dirname(\"__file__\"), '..', '..', 'dataset'))\n",
    "def isnotebook():\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return True   # Jupyter notebook or qtconsole\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            return False  # Terminal running IPython\n",
    "        else:\n",
    "            return False  # Other type (?)\n",
    "    except NameError:\n",
    "        return False      # Probably standard Python interpreter\n",
    "if isnotebook():\n",
    "    device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "FORMAT = \"%(asctime)-15s %(message)s\"\n",
    "logging.basicConfig(format=FORMAT, level=logging.INFO,\n",
    "                    datefmt=\"%Y-%m-%d %H:%M\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from ReaSCAN_dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-17 15:44 Reading dataset from file: ../../../data-files/ReaSCAN-compositional/data-compositional-splits.txt...\n"
     ]
    }
   ],
   "source": [
    "path_to_data = \"../../../data-files/ReaSCAN-compositional/data-compositional-splits.txt\"\n",
    "logger.info(f\"Reading dataset from file: {path_to_data}...\")\n",
    "data_json = json.load(open(path_to_data, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-17 17:17 Formulating the dataset from the passed in json file...\n",
      "2021-05-17 17:17 Loading vocabularies...\n",
      "2021-05-17 17:17 Done loading vocabularies.\n",
      "2021-05-17 17:17 Converting dataset to tensors...\n",
      "2021-05-17 17:17 Loading few examples into the training set for few-shots learning...\n",
      "2021-05-17 17:17 The following idx examples are selected for few-shot learning:\n",
      "2021-05-17 17:17 [5010, 10723, 6059, 26887, 32423, 19034, 4813, 22516, 47822, 39602, 36936, 18548, 11016, 34759, 29562, 45122, 45528, 37179, 14605, 20723, 6153, 8403, 19641, 27385, 16961, 11031, 3893, 41565, 47631, 6607, 35161, 3186, 44075, 38587, 35049, 827, 26706, 24965, 1519, 33543, 34917, 22927, 176, 15244, 35676, 23533, 28085, 445, 39335, 44803, 27619, 12948, 31673, 838, 19363, 19006, 25030, 48495, 16274, 49237, 11232, 31648, 14557, 34082, 13098, 23645, 36752, 43737, 16789, 16065, 4473, 31989, 34094, 28212, 21897, 13052, 20681, 15528, 47544, 37475, 20677, 32127, 20403, 13209, 27369, 29267, 8333, 7897, 33133, 40933, 27197, 47929, 8057, 43072, 45564, 36156, 48629, 7383, 12574, 8230]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = ReaSCANDataset(\n",
    "    data_json=data_json, \n",
    "    save_directory=\"../../../data-files/ReaSCAN-compositional/\", \n",
    "    input_vocabulary_file=\"input_vocabulary.txt\",\n",
    "    target_vocabulary_file=\"target_vocabulary.txt\",\n",
    "    k=100, \n",
    "    split=\"train\", \n",
    "    generate_vocabulary=False\n",
    ")\n",
    "train_dataset.read_dataset(\n",
    "    max_examples=100,\n",
    "    simple_situation_representation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-17 17:21 Formulating the dataset from the passed in json file...\n",
      "2021-05-17 17:21 Loading vocabularies...\n",
      "2021-05-17 17:21 Done loading vocabularies.\n",
      "2021-05-17 17:21 Converting dataset to tensors...\n"
     ]
    }
   ],
   "source": [
    "test_dataset = ReaSCANDataset(\n",
    "    data_json=data_json, \n",
    "    save_directory=\"../../../data-files/ReaSCAN-compositional/\", \n",
    "    input_vocabulary_file=\"input_vocabulary.txt\",\n",
    "    target_vocabulary_file=\"target_vocabulary.txt\",\n",
    "    k=0, \n",
    "    split=\"dev\", \n",
    "    generate_vocabulary=False\n",
    ")\n",
    "test_dataset.read_dataset(\n",
    "    max_examples=100,\n",
    "    simple_situation_representation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import torch\n",
    "import os\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.dirname(\"__file__\"), '..'))\n",
    "\n",
    "from seq2seq.model import Model\n",
    "from seq2seq.ReaSCAN_dataset import *\n",
    "from seq2seq.helpers import log_parameters\n",
    "from seq2seq.evaluate import evaluate\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "use_cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "\n",
    "def train(\n",
    "    data_path: str, \n",
    "    data_directory: str, \n",
    "    generate_vocabularies: bool, \n",
    "    input_vocab_path: str,   \n",
    "    target_vocab_path: str, \n",
    "    embedding_dimension: int, \n",
    "    num_encoder_layers: int, \n",
    "    encoder_dropout_p: float,\n",
    "    encoder_bidirectional: bool, \n",
    "    training_batch_size: int, \n",
    "    test_batch_size: int, \n",
    "    max_decoding_steps: int,\n",
    "    num_decoder_layers: int, \n",
    "    decoder_dropout_p: float, \n",
    "    cnn_kernel_size: int, \n",
    "    cnn_dropout_p: float,\n",
    "    cnn_hidden_num_channels: int, \n",
    "    simple_situation_representation: bool, \n",
    "    decoder_hidden_size: int,\n",
    "    encoder_hidden_size: int, \n",
    "    learning_rate: float, \n",
    "    adam_beta_1: float, \n",
    "    adam_beta_2: float, \n",
    "    lr_decay: float,\n",
    "    lr_decay_steps: int, \n",
    "    resume_from_file: str, \n",
    "    max_training_iterations: int, \n",
    "    output_directory: str,\n",
    "    print_every: int, \n",
    "    evaluate_every: int, \n",
    "    conditional_attention: bool, \n",
    "    auxiliary_task: bool,\n",
    "    weight_target_loss: float, \n",
    "    attention_type: str, \n",
    "    k: int, \n",
    "    max_training_examples=None, \n",
    "    seed=42, **kwargs\n",
    "):\n",
    "    if isnotebook():\n",
    "        device = torch.device(\"cpu\")\n",
    "    else:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    cfg = locals().copy()\n",
    "\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    logger.info(\"Loading all data into memory...\")\n",
    "    logger.info(f\"Reading dataset from file: {data_path}...\")\n",
    "    data_json = json.load(open(data_path, \"r\"))\n",
    "    \n",
    "    logger.info(\"Loading Training set...\")\n",
    "    training_set = ReaSCANDataset(\n",
    "        data_json, data_directory, split=\"train\",\n",
    "        input_vocabulary_file=input_vocab_path,\n",
    "        target_vocabulary_file=target_vocab_path,\n",
    "        generate_vocabulary=generate_vocabularies, k=k\n",
    "    )\n",
    "    training_set.read_dataset(\n",
    "        max_examples=max_training_examples,\n",
    "        simple_situation_representation=simple_situation_representation\n",
    "    )\n",
    "    logger.info(\"Done Loading Training set.\")\n",
    "    logger.info(\"  Loaded {} training examples.\".format(training_set.num_examples))\n",
    "    logger.info(\"  Input vocabulary size training set: {}\".format(training_set.input_vocabulary_size))\n",
    "    logger.info(\"  Most common input words: {}\".format(training_set.input_vocabulary.most_common(5)))\n",
    "    logger.info(\"  Output vocabulary size training set: {}\".format(training_set.target_vocabulary_size))\n",
    "    logger.info(\"  Most common target words: {}\".format(training_set.target_vocabulary.most_common(5)))\n",
    "\n",
    "    if generate_vocabularies:\n",
    "        training_set.save_vocabularies(input_vocab_path, target_vocab_path)\n",
    "        logger.info(\"Saved vocabularies to {} for input and {} for target.\".format(input_vocab_path, target_vocab_path))\n",
    "\n",
    "    logger.info(\"Loading Dev. set...\")\n",
    "    test_set = ReaSCANDataset(\n",
    "        data_json, data_directory, split=\"dev\",\n",
    "        input_vocabulary_file=input_vocab_path,\n",
    "        target_vocabulary_file=target_vocab_path,\n",
    "        generate_vocabulary=generate_vocabularies, k=0\n",
    "    )\n",
    "    test_set.read_dataset(\n",
    "        max_examples=None,\n",
    "        simple_situation_representation=simple_situation_representation\n",
    "    )\n",
    "\n",
    "    # Shuffle the test set to make sure that if we only evaluate max_testing_examples we get a random part of the set.\n",
    "    test_set.shuffle_data()\n",
    "    logger.info(\"Done Loading Dev. set.\")\n",
    "\n",
    "    return\n",
    "    \n",
    "    \n",
    "#     model = Model(input_vocabulary_size=training_set.input_vocabulary_size,\n",
    "#                   target_vocabulary_size=training_set.target_vocabulary_size,\n",
    "#                   num_cnn_channels=training_set.image_channels,\n",
    "#                   input_padding_idx=training_set.input_vocabulary.pad_idx,\n",
    "#                   target_pad_idx=training_set.target_vocabulary.pad_idx,\n",
    "#                   target_eos_idx=training_set.target_vocabulary.eos_idx,\n",
    "#                   **cfg)\n",
    "#     model = model.cuda() if use_cuda else model\n",
    "#     log_parameters(model)\n",
    "#     trainable_parameters = [parameter for parameter in model.parameters() if parameter.requires_grad]\n",
    "#     optimizer = torch.optim.Adam(trainable_parameters, lr=learning_rate, betas=(adam_beta_1, adam_beta_2))\n",
    "#     scheduler = LambdaLR(optimizer,\n",
    "#                          lr_lambda=lambda t: lr_decay ** (t / lr_decay_steps))\n",
    "\n",
    "#     # Load model and vocabularies if resuming.\n",
    "#     start_iteration = 1\n",
    "#     best_iteration = 1\n",
    "#     best_accuracy = 0\n",
    "#     best_exact_match = 0\n",
    "#     best_loss = float('inf')\n",
    "#     if resume_from_file:\n",
    "#         assert os.path.isfile(resume_from_file), \"No checkpoint found at {}\".format(resume_from_file)\n",
    "#         logger.info(\"Loading checkpoint from file at '{}'\".format(resume_from_file))\n",
    "#         optimizer_state_dict = model.load_model(resume_from_file)\n",
    "#         optimizer.load_state_dict(optimizer_state_dict)\n",
    "#         start_iteration = model.trained_iterations\n",
    "#         logger.info(\"Loaded checkpoint '{}' (iter {})\".format(resume_from_file, start_iteration))\n",
    "\n",
    "#     logger.info(\"Training starts..\")\n",
    "#     training_iteration = start_iteration\n",
    "#     while training_iteration < max_training_iterations:\n",
    "\n",
    "#         # Shuffle the dataset and loop over it.\n",
    "#         training_set.shuffle_data()\n",
    "#         for (input_batch, input_lengths, _, situation_batch, _, target_batch,\n",
    "#              target_lengths, agent_positions, target_positions) in training_set.get_data_iterator(\n",
    "#                 batch_size=training_batch_size):\n",
    "#             is_best = False\n",
    "#             model.train()\n",
    "\n",
    "#             # Forward pass.\n",
    "#             target_scores, target_position_scores = model(commands_input=input_batch, commands_lengths=input_lengths,\n",
    "#                                                           situations_input=situation_batch, target_batch=target_batch,\n",
    "#                                                           target_lengths=target_lengths)\n",
    "#             loss = model.get_loss(target_scores, target_batch)\n",
    "#             if auxiliary_task:\n",
    "#                 target_loss = model.get_auxiliary_loss(target_position_scores, target_positions)\n",
    "#             else:\n",
    "#                 target_loss = 0\n",
    "#             loss += weight_target_loss * target_loss\n",
    "\n",
    "#             # Backward pass and update model parameters.\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             scheduler.step()\n",
    "#             optimizer.zero_grad()\n",
    "#             model.update_state(is_best=is_best)\n",
    "\n",
    "#             # Print current metrics.\n",
    "#             if training_iteration % print_every == 0:\n",
    "#                 accuracy, exact_match = model.get_metrics(target_scores, target_batch)\n",
    "#                 if auxiliary_task:\n",
    "#                     auxiliary_accuracy_target = model.get_auxiliary_accuracy(target_position_scores, target_positions)\n",
    "#                 else:\n",
    "#                     auxiliary_accuracy_target = 0.\n",
    "#                 learning_rate = scheduler.get_lr()[0]\n",
    "#                 logger.info(\"Iteration %08d, loss %8.4f, accuracy %5.2f, exact match %5.2f, learning_rate %.5f,\"\n",
    "#                             \" aux. accuracy target pos %5.2f\" % (training_iteration, loss, accuracy, exact_match,\n",
    "#                                                                  learning_rate, auxiliary_accuracy_target))\n",
    "\n",
    "#             # Evaluate on test set.\n",
    "#             if training_iteration % evaluate_every == 0:\n",
    "#                 with torch.no_grad():\n",
    "#                     model.eval()\n",
    "#                     logger.info(\"Evaluating..\")\n",
    "#                     accuracy, exact_match, target_accuracy = evaluate(\n",
    "#                         test_set.get_data_iterator(batch_size=1), model=model,\n",
    "#                         max_decoding_steps=max_decoding_steps, pad_idx=test_set.target_vocabulary.pad_idx,\n",
    "#                         sos_idx=test_set.target_vocabulary.sos_idx,\n",
    "#                         eos_idx=test_set.target_vocabulary.eos_idx,\n",
    "#                         max_examples_to_evaluate=kwargs[\"max_testing_examples\"])\n",
    "#                     logger.info(\"  Evaluation Accuracy: %5.2f Exact Match: %5.2f \"\n",
    "#                                 \" Target Accuracy: %5.2f\" % (accuracy, exact_match, target_accuracy))\n",
    "#                     if exact_match > best_exact_match:\n",
    "#                         is_best = True\n",
    "#                         best_accuracy = accuracy\n",
    "#                         best_exact_match = exact_match\n",
    "#                         model.update_state(accuracy=accuracy, exact_match=exact_match, is_best=is_best)\n",
    "#                     file_name = \"checkpoint.pth.tar\".format(str(training_iteration))\n",
    "#                     if is_best:\n",
    "#                         model.save_checkpoint(file_name=file_name, is_best=is_best,\n",
    "#                                               optimizer_state_dict=optimizer.state_dict())\n",
    "\n",
    "#             training_iteration += 1\n",
    "#             if training_iteration > max_training_iterations:\n",
    "#                 break\n",
    "#     logger.info(\"Finished training.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from seq2seq.ReaSCAN_dataset import *\n",
    "from seq2seq.model import Model\n",
    "from seq2seq.train import train\n",
    "from seq2seq.predict import predict_and_save\n",
    "\n",
    "FORMAT = \"%(asctime)-15s %(message)s\"\n",
    "logging.basicConfig(format=FORMAT, level=logging.DEBUG,\n",
    "                    datefmt=\"%Y-%m-%d %H:%M\")\n",
    "logger = logging.getLogger(__name__)\n",
    "if isnotebook():\n",
    "    use_cuda = False\n",
    "else:\n",
    "    use_cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "\n",
    "if use_cuda:\n",
    "    logger.info(\"Using CUDA.\")\n",
    "    logger.info(\"Cuda version: {}\".format(torch.version.cuda))\n",
    "\n",
    "def arg_parse():\n",
    "    parser = argparse.ArgumentParser(description=\"Sequence to sequence models for ReaSCAN\")\n",
    "\n",
    "    # General arguments\n",
    "    parser.add_argument(\"--mode\", type=str, default=\"run_tests\", help=\"train, test or predict\", required=True)\n",
    "    parser.add_argument(\"--output_directory\", type=str, default=\"output\", help=\"In this directory the models will be \"\n",
    "                                                                               \"saved. Will be created if doesn't exist.\")\n",
    "    parser.add_argument(\"--resume_from_file\", type=str, default=\"\", help=\"Full path to previously saved model to load.\")\n",
    "\n",
    "    # Data arguments\n",
    "    parser.add_argument(\"--split\", type=str, default=\"test\", help=\"Which split to get from Grounded Scan.\")\n",
    "    parser.add_argument(\"--data_directory\", type=str, default=\"data/uniform_dataset\", help=\"Path to folder with data.\")\n",
    "    parser.add_argument(\"--input_vocab_path\", type=str, default=\"training_input_vocab.txt\",\n",
    "                        help=\"Path to file with input vocabulary as saved by Vocabulary class in gSCAN_dataset.py\")\n",
    "    parser.add_argument(\"--target_vocab_path\", type=str, default=\"training_target_vocab.txt\",\n",
    "                        help=\"Path to file with target vocabulary as saved by Vocabulary class in gSCAN_dataset.py\")\n",
    "    parser.add_argument(\"--generate_vocabularies\", dest=\"generate_vocabularies\", default=False, action=\"store_true\",\n",
    "                        help=\"Whether to generate vocabularies based on the data.\")\n",
    "    parser.add_argument(\"--load_vocabularies\", dest=\"generate_vocabularies\", default=True, action=\"store_false\",\n",
    "                        help=\"Whether to use previously saved vocabularies.\")\n",
    "\n",
    "    # Training and learning arguments\n",
    "    parser.add_argument(\"--training_batch_size\", type=int, default=50)\n",
    "    parser.add_argument(\"--k\", type=int, default=0, help=\"How many examples from the few-shot split to move to train.\")\n",
    "    parser.add_argument(\"--test_batch_size\", type=int, default=1, help=\"Currently only 1 supported due to decoder.\")\n",
    "    parser.add_argument(\"--max_training_examples\", type=int, default=None, help=\"If None all are used.\")\n",
    "    parser.add_argument(\"--learning_rate\", type=float, default=0.001)\n",
    "    parser.add_argument('--lr_decay', type=float, default=0.9)\n",
    "    parser.add_argument('--lr_decay_steps', type=float, default=20000)\n",
    "    parser.add_argument(\"--adam_beta_1\", type=float, default=0.9)\n",
    "    parser.add_argument(\"--adam_beta_2\", type=float, default=0.999)\n",
    "    parser.add_argument(\"--print_every\", type=int, default=100)\n",
    "    parser.add_argument(\"--evaluate_every\", type=int, default=1000, help=\"How often to evaluate the model by decoding the \"\n",
    "                                                                         \"test set (without teacher forcing).\")\n",
    "    parser.add_argument(\"--max_training_iterations\", type=int, default=100000)\n",
    "    parser.add_argument(\"--weight_target_loss\", type=float, default=0.3, help=\"Only used if --auxiliary_task set.\")\n",
    "\n",
    "    # Testing and predicting arguments\n",
    "    parser.add_argument(\"--max_testing_examples\", type=int, default=None)\n",
    "    parser.add_argument(\"--splits\", type=str, default=\"test\", help=\"comma-separated list of splits to predict for.\")\n",
    "    parser.add_argument(\"--max_decoding_steps\", type=int, default=30, help=\"After 30 decoding steps, the decoding process \"\n",
    "                                                                           \"is stopped regardless of whether an EOS token \"\n",
    "                                                                           \"was generated.\")\n",
    "    parser.add_argument(\"--output_file_name\", type=str, default=\"predict.json\")\n",
    "\n",
    "    # Situation Encoder arguments\n",
    "    parser.add_argument(\"--simple_situation_representation\", dest=\"simple_situation_representation\", default=True,\n",
    "                        action=\"store_true\", help=\"Represent the situation with 1 vector per grid cell. \"\n",
    "                                                  \"For more information, read grounded SCAN documentation.\")\n",
    "    parser.add_argument(\"--image_situation_representation\", dest=\"simple_situation_representation\", default=False,\n",
    "                        action=\"store_false\", help=\"Represent the situation with the full gridworld RGB image. \"\n",
    "                                                   \"For more information, read grounded SCAN documentation.\")\n",
    "    parser.add_argument(\"--cnn_hidden_num_channels\", type=int, default=50)\n",
    "    parser.add_argument(\"--cnn_kernel_size\", type=int, default=7, help=\"Size of the largest filter in the world state \"\n",
    "                                                                       \"model.\")\n",
    "    parser.add_argument(\"--cnn_dropout_p\", type=float, default=0.1, help=\"Dropout applied to the output features of the \"\n",
    "                                                                         \"world state model.\")\n",
    "    parser.add_argument(\"--auxiliary_task\", dest=\"auxiliary_task\", default=False, action=\"store_true\",\n",
    "                        help=\"If set to true, the model predicts the target location from the joint attention over the \"\n",
    "                             \"input instruction and world state.\")\n",
    "    parser.add_argument(\"--no_auxiliary_task\", dest=\"auxiliary_task\", default=True, action=\"store_false\")\n",
    "\n",
    "    # Command Encoder arguments\n",
    "    parser.add_argument(\"--embedding_dimension\", type=int, default=25)\n",
    "    parser.add_argument(\"--num_encoder_layers\", type=int, default=1)\n",
    "    parser.add_argument(\"--encoder_hidden_size\", type=int, default=100)\n",
    "    parser.add_argument(\"--encoder_dropout_p\", type=float, default=0.3, help=\"Dropout on instruction embeddings and LSTM.\")\n",
    "    parser.add_argument(\"--encoder_bidirectional\", dest=\"encoder_bidirectional\", default=True, action=\"store_true\")\n",
    "    parser.add_argument(\"--encoder_unidirectional\", dest=\"encoder_bidirectional\", default=False, action=\"store_false\")\n",
    "\n",
    "    # Decoder arguments\n",
    "    parser.add_argument(\"--num_decoder_layers\", type=int, default=1)\n",
    "    parser.add_argument(\"--attention_type\", type=str, default='bahdanau', choices=['bahdanau', 'luong'],\n",
    "                        help=\"Luong not properly implemented.\")\n",
    "    parser.add_argument(\"--decoder_dropout_p\", type=float, default=0.3, help=\"Dropout on decoder embedding and LSTM.\")\n",
    "    parser.add_argument(\"--decoder_hidden_size\", type=int, default=100)\n",
    "    parser.add_argument(\"--conditional_attention\", dest=\"conditional_attention\", default=True, action=\"store_true\",\n",
    "                        help=\"If set to true joint attention over the world state conditioned on the input instruction is\"\n",
    "                             \" used.\")\n",
    "    parser.add_argument(\"--no_conditional_attention\", dest=\"conditional_attention\", default=False, action=\"store_false\")\n",
    "\n",
    "    # Other arguments\n",
    "    parser.add_argument(\"--seed\", type=int, default=42)\n",
    "    \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "        args = parser.parse_args([])\n",
    "    except:\n",
    "        args = parser.parse_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --mode MODE\n",
      "                             [--output_directory OUTPUT_DIRECTORY]\n",
      "                             [--resume_from_file RESUME_FROM_FILE]\n",
      "                             [--split SPLIT] [--data_directory DATA_DIRECTORY]\n",
      "                             [--input_vocab_path INPUT_VOCAB_PATH]\n",
      "                             [--target_vocab_path TARGET_VOCAB_PATH]\n",
      "                             [--generate_vocabularies] [--load_vocabularies]\n",
      "                             [--training_batch_size TRAINING_BATCH_SIZE]\n",
      "                             [--k K] [--test_batch_size TEST_BATCH_SIZE]\n",
      "                             [--max_training_examples MAX_TRAINING_EXAMPLES]\n",
      "                             [--learning_rate LEARNING_RATE]\n",
      "                             [--lr_decay LR_DECAY]\n",
      "                             [--lr_decay_steps LR_DECAY_STEPS]\n",
      "                             [--adam_beta_1 ADAM_BETA_1]\n",
      "                             [--adam_beta_2 ADAM_BETA_2]\n",
      "                             [--print_every PRINT_EVERY]\n",
      "                             [--evaluate_every EVALUATE_EVERY]\n",
      "                             [--max_training_iterations MAX_TRAINING_ITERATIONS]\n",
      "                             [--weight_target_loss WEIGHT_TARGET_LOSS]\n",
      "                             [--max_testing_examples MAX_TESTING_EXAMPLES]\n",
      "                             [--splits SPLITS]\n",
      "                             [--max_decoding_steps MAX_DECODING_STEPS]\n",
      "                             [--output_file_name OUTPUT_FILE_NAME]\n",
      "                             [--simple_situation_representation]\n",
      "                             [--image_situation_representation]\n",
      "                             [--cnn_hidden_num_channels CNN_HIDDEN_NUM_CHANNELS]\n",
      "                             [--cnn_kernel_size CNN_KERNEL_SIZE]\n",
      "                             [--cnn_dropout_p CNN_DROPOUT_P]\n",
      "                             [--auxiliary_task] [--no_auxiliary_task]\n",
      "                             [--embedding_dimension EMBEDDING_DIMENSION]\n",
      "                             [--num_encoder_layers NUM_ENCODER_LAYERS]\n",
      "                             [--encoder_hidden_size ENCODER_HIDDEN_SIZE]\n",
      "                             [--encoder_dropout_p ENCODER_DROPOUT_P]\n",
      "                             [--encoder_bidirectional]\n",
      "                             [--encoder_unidirectional]\n",
      "                             [--num_decoder_layers NUM_DECODER_LAYERS]\n",
      "                             [--attention_type {bahdanau,luong}]\n",
      "                             [--decoder_dropout_p DECODER_DROPOUT_P]\n",
      "                             [--decoder_hidden_size DECODER_HIDDEN_SIZE]\n",
      "                             [--conditional_attention]\n",
      "                             [--no_conditional_attention] [--seed SEED]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --mode\n",
      "usage: ipykernel_launcher.py [-h] --mode MODE\n",
      "                             [--output_directory OUTPUT_DIRECTORY]\n",
      "                             [--resume_from_file RESUME_FROM_FILE]\n",
      "                             [--split SPLIT] [--data_directory DATA_DIRECTORY]\n",
      "                             [--input_vocab_path INPUT_VOCAB_PATH]\n",
      "                             [--target_vocab_path TARGET_VOCAB_PATH]\n",
      "                             [--generate_vocabularies] [--load_vocabularies]\n",
      "                             [--training_batch_size TRAINING_BATCH_SIZE]\n",
      "                             [--k K] [--test_batch_size TEST_BATCH_SIZE]\n",
      "                             [--max_training_examples MAX_TRAINING_EXAMPLES]\n",
      "                             [--learning_rate LEARNING_RATE]\n",
      "                             [--lr_decay LR_DECAY]\n",
      "                             [--lr_decay_steps LR_DECAY_STEPS]\n",
      "                             [--adam_beta_1 ADAM_BETA_1]\n",
      "                             [--adam_beta_2 ADAM_BETA_2]\n",
      "                             [--print_every PRINT_EVERY]\n",
      "                             [--evaluate_every EVALUATE_EVERY]\n",
      "                             [--max_training_iterations MAX_TRAINING_ITERATIONS]\n",
      "                             [--weight_target_loss WEIGHT_TARGET_LOSS]\n",
      "                             [--max_testing_examples MAX_TESTING_EXAMPLES]\n",
      "                             [--splits SPLITS]\n",
      "                             [--max_decoding_steps MAX_DECODING_STEPS]\n",
      "                             [--output_file_name OUTPUT_FILE_NAME]\n",
      "                             [--simple_situation_representation]\n",
      "                             [--image_situation_representation]\n",
      "                             [--cnn_hidden_num_channels CNN_HIDDEN_NUM_CHANNELS]\n",
      "                             [--cnn_kernel_size CNN_KERNEL_SIZE]\n",
      "                             [--cnn_dropout_p CNN_DROPOUT_P]\n",
      "                             [--auxiliary_task] [--no_auxiliary_task]\n",
      "                             [--embedding_dimension EMBEDDING_DIMENSION]\n",
      "                             [--num_encoder_layers NUM_ENCODER_LAYERS]\n",
      "                             [--encoder_hidden_size ENCODER_HIDDEN_SIZE]\n",
      "                             [--encoder_dropout_p ENCODER_DROPOUT_P]\n",
      "                             [--encoder_bidirectional]\n",
      "                             [--encoder_unidirectional]\n",
      "                             [--num_decoder_layers NUM_DECODER_LAYERS]\n",
      "                             [--attention_type {bahdanau,luong}]\n",
      "                             [--decoder_dropout_p DECODER_DROPOUT_P]\n",
      "                             [--decoder_hidden_size DECODER_HIDDEN_SIZE]\n",
      "                             [--conditional_attention]\n",
      "                             [--no_conditional_attention] [--seed SEED]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --mode\n",
      "2021-05-17 18:17 Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "2021-05-17 18:17 \n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-80-1381d86c6516>\", line 110, in arg_parse\n",
      "    args = parser.parse_args([])\n",
      "  File \"/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/argparse.py\", line 1755, in parse_args\n",
      "    args, argv = self.parse_known_args(args, namespace)\n",
      "  File \"/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/argparse.py\", line 1787, in parse_known_args\n",
      "    namespace, args = self._parse_known_args(args, namespace)\n",
      "  File \"/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/argparse.py\", line 2022, in _parse_known_args\n",
      "    ', '.join(required_actions))\n",
      "  File \"/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/argparse.py\", line 2508, in error\n",
      "    self.exit(2, _('%(prog)s: error: %(message)s\\n') % args)\n",
      "  File \"/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/argparse.py\", line 2495, in exit\n",
      "    _sys.exit(status)\n",
      "SystemExit: 2\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/afs/cs.stanford.edu/u/wuzhengx/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3417, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-81-70140d08f56e>\", line 4, in <module>\n",
      "    args = arg_parse()\n",
      "  File \"<ipython-input-80-1381d86c6516>\", line 112, in arg_parse\n",
      "    args = parser.parse_args()\n",
      "  File \"/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/argparse.py\", line 1755, in parse_args\n",
      "    args, argv = self.parse_known_args(args, namespace)\n",
      "  File \"/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/argparse.py\", line 1787, in parse_known_args\n",
      "    namespace, args = self._parse_known_args(args, namespace)\n",
      "  File \"/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/argparse.py\", line 2022, in _parse_known_args\n",
      "    ', '.join(required_actions))\n",
      "  File \"/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/argparse.py\", line 2508, in error\n",
      "    self.exit(2, _('%(prog)s: error: %(message)s\\n') % args)\n",
      "  File \"/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/argparse.py\", line 2495, in exit\n",
      "    _sys.exit(status)\n",
      "SystemExit: 2\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/afs/cs.stanford.edu/u/wuzhengx/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/afs/cs.stanford.edu/u/wuzhengx/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/afs/cs.stanford.edu/u/wuzhengx/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "AttributeError: 'tuple' object has no attribute 'tb_frame'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-1381d86c6516>\u001b[0m in \u001b[0;36marg_parse\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36mparse_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1754\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1755\u001b[0;31m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1756\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36mparse_known_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1787\u001b[0;31m             \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_known_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1788\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_UNRECOGNIZED_ARGS_ATTR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36m_parse_known_args\u001b[0;34m(self, arg_strings, namespace)\u001b[0m\n\u001b[1;32m   2021\u001b[0m             self.error(_('the following arguments are required: %s') %\n\u001b[0;32m-> 2022\u001b[0;31m                        ', '.join(required_actions))\n\u001b[0m\u001b[1;32m   2023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m   2507\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'prog'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'message'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2508\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%(prog)s: error: %(message)s\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36mexit\u001b[0;34m(self, status, message)\u001b[0m\n\u001b[1;32m   2494\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2495\u001b[0;31m         \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemExit\u001b[0m: 2",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-81-70140d08f56e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Loading arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-80-1381d86c6516>\u001b[0m in \u001b[0;36marg_parse\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36mparse_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1754\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1755\u001b[0;31m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1756\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36mparse_known_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1787\u001b[0;31m             \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_known_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1788\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_UNRECOGNIZED_ARGS_ATTR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36m_parse_known_args\u001b[0;34m(self, arg_strings, namespace)\u001b[0m\n\u001b[1;32m   2021\u001b[0m             self.error(_('the following arguments are required: %s') %\n\u001b[0;32m-> 2022\u001b[0;31m                        ', '.join(required_actions))\n\u001b[0m\u001b[1;32m   2023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m   2507\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'prog'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'message'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2508\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%(prog)s: error: %(message)s\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36mexit\u001b[0;34m(self, status, message)\u001b[0m\n\u001b[1;32m   2494\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2495\u001b[0;31m         \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemExit\u001b[0m: 2",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2036\u001b[0m                            'the full traceback.\\n']\n\u001b[1;32m   2037\u001b[0m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0;32m-> 2038\u001b[0;31m                                                                      value))\n\u001b[0m\u001b[1;32m   2039\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m         \"\"\"\n\u001b[0;32m--> 823\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     chained_exceptions_tb_offset, context)\n\u001b[1;32m    701\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0mchained_exception_message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m                 + out_list)\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1436\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1336\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m             )\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1193\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Loading arguments\n",
    "    args = arg_parse()\n",
    "    try:\n",
    "        get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "        # Experiment management:\n",
    "        \n",
    "        is_jupyter = True\n",
    "    except:\n",
    "        is_jupyter = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(flags):\n",
    "    for argument, value in flags.items():\n",
    "        logger.info(\"{}: {}\".format(argument, value))\n",
    "\n",
    "    if not os.path.exists(flags[\"output_directory\"]):\n",
    "        os.mkdir(os.path.join(os.getcwd(), flags[\"output_directory\"]))\n",
    "\n",
    "    if not flags[\"simple_situation_representation\"]:\n",
    "        raise NotImplementedError(\"Full RGB input image not implemented. Implement or set \"\n",
    "                                  \"--simple_situation_representation\")\n",
    "    # Some checks on the flags\n",
    "    if flags[\"generate_vocabularies\"]:\n",
    "        assert flags[\"input_vocab_path\"] and flags[\"target_vocab_path\"], \"Please specify paths to vocabularies to save.\"\n",
    "\n",
    "    if flags[\"test_batch_size\"] > 1:\n",
    "        raise NotImplementedError(\"Test batch size larger than 1 not implemented.\")\n",
    "\n",
    "    data_path = os.path.join(flags[\"data_directory\"], \"dataset.txt\")\n",
    "    if flags[\"mode\"] == \"train\":\n",
    "        train(data_path=data_path, **flags)\n",
    "    elif flags[\"mode\"] == \"test\":\n",
    "        assert os.path.exists(os.path.join(flags[\"data_directory\"], flags[\"input_vocab_path\"])) and os.path.exists(\n",
    "            os.path.join(flags[\"data_directory\"], flags[\"target_vocab_path\"])), \\\n",
    "            \"No vocabs found at {} and {}\".format(flags[\"input_vocab_path\"], flags[\"target_vocab_path\"])\n",
    "        splits = flags[\"splits\"].split(\",\")\n",
    "        for split in splits:\n",
    "            logger.info(\"Loading {} dataset split...\".format(split))\n",
    "            test_set = GroundedScanDataset(data_path, flags[\"data_directory\"], split=split,\n",
    "                                           input_vocabulary_file=flags[\"input_vocab_path\"],\n",
    "                                           target_vocabulary_file=flags[\"target_vocab_path\"], generate_vocabulary=False,\n",
    "                                           k=flags[\"k\"])\n",
    "            test_set.read_dataset(max_examples=None,\n",
    "                                  simple_situation_representation=flags[\"simple_situation_representation\"])\n",
    "            logger.info(\"Done Loading {} dataset split.\".format(flags[\"split\"]))\n",
    "            logger.info(\"  Loaded {} examples.\".format(test_set.num_examples))\n",
    "            logger.info(\"  Input vocabulary size: {}\".format(test_set.input_vocabulary_size))\n",
    "            logger.info(\"  Most common input words: {}\".format(test_set.input_vocabulary.most_common(5)))\n",
    "            logger.info(\"  Output vocabulary size: {}\".format(test_set.target_vocabulary_size))\n",
    "            logger.info(\"  Most common target words: {}\".format(test_set.target_vocabulary.most_common(5)))\n",
    "\n",
    "            model = Model(input_vocabulary_size=test_set.input_vocabulary_size,\n",
    "                          target_vocabulary_size=test_set.target_vocabulary_size,\n",
    "                          num_cnn_channels=test_set.image_channels,\n",
    "                          input_padding_idx=test_set.input_vocabulary.pad_idx,\n",
    "                          target_pad_idx=test_set.target_vocabulary.pad_idx,\n",
    "                          target_eos_idx=test_set.target_vocabulary.eos_idx,\n",
    "                          **flags)\n",
    "            model = model.cuda() if use_cuda else model\n",
    "\n",
    "            # Load model and vocabularies if resuming.\n",
    "            assert os.path.isfile(flags[\"resume_from_file\"]), \"No checkpoint found at {}\".format(flags[\"resume_from_file\"])\n",
    "            logger.info(\"Loading checkpoint from file at '{}'\".format(flags[\"resume_from_file\"]))\n",
    "            model.load_model(flags[\"resume_from_file\"])\n",
    "            start_iteration = model.trained_iterations\n",
    "            logger.info(\"Loaded checkpoint '{}' (iter {})\".format(flags[\"resume_from_file\"], start_iteration))\n",
    "            output_file_name = \"_\".join([split, flags[\"output_file_name\"]])\n",
    "            output_file_path = os.path.join(flags[\"output_directory\"], output_file_name)\n",
    "            output_file = predict_and_save(dataset=test_set, model=model, output_file_path=output_file_path, **flags)\n",
    "            logger.info(\"Saved predictions to {}\".format(output_file))\n",
    "    elif flags[\"mode\"] == \"predict\":\n",
    "        raise NotImplementedError()\n",
    "    else:\n",
    "        raise ValueError(\"Wrong value for parameters --mode ({}).\".format(flags[\"mode\"]))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_flags = vars(parser.parse_args())\n",
    "    main(flags=input_flags)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

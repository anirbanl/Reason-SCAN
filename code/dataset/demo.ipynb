{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple, OrderedDict\n",
    "import itertools\n",
    "import os\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "from typing import List\n",
    "from typing import Dict\n",
    "import random\n",
    "from itertools import product\n",
    "import copy\n",
    "import re\n",
    "import random\n",
    "\n",
    "from utils import one_hot\n",
    "from utils import generate_possible_object_names\n",
    "from utils import numpy_array_to_image\n",
    "\n",
    "from vocabulary import *\n",
    "from object_vocabulary import *\n",
    "from world import *\n",
    "from grammer import *\n",
    "from simulator import *\n",
    "from relation_graph import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test out the vocabulary\n",
    "intransitive_verbs = [\"walk\"]\n",
    "transitive_verbs = [\"push\", \"pull\"]\n",
    "adverbs = [\"while zigzagging\", \"while spinning\", \"cautiously\", \"hesitantly\"]\n",
    "nouns = [\"circle\", \"cylinder\", \"square\", \"box\"]\n",
    "color_adjectives = [\"red\", \"blue\", \"green\", \"yellow\"]\n",
    "size_adjectives = [\"big\", \"small\"]\n",
    "relative_pronouns = [\"that is\"]\n",
    "relation_clauses = [\"in the same row as\", \n",
    "                    \"in the same column as\", \n",
    "                    \"in the same color as\", \n",
    "                    \"in the same shape as\", \n",
    "                    \"in the same size as\",\n",
    "                    \"inside of\"]\n",
    "vocabulary = Vocabulary.initialize(intransitive_verbs=intransitive_verbs,\n",
    "                                   transitive_verbs=transitive_verbs, adverbs=adverbs, nouns=nouns,\n",
    "                                   color_adjectives=color_adjectives,\n",
    "                                   size_adjectives=size_adjectives, \n",
    "                                   relative_pronouns=relative_pronouns, \n",
    "                                   relation_clauses=relation_clauses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test out the object vocab\n",
    "min_object_size = 1\n",
    "max_object_size = 4\n",
    "object_vocabulary = ObjectVocabulary(shapes=vocabulary.get_semantic_shapes(),\n",
    "                                     colors=vocabulary.get_semantic_colors(),\n",
    "                                     min_size=min_object_size, max_size=max_object_size)\n",
    "# object_vocabulary.generate_objects()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Situtation Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test out situation repr\n",
    "TEST_SITUATION_1 = Situation(grid_size=15, agent_position=Position(row=7, column=2), agent_direction=INT_TO_DIR[0],\n",
    "                             target_object=PositionedObject(object=Object(size=2, color='red', shape='circle'),\n",
    "                                                            position=Position(row=10, column=4),\n",
    "                                                            vector=np.array([1, 0, 1])),\n",
    "                             placed_objects=[PositionedObject(object=Object(size=2, color='red', shape='circle'),\n",
    "                                                              position=Position(row=10, column=4),\n",
    "                                                              vector=np.array([1, 0, 1])),\n",
    "                                             PositionedObject(object=Object(size=4, color='green', shape='circle'),\n",
    "                                                              position=Position(row=3, column=12),\n",
    "                                                              vector=np.array([0, 1, 0]))], carrying=None)\n",
    "# TEST_SITUATION_1.to_representation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PositionedObject(object=Object(size=4, color='green', shape='box'), position=Position(column=12, row=3), vector=array([0, 1, 0]), overflow=True, overlap=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test out our new object definition\n",
    "PositionedObject(object=Object(size=4, color='green', shape='box'),\n",
    "                 position=Position(row=3, column=12),\n",
    "                 vector=np.array([0, 1, 0]), overflow=True, overlap=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### World Module with Mini-Gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test out the world\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import os\n",
    "os.environ['QT_QPA_PLATFORM']='offscreen'\n",
    "\n",
    "world = World(grid_size=6, colors=vocabulary.get_semantic_colors(),\n",
    "              object_vocabulary=object_vocabulary,\n",
    "              shapes=vocabulary.get_semantic_shapes(),\n",
    "              save_directory=\"./tmp/\")\n",
    "\n",
    "# try to place an object on to the map\n",
    "world.clear_situation()\n",
    "# world.place_object(Object(size=4, color=\"green\", shape=\"box\"), position=Position(row=3, column=3))\n",
    "world.place_object(Object(size=2, color=\"green\", shape=\"box\"), position=Position(row=2, column=2))\n",
    "world.place_object(Object(size=2, color=\"green\", shape=\"box\"), position=Position(row=1, column=1))\n",
    "world.place_object(Object(size=3, color=\"red\", shape=\"cylinder\"), position=Position(row=3, column=2))\n",
    "world.place_agent_at(Position(row=5, column=2))\n",
    "_ = world.render_simple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb = \"push\"\n",
    "adverb = \"cautiously\"\n",
    "\n",
    "# Direct walk.\n",
    "action = \"walk\" # this is definit!\n",
    "primitive_command = vocabulary.translate_word(action)\n",
    "target_position = Position(row=3, column=2)\n",
    "# simulator._world.get_current_situation().to_dict()[\"target_object\"].position\n",
    "world.go_to_position(position=target_position, manner=adverb, primitive_command=primitive_command)\n",
    "\n",
    "# Object actions.\n",
    "if True:\n",
    "    semantic_action = vocabulary.translate_word(verb)\n",
    "    world.move_object_to_wall(action=semantic_action, manner=adverb)\n",
    "target_commands, target_demonstration = world.get_current_observations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = world.render_simple()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReaSCAN Grammer Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['push', 'pull', 'walk']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammer = Grammer(vocabulary)\n",
    "vocabulary.get_transitive_verbs() + vocabulary.get_intransitive_verbs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammer_pattern = '$OBJ_0 ^ $OBJ_1 & $OBJ_2'\n",
    "\n",
    "relations = grammer.sample_object_relation_grammer(\n",
    "    '$OBJ_0', \n",
    "    grammer.build_dependency_graph(grammer_pattern))\n",
    "\n",
    "command_structs = []\n",
    "for relation in relations:\n",
    "    obj_pattern_map = relation[0]\n",
    "    rel_map = relation[1]\n",
    "    grammer_bindings = grammer.grounding_grammer_with_vocabulary(grammer_pattern, obj_pattern_map, rel_map)\n",
    "    for obj_map in grammer_bindings:\n",
    "        # here, we also sample the verb and adverb bindings!\n",
    "        \n",
    "        command_struct = {\n",
    "            \"obj_pattern_map\" : obj_pattern_map,\n",
    "            \"rel_map\" : rel_map,\n",
    "            \"obj_map\" : obj_map,\n",
    "            \"grammer_pattern\" : grammer_pattern,\n",
    "            \"adverb\" : random.choice(vocabulary.get_adverbs()),\n",
    "            \"verb\" : random.choice(vocabulary.get_transitive_verbs() + vocabulary.get_intransitive_verbs()),\n",
    "        }\n",
    "        command_structs += [command_struct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['push', 'pull']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary.get_transitive_verbs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# command_struct_stats = get_command_struct_statistics(command_structs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReaSCAN Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = Simulator(\n",
    "    object_vocabulary, vocabulary, \n",
    "    grid_size=6, \n",
    "    n_object_max=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOsAAADrCAYAAACICmHVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAFAElEQVR4nO3dPWpbWRyH4ashhRcgNW5cpjGkkPtsQWUWYC0g4GUEQmptwKXrdGlDGteGwSZgGGzSBNKeaRLCeK4cXfl+nB9+HlAR3wv+I3hzjqRjNCulNED9/pp6AGA3YoUQYoUQYoUQYoUQYoUQL7rcfHBwUI6Pj4eapbObm5vm6Oho6jGqVttzVNs8tbm+vm7u7+9nrRdLKTs/5vN5qcnp6enUI1Svtueotnlqs1wuS9nSn20whBArhBArhBArhBArhBArhBArhBArhOh0gumpXr1787+fXZ6djzkCxBol1rZIH14TLRE+fWma1yeT/OrBt8GPhbrPfTC5T19+P0Y0aKxdAxQscUaM1htM0IcRoh0s1n1XSasr0QbcIltZYSg9RytWGFpP0Y76OSs8Oz1+zCNWGMIAn8UOtg3e95CDwxHEen3y+zEAKys8xYinmQZ9g6nrKmlVJcrIxw4Hfzd41wCFSoSBt7qPGWUb/CtEf3UD+xv1NaswYX8ORUAIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUKIWSll55sXi0VZrVYDjgPP28XFRXN3dzdrvbjtK9HbHvP5fOQvbX+cr7z/s9qeo9rmqc1yuSxlS3+2wRBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBDixdQDwBRevXsz9Qitrv75e+s1KyuEmJVSdr55sViU1Wo14Dgwjs8vv089QqurDx+bH1+/zdqudd4Gbzabp0/Uk/V6XdU8NartOaplnlq3wY/xmhV+ujw7n/T3/+k/EK9ZIYRYIYRYIYRYIYRYIYRYIYRYIYRYIYRDEfBEh4dv//Pv29v3g/wescKeHkba9vM+w7UNho4OD99uDbXt3r6IFUKIFTrYZ6Xsa3UVK4ygj2DFCiHECiHECiHECiHECiPo43CEWKGDfaLr6xSTWCGEWKGj29v3O6+WfZ4NdpAf9vQrRH91AyGGivMh22AIIVYIIVYIIVYIIVYIIVYIIVYI4XNW+Kn2L1i2skKIWSll55sXi0VZrVYDjgPj+Pzy+9QjtLr68LH58fXbrO1a523wZrN5+kQ9Wa/XVc1To9qeo1rmqX3L28Y2GEJ4g4ln6fLsfOoRWp2cn2y9ZmWFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFELNSyu43z2Z3TdPcDDcOPHtHpZRF24VOsQLTsQ2GEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEP8CEpba6/9ifCEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "obj_pattern_map = {'$OBJ_0': '$ABS_SHAPE', '$OBJ_1': '$SHAPE', '$OBJ_2': '$SHAPE'}\n",
    "rel_map = {('$OBJ_0', '$OBJ_1'): '$SAME_SHAPE', ('$OBJ_0', '$OBJ_2'): '$IS_INSIDE'}\n",
    "obj_map = {'$OBJ_0': 'object', '$OBJ_1': 'circle', '$OBJ_2': 'box'}\n",
    "grammer_pattern = '$OBJ_0 ^ $OBJ_1 & $OBJ_2'\n",
    "verb = \"push\"\n",
    "adverb = \"slowly\"\n",
    "sampled_world = simulator.sample_situations_from_grounded_grammer(\n",
    "    copy.deepcopy(grammer_pattern), \n",
    "    copy.deepcopy(obj_pattern_map), \n",
    "    copy.deepcopy(rel_map), \n",
    "    copy.deepcopy(obj_map),\n",
    "    is_plot=True,\n",
    "    include_relation_distractor=False, \n",
    "    include_attribute_distractor=False, \n",
    "    include_isomorphism_distractor=False, \n",
    "    include_random_distractor=False,\n",
    "    full_relation_probability=0.5,\n",
    "    debug=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_transitive = False\n",
    "if verb in simulator.vocabulary.get_transitive_verbs():\n",
    "    is_transitive = True\n",
    "\n",
    "# Direct walk.\n",
    "action = \"walk\" # this is definit!\n",
    "primitive_command = simulator.vocabulary.translate_word(action)\n",
    "target_position = sampled_world[\"situation\"].target_object.position\n",
    "\n",
    "simulator._world.go_to_position(position=target_position, manner=adverb, primitive_command=primitive_command)\n",
    "\n",
    "# Object actions.\n",
    "if is_transitive:\n",
    "    semantic_action = simulator.vocabulary.translate_word(verb)\n",
    "    simulator._world.move_object_to_wall(action=semantic_action, manner=adverb)\n",
    "target_commands, target_demonstration = simulator._world.get_current_observations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['turn right', 'walk', 'walk', 'walk', 'push', 'push']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End-to-end Task Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulator(object):\n",
    "    \"\"\"\n",
    "    This convert generated grammers into a world/situation.\n",
    "    \n",
    "    Sample Situation:\n",
    "    Situation(grid_size=15, agent_position=Position(row=7, column=2), agent_direction=INT_TO_DIR[0],\n",
    "              target_object=PositionedObject(object=Object(size=2, color='red', shape='circle'),\n",
    "                                             position=Position(row=10, column=4),\n",
    "                                             vector=np.array([1, 0, 1])),\n",
    "              placed_objects=[PositionedObject(object=Object(size=2, color='red', shape='circle'),\n",
    "                                               position=Position(row=10, column=4),\n",
    "                                               vector=np.array([1, 0, 1])),\n",
    "                              PositionedObject(object=Object(size=4, color='green', shape='circle'),\n",
    "                                               position=Position(row=3, column=12),\n",
    "                                               vector=np.array([0, 1, 0]))], carrying=None)\n",
    "                                               \n",
    "    Sample Placement in the World:\n",
    "    world.place_object(Object(size=2, color=\"green\", shape=\"box\"), position=Position(row=2, column=2))\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, object_vocabulary, vocabulary, grid_size=6, \n",
    "                 n_object_min=6,\n",
    "                 n_object_max=12,\n",
    "                 save_directory=\"./tmp/\"):\n",
    "        self.object_vocabulary = object_vocabulary\n",
    "        self.vocabulary = vocabulary\n",
    "        self.grid_size = grid_size\n",
    "        self.n_object_min = n_object_min\n",
    "        self.n_object_max = n_object_max\n",
    "\n",
    "        self._world = World(grid_size=grid_size, colors=vocabulary.get_semantic_colors(),\n",
    "                            object_vocabulary=object_vocabulary,\n",
    "                            shapes=vocabulary.get_semantic_shapes(),\n",
    "                            save_directory=save_directory)\n",
    "        self._world.clear_situation()\n",
    "    \n",
    "    def sample_object_shape(\n",
    "        self, obj_grammer, obj_pattern, obj_str, rel_map, \n",
    "        is_root, shape_map\n",
    "    ):\n",
    "        obj_pattern = obj_pattern.split(\" \")\n",
    "        obj_str = obj_str.split(\" \")\n",
    "        shape = None\n",
    "        if len(obj_str) == 3:\n",
    "            shape = obj_str[2]\n",
    "        elif len(obj_str) == 2:\n",
    "            shape = obj_str[1]\n",
    "        elif len(obj_str) == 1:\n",
    "            # it must be the object\n",
    "            shape = obj_str[0]\n",
    "        # Final handling for the shape.\n",
    "        if shape == \"object\":\n",
    "            shape = self.object_vocabulary.sample_shape()\n",
    "            \n",
    "        # Override size, color and shape based on relations.\n",
    "        if not is_root:\n",
    "            # Go through the rel.\n",
    "            for pair, rel in rel_map.items():\n",
    "                if obj_grammer == pair[-1]:\n",
    "                    if pair[0] in shape_map.keys():\n",
    "                        # if this obj is acting as a child node\n",
    "                        # then have to complain with parent node\n",
    "                        if rel == \"$SAME_SHAPE\":\n",
    "                            shape = shape_map[pair[0]]\n",
    "                        elif rel == \"$IS_INSIDE\":\n",
    "                            shape = \"box\"\n",
    "        return shape\n",
    "    \n",
    "    def sample_object_spec(\n",
    "        self, obj_grammer, obj_pattern, obj_str, rel_map, \n",
    "        is_root, obj_placed_map, \n",
    "        size_restriction_map=None,\n",
    "        mentioned_shapes=None\n",
    "    ):\n",
    "        obj_pattern = obj_pattern.split(\" \")\n",
    "        obj_str = obj_str.split(\" \")\n",
    "        color = None\n",
    "        size = None\n",
    "        shape = None\n",
    "        if len(obj_str) == 3:\n",
    "            size = self.object_vocabulary.sample_size_with_prior(prior=obj_str[0])\n",
    "            color = obj_str[1]\n",
    "            shape = obj_str[2]\n",
    "        elif len(obj_str) == 2:\n",
    "            if \"$COLOR\" in obj_pattern: # color + shape.\n",
    "                size = self.object_vocabulary.sample_size()\n",
    "                color = obj_str[0]\n",
    "                shape = obj_str[1]\n",
    "            elif \"$SIZE\" in obj_pattern: # size + shape.\n",
    "                size = self.object_vocabulary.sample_size_with_prior(prior=obj_str[0])\n",
    "                color = self.object_vocabulary.sample_color()\n",
    "                shape = obj_str[1]\n",
    "        elif len(obj_str) == 1:\n",
    "            # it must be the object\n",
    "            size = self.object_vocabulary.sample_size()\n",
    "            color = self.object_vocabulary.sample_color()\n",
    "            shape = obj_str[0]\n",
    "        # Final handling for the shape.\n",
    "        if shape == \"object\":\n",
    "            # WARNING: this is a corner case you will hit\n",
    "            # if your logic chain is long, you may need to\n",
    "            # consider remove object option!\n",
    "            if mentioned_shapes != None and len(mentioned_shapes) == self.object_vocabulary._shapes:\n",
    "                assert False\n",
    "            if is_root:\n",
    "                shape = self.object_vocabulary.sample_shape() # _exclude=mentioned_shapes\n",
    "            else:\n",
    "                shape = self.object_vocabulary.sample_shape()\n",
    "\n",
    "        # Override size, color and shape based on relations.\n",
    "        # if not is_root:\n",
    "        #     # Go through the rel.\n",
    "        #     for pair, rel in rel_map.items():\n",
    "        #         if obj_grammer == pair[-1]:\n",
    "        #             if pair[0] in obj_placed_map.keys():\n",
    "        #                 # if this obj is acting as a child node\n",
    "        #                 # then have to complain with parent node\n",
    "        #                 if rel == \"$SAME_SHAPE\":\n",
    "        #                     shape = obj_placed_map[pair[0]].shape\n",
    "        #                 elif rel == \"$SAME_COLOR\":\n",
    "        #                     color = obj_placed_map[pair[0]].color\n",
    "        #                 elif rel == \"$SAME_SIZE\":\n",
    "        #                     size = obj_placed_map[pair[0]].size\n",
    "        #                 elif rel == \"$IS_INSIDE\":\n",
    "        #                    shape = \"box\" # Might never reach here.\n",
    "                \n",
    "        return Object(color=color,size=size,shape=shape)\n",
    "                    \n",
    "    def sample_object_position(\n",
    "        self, sampled_obj, root, obj_grammer, \n",
    "        rel_map, obj_placed_map, \n",
    "        obj_position_map,\n",
    "        retry_max=10\n",
    "    ):\n",
    "        # If it is the first node, we directly return.\n",
    "        if obj_grammer == root:\n",
    "            sampled_pos = self._world.sample_position()\n",
    "            return sampled_pos\n",
    "                \n",
    "        for _ in range(retry_max):\n",
    "            if sampled_obj.shape != \"box\":\n",
    "                obj_random_pos = self._world.sample_position()\n",
    "            else:\n",
    "                obj_random_pos = self._world.sample_position_box(sampled_obj.size)\n",
    "\n",
    "            row = obj_random_pos.row\n",
    "            col = obj_random_pos.column\n",
    "            for pair, rel in rel_map.items():\n",
    "                if obj_grammer == pair[-1]:\n",
    "                    if pair[0] in obj_placed_map.keys():\n",
    "                        # if this obj is acting as a child node\n",
    "                        # then have to complain with parent node\n",
    "                        if rel == \"$SAME_ROW\":\n",
    "                            row = obj_position_map[pair[0]].row\n",
    "                        elif rel == \"$SAME_COLUMN\":\n",
    "                            col = obj_position_map[pair[0]].column\n",
    "                        elif rel == \"$IS_INSIDE\":\n",
    "                            # we need to make sure enclosure\n",
    "                            size = sampled_obj.size\n",
    "                            row_higher = min(obj_position_map[pair[0]].row, self.grid_size-size)\n",
    "                            col_higher = min(obj_position_map[pair[0]].column, self.grid_size-size)\n",
    "                            row_lower = max(obj_position_map[pair[0]].row-(size-1), 0)\n",
    "                            col_lower = max(obj_position_map[pair[0]].column-(size-1), 0)\n",
    "                            random_positions = []\n",
    "                            for i in range(row_lower, row_higher+1):\n",
    "                                for j in range(col_lower, col_higher+1):\n",
    "                                    random_positions.append((i,j))\n",
    "                            random.shuffle(random_positions)\n",
    "                            for position in random_positions:\n",
    "                                # consider the size and boundary as well\n",
    "                                row = position[0]\n",
    "                                col = position[1]\n",
    "                                proposed_position=Position(row=row, column=col)\n",
    "                                if not self._world.position_taken(proposed_position):\n",
    "                                    break\n",
    "\n",
    "            proposed_position=Position(row=row, column=col)\n",
    "            # we need to resample the position for box.\n",
    "\n",
    "            if sampled_obj.shape != \"box\":\n",
    "                if not self._world.position_taken(proposed_position):\n",
    "                    return proposed_position\n",
    "            else:\n",
    "                overlap_box = False\n",
    "                for obj_str, obj in obj_placed_map.items():\n",
    "                    if obj.shape == \"box\":\n",
    "                        if obj_position_map[obj_str].row == row and \\\n",
    "                            obj_position_map[obj_str].column == col:\n",
    "                            overlap_box = True\n",
    "                            break\n",
    "                if not overlap_box:\n",
    "                    return proposed_position\n",
    "        return -1 # Fail to propose a valid position.\n",
    "    \n",
    "    def sample_random_object_spec(\n",
    "        self, \n",
    "        size_exclude=None, \n",
    "        color_exclude=None, shape_exclude=None\n",
    "    ):\n",
    "        d_size = self.object_vocabulary.sample_size(_exclude=size_exclude)\n",
    "        d_color = self.object_vocabulary.sample_color(_exclude=color_exclude)\n",
    "        d_shape = self.object_vocabulary.sample_shape(_exclude=shape_exclude)\n",
    "        return Object(color=d_color,size=d_size,shape=d_shape)\n",
    "    \n",
    "    def place_distractor_from_dict(\n",
    "        self, distractors_dict, \n",
    "        obj_placed_map, obj_position_map, \n",
    "        debug=False, \n",
    "        special_shape_size_bound=None,\n",
    "        mentioned_shapes=None,\n",
    "    ):\n",
    "        if debug:\n",
    "            import pprint\n",
    "            pp = pprint.PrettyPrinter(indent=4)\n",
    "            pp.pprint(distractors_dict)\n",
    "        distractor_root = f\"$OBJ_{len(obj_placed_map)}\"\n",
    "        success = True\n",
    "        distractors_obj_map = distractors_dict[\"obj_map\"]\n",
    "        distractors_rel_map = distractors_dict[\"rel_map\"]\n",
    "        distractors_obj_pattern_map = distractors_dict[\"obj_pattern_map\"]\n",
    "        distractors_size_map = distractors_dict[\"size_map\"]\n",
    "        \n",
    "        distractors_sampled_obj_map = {}\n",
    "        for dis_grammer, dis_str in distractors_obj_map.items():\n",
    "            # 1. Sample object.\n",
    "            sampled_dis = self.sample_object_spec(\n",
    "                dis_grammer,\n",
    "                distractors_obj_pattern_map[dis_grammer], \n",
    "                dis_str, distractors_rel_map, \n",
    "                is_root=dis_grammer==distractor_root, \n",
    "                obj_placed_map=obj_placed_map,\n",
    "                mentioned_shapes=mentioned_shapes,\n",
    "            )\n",
    "            # 1.1. Update the size of the object if needed.\n",
    "            if dis_grammer in distractors_size_map.keys():\n",
    "                sampled_dis = Object(\n",
    "                    color=sampled_dis.color,\n",
    "                    size=distractors_size_map[dis_grammer],\n",
    "                    shape=sampled_dis.shape\n",
    "                )\n",
    "            # 1.2. Another pass of override by using global constraints.\n",
    "            special_shape_super = sampled_dis.shape\n",
    "            special_shape_sub = sampled_dis.color + \" \" + sampled_dis.shape\n",
    "            # e.g., small circle exists in the command, then any colored circle needs to be constrain\n",
    "            if special_shape_super in special_shape_size_bound.keys():\n",
    "                if \"small\" in dis_str:\n",
    "                    updated_size = special_shape_size_bound[special_shape_super][0]\n",
    "                else:\n",
    "                    updated_size = special_shape_size_bound[special_shape_super][1]\n",
    "                sampled_dis = Object(\n",
    "                    color=sampled_dis.color,\n",
    "                    size=updated_size,\n",
    "                    shape=sampled_dis.shape\n",
    "                )\n",
    "            elif special_shape_sub in special_shape_size_bound.keys():\n",
    "                if \"small\" in dis_str:\n",
    "                    updated_size = special_shape_size_bound[special_shape_sub][0]\n",
    "                else:\n",
    "                    updated_size = special_shape_size_bound[special_shape_sub][1]\n",
    "                sampled_dis = Object(\n",
    "                    color=sampled_dis.color,\n",
    "                    size=updated_size,\n",
    "                    shape=sampled_dis.shape\n",
    "                )\n",
    "            else:\n",
    "                pass # Do nothing.\n",
    "            distractors_sampled_obj_map[dis_grammer] = sampled_dis\n",
    "        \n",
    "        # 2. Update it using relationships.\n",
    "        for pair, rel in distractors_rel_map.items():\n",
    "            if rel == \"$SAME_SHAPE\":\n",
    "                # Update the src node shape information.\n",
    "                # shape = distractors_sampled_obj_map[pair[1]].shape\n",
    "                # distractors_sampled_obj_map[pair[0]] = Object(\n",
    "                #     color=distractors_sampled_obj_map[pair[0]].color,\n",
    "                #     size=distractors_sampled_obj_map[pair[0]].size,\n",
    "                #     shape=shape\n",
    "                # )\n",
    "                pass\n",
    "            elif rel == \"$SAME_COLOR\":\n",
    "                # Update the src node color information.\n",
    "                # color = distractors_sampled_obj_map[pair[1]].color\n",
    "                # distractors_sampled_obj_map[pair[0]] = Object(\n",
    "                #     color=color,\n",
    "                #     size=distractors_sampled_obj_map[pair[0]].size,\n",
    "                #     shape=distractors_sampled_obj_map[pair[0]].shape\n",
    "                # )\n",
    "                pass\n",
    "            elif rel == \"$SAME_SIZE\":\n",
    "                # Update the src node size information.\n",
    "                size = distractors_sampled_obj_map[pair[1]].size\n",
    "                distractors_sampled_obj_map[pair[0]] = Object(\n",
    "                    color=distractors_sampled_obj_map[pair[0]].color,\n",
    "                    size=size,\n",
    "                    shape=distractors_sampled_obj_map[pair[0]].shape\n",
    "                )\n",
    "            elif rel == \"$IS_INSIDE\":\n",
    "                pass # Do nothing!\n",
    "\n",
    "        for dis_grammer, sampled_dis in distractors_sampled_obj_map.items():\n",
    "            # 2. Place on the world map.\n",
    "            sampled_pos = self.sample_object_position(\n",
    "                sampled_dis, distractor_root, \n",
    "                dis_grammer, distractors_rel_map, \n",
    "                obj_placed_map, obj_position_map\n",
    "            )\n",
    "\n",
    "            if sampled_dis == -1 or sampled_pos == -1:\n",
    "                return False\n",
    "\n",
    "            self._world.place_object(\n",
    "                sampled_dis, \n",
    "                position=sampled_pos, target=False # Distractor is never the target!\n",
    "            )\n",
    "            obj_placed_map[dis_grammer] = sampled_dis\n",
    "            obj_position_map[dis_grammer] = sampled_pos\n",
    "        return True\n",
    "    \n",
    "    def sample_situations_from_grounded_grammer(\n",
    "        self, grammer_pattern, \n",
    "        obj_pattern_map, rel_map, obj_map, root=\"$OBJ_0\", \n",
    "        is_plot=False, \n",
    "        include_random_distractor=False, \n",
    "        include_relation_distractor=False, \n",
    "        include_attribute_distractor=False, \n",
    "        include_isomorphism_distractor=False, \n",
    "        full_relation_probability=0.5,\n",
    "        debug=False,\n",
    "    ):\n",
    "        # Clear current world.\n",
    "        self._world.clear_situation()\n",
    "        \n",
    "        # Start placing objects with specs.\n",
    "        obj_placed_map = OrderedDict({})\n",
    "        obj_position_map = OrderedDict({})\n",
    "        referred_obj = root\n",
    "        \n",
    "        # Preliminary size check!\n",
    "        \"\"\"\n",
    "        Here is a list of potential internal conflicts:\n",
    "        (1) ... to a small box ... to a yellow box ...\n",
    "        Explain: we need to adjust the size of two boxes\n",
    "        so that small box has 1 size, and all other boxes \n",
    "        have the same other size.\n",
    "        There will at max two different size of same type objects.\n",
    "        \n",
    "        So this is the rule:\n",
    "        For 1 type of shape, max two different sizes.\n",
    "        \"\"\"\n",
    "        # Ok, we need to determine shapes first!\n",
    "        # Even there is any abstract object, the\n",
    "        # shape is now determined.\n",
    "        object_map = {}\n",
    "        mentioned_shapes = set([]) # this is used to sample shapes for object.\n",
    "        for obj_grammer, obj_str in obj_map.items():\n",
    "            shape = self.extract_shape(obj_str)\n",
    "            if shape != \"\":\n",
    "                mentioned_shapes.add(shape)\n",
    "        for obj_grammer, obj_str in obj_map.items():\n",
    "            # 1. Sample object.\n",
    "            sampled_obj = self.sample_object_spec(\n",
    "                obj_grammer,\n",
    "                obj_pattern_map[obj_grammer], obj_str, rel_map, \n",
    "                is_root=obj_grammer==root, \n",
    "                obj_placed_map=object_map,\n",
    "                mentioned_shapes=mentioned_shapes,\n",
    "            )\n",
    "            object_map[obj_grammer] = sampled_obj\n",
    "        \n",
    "        # Next, we update all of them based on relations.\n",
    "        # Final pass, we need to change attributes of objects based\n",
    "        # on relations.\n",
    "        # Here, we only change size!\n",
    "        for pair, rel in rel_map.items():\n",
    "            if rel == \"$SAME_SHAPE\":\n",
    "                # Update the src node shape information.\n",
    "                shape = object_map[pair[1]].shape\n",
    "                object_map[pair[0]] = Object(\n",
    "                    color=object_map[pair[0]].color,\n",
    "                    size=object_map[pair[0]].size,\n",
    "                    shape=shape\n",
    "                )\n",
    "                pass\n",
    "            elif rel == \"$SAME_COLOR\":\n",
    "                # Update the src node color information.\n",
    "                color = object_map[pair[1]].color\n",
    "                object_map[pair[0]] = Object(\n",
    "                    color=color,\n",
    "                    size=object_map[pair[0]].size,\n",
    "                    shape=object_map[pair[0]].shape\n",
    "                )\n",
    "                pass\n",
    "            elif rel == \"$SAME_SIZE\":\n",
    "                # Update the src node size information.\n",
    "                size = object_map[pair[1]].size\n",
    "                object_map[pair[0]] = Object(\n",
    "                    color=object_map[pair[0]].color,\n",
    "                    size=size,\n",
    "                    shape=object_map[pair[0]].shape\n",
    "                )\n",
    "            elif rel == \"$IS_INSIDE\":\n",
    "                pass\n",
    "            \n",
    "        # Then, we will determine size bounds.\n",
    "        special_shape_size_bound = {}\n",
    "        for obj_grammer, obj_pattern in obj_pattern_map.items():\n",
    "            \n",
    "            small_size = random.randint(\n",
    "                self.object_vocabulary._min_size, \n",
    "                self.object_vocabulary._max_size-1\n",
    "            )\n",
    "            big_size = random.randint(\n",
    "                small_size+1, \n",
    "                self.object_vocabulary._max_size\n",
    "            )\n",
    "            \n",
    "            if \"$SIZE\" in obj_pattern and \"$COLOR\" in obj_pattern:\n",
    "                special_shape = object_map[obj_grammer].color + \" \" + object_map[obj_grammer].shape\n",
    "                if object_map[obj_grammer].shape in special_shape_size_bound.keys():\n",
    "                    # e.g., small circle exists\n",
    "                    special_shape_size_bound[special_shape] = special_shape_size_bound[object_map[obj_grammer].shape]\n",
    "                else:\n",
    "                    # e.g., small yellow circle\n",
    "                    special_shape_size_bound[special_shape] = [small_size, big_size]\n",
    "            elif \"$SIZE\" in obj_pattern and not \"$COLOR\" in obj_pattern:\n",
    "                # e.g., small circle\n",
    "                # overwrite any existing bounds.\n",
    "                special_shape = object_map[obj_grammer].shape\n",
    "                for ss, bound in special_shape_size_bound.items():\n",
    "                    if special_shape in ss:\n",
    "                        special_shape_size_bound[ss] = [small_size, big_size]\n",
    "                # for shape, it adds.\n",
    "                special_shape_size_bound[special_shape] = [small_size, big_size]\n",
    "                # for non-sized shape, it also adds as long as shape is the same.\n",
    "                for obj_grammer, obj_pattern in obj_pattern_map.items():\n",
    "                    if special_shape in obj_map[obj_grammer]:\n",
    "                        if \"$COLOR\" in obj_pattern:\n",
    "                            special_shape = object_map[obj_grammer].color + \" \" + object_map[obj_grammer].shape\n",
    "                            special_shape_size_bound[special_shape] = [small_size, big_size]\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        # Update object size based on global scanning results.\n",
    "        updated_object_map = {}\n",
    "        for obj_grammer, obj_pattern in obj_pattern_map.items():\n",
    "\n",
    "            special_shape_super = object_map[obj_grammer].shape\n",
    "            special_shape_sub = object_map[obj_grammer].color + \" \" + object_map[obj_grammer].shape\n",
    "            \n",
    "            # e.g., small circle exists in the command, then any colored circle needs to be constrain\n",
    "            if special_shape_super in special_shape_size_bound.keys():\n",
    "                if \"small\" in obj_map[obj_grammer]:\n",
    "                    updated_size = special_shape_size_bound[special_shape_super][0]\n",
    "                else:\n",
    "                    updated_size = special_shape_size_bound[special_shape_super][1]\n",
    "                updated_object_map[obj_grammer] = Object(\n",
    "                    color=object_map[obj_grammer].color,\n",
    "                    size=updated_size,\n",
    "                    shape=object_map[obj_grammer].shape\n",
    "                )\n",
    "            elif special_shape_sub in special_shape_size_bound.keys():\n",
    "                if \"small\" in obj_map[obj_grammer]:\n",
    "                    updated_size = special_shape_size_bound[special_shape_sub][0]\n",
    "                else:\n",
    "                    updated_size = special_shape_size_bound[special_shape_sub][1]\n",
    "                updated_object_map[obj_grammer] = Object(\n",
    "                    color=object_map[obj_grammer].color,\n",
    "                    size=updated_size,\n",
    "                    shape=object_map[obj_grammer].shape\n",
    "                )\n",
    "            else:\n",
    "                # If nothing exists in the special size map, then we don't need\n",
    "                # to alter the size.\n",
    "                updated_object_map[obj_grammer] = object_map[obj_grammer]\n",
    "\n",
    "        # Final pass, we need to change attributes of objects based\n",
    "        # on relations.\n",
    "        # Here, we only change size!\n",
    "        for pair, rel in rel_map.items():\n",
    "            if rel == \"$SAME_SHAPE\":\n",
    "                # Update the src node shape information.\n",
    "                # shape = updated_object_map[pair[1]].shape\n",
    "                # updated_object_map[pair[0]] = Object(\n",
    "                #     color=object_map[pair[0]].color,\n",
    "                #     size=object_map[pair[0]].size,\n",
    "                #     shape=shape\n",
    "                #)\n",
    "                pass\n",
    "            elif rel == \"$SAME_COLOR\":\n",
    "                # Update the src node color information.\n",
    "                # color = updated_object_map[pair[1]].color\n",
    "                # updated_object_map[pair[0]] = Object(\n",
    "                #     color=color,\n",
    "                #     size=object_map[pair[0]].size,\n",
    "                #     shape=object_map[pair[0]].shape\n",
    "                # )\n",
    "                pass\n",
    "            elif rel == \"$SAME_SIZE\":\n",
    "                # Update the src node size information.\n",
    "                size = updated_object_map[pair[1]].size\n",
    "                updated_object_map[pair[0]] = Object(\n",
    "                    color=object_map[pair[0]].color,\n",
    "                    size=size,\n",
    "                    shape=object_map[pair[0]].shape\n",
    "                )\n",
    "            elif rel == \"$IS_INSIDE\":\n",
    "                pass\n",
    "        \n",
    "        # Next, we sample positions of all objects and place them.\n",
    "        for obj_grammer, obj_str in obj_map.items():\n",
    "            # 1. Sample object (bu fetching the updated one).\n",
    "            sampled_obj = updated_object_map[obj_grammer]\n",
    "            \n",
    "            # 2. Place on the world map.\n",
    "            sampled_pos = self.sample_object_position(\n",
    "                sampled_obj, root, obj_grammer, rel_map, \n",
    "                obj_placed_map, obj_position_map\n",
    "            )\n",
    "            \n",
    "            if sampled_obj == -1 or sampled_pos == -1:\n",
    "                return -1 # Fail to sample.\n",
    "        \n",
    "            self._world.place_object(\n",
    "                sampled_obj, \n",
    "                position=sampled_pos, target=obj_grammer==root\n",
    "            )\n",
    "            obj_placed_map[obj_grammer] = sampled_obj\n",
    "            obj_position_map[obj_grammer] = sampled_pos\n",
    "            \n",
    "        \"\"\"\n",
    "        Distractor Sampling Strategies and Design\n",
    "        \n",
    "        Giving a complex command as:\n",
    "        \"the small red circle(1) that is in the same row(a) \n",
    "        as a big green square(2) and that is in the same column(b) \n",
    "        as a small yellow cylinder(3).\"\n",
    "        \n",
    "        We have 4 types of distractors (objects):\n",
    "        - Attribute-based Distractors\n",
    "        - Relation-based Distractors\n",
    "        - Sytax-based Distractors\n",
    "        - Random Distractors\n",
    "        \n",
    "        For each type of distractors, we will modify the command\n",
    "        to generate a new command for distractors. Then, we will\n",
    "        ensure such every command-world pair needs to reason about\n",
    "        attribute, relation and syntax. \n",
    "        \n",
    "        There are some caveats around this design. Due to the \n",
    "        complexity of the command, to make sure\n",
    "        every attribute/relation is necessary becomes unfeasible. For\n",
    "        example, if we want to make \"small\" in \"the small red circle (1)\"\n",
    "        necessary, then, we need to put another non-\"small\" \"red circle\".\n",
    "        This is easy. However, if we want to make \"big\" in \"the big\n",
    "        green square\" necessary, we essentially need to sample another\n",
    "        set of objects (at max 3) that complies with a modified command\n",
    "        \"the small red circle(1) that is in the same row(a) \n",
    "        as a small green square(2*) and that is in the same column(b) \n",
    "        as a small yellow cylinder(3).\"\n",
    "        \n",
    "        Following this logic, if we want to make sure *every descriptor*\\\n",
    "        (i.e., every adjective) is necessary to identity the referent\n",
    "        target, we could flood the system easily with way too many\n",
    "        distractors that cannot fit in our grid world.\n",
    "        \n",
    "        On the other hand, the goal of having the distractors is to\n",
    "        have the system learn the importantce of relations, attributes\n",
    "        and linguistic syntax. So, are these distractors necessary?\n",
    "        Do we need to actually have an exhaustive list of distractors\n",
    "        for each command-world pair in order to have the model to learn\n",
    "        this? We propose the answer is No, but Yes in the dataset level. In\n",
    "        the command level, we will not make sure *every descriptor* is\n",
    "        necessary, but in the command level, we will make sure \n",
    "        *every descriptor* matters for at least some of the command.\n",
    "        Otherwise, the model may just completely ignores one part of\n",
    "        the command and relies on the rest.\n",
    "        \n",
    "        In our design, we ensure for each command-world pair, some attribute\n",
    "        and some relation and some syntax are needed. In the dataset\n",
    "        level, we ensure different attribute, relation and syntax are \n",
    "        weighted equally.\n",
    "        \n",
    "        We propose to sample distractors following the design below:\n",
    "        \n",
    "        For a command such as\n",
    "        \"A that is X B and that is Y C\"\n",
    "        (1) We generate two distractor commands: \"A that X B\"; and \"A that Y C\"\n",
    "        without guarantee all relations in the original command. This samples\n",
    "        4 distractors. This ensures X and Y are necessary!\n",
    "        \n",
    "        (2) Next, we need to ensure that if we change some descriptors for\n",
    "        A, B or C, referent target cannot be identified. For example, if\n",
    "        we change B from \"yellow square\" to \"blue square\" the referent target\n",
    "        should change. In this case, we need to sample a new set of {A,B,C}.\n",
    "        And if we do this for each object, this results in 9 new distractors.\n",
    "        If size is not selected, we potentially need 3 more distractors to\n",
    "        ground the size aspects.\n",
    "        \n",
    "        (3) Next, to ensure model learns linguistic syntax, instead of simple\n",
    "        BoW approach to represent the command, we would perform swap attributes\n",
    "        between objects. We pick a pair of objects, and swap attributes \n",
    "        randomly. This results in 3 more distractors.\n",
    "        \n",
    "        (1) + (2) + (3) results in at max 19 distractors for each command-world pair.\n",
    "        Plus the original 3 objects, we have in total 21 distractors.\n",
    "        This is still a lot higher than gSCAN which is at max about 12.\n",
    "        \n",
    "        Then, we design another way to sample distractors:\n",
    "        (1) We pick 1 relations from {X, Y}, and generate distracotrs: 3 distractors.\n",
    "        \n",
    "        (2) We pick 1 object from {A, B, C} and modify its attribute, sample 3 distractors.\n",
    "        if size is not selected for any object, we need to randomly sample non-relational\n",
    "        counterparts, at max 3.\n",
    "        \n",
    "        (3) Same, so 3.\n",
    "        \n",
    "        (1) + (2) + (3) results in 3 + 3 + 3 + 3 = 12, 12 + 3 -> at max 15. Is this doable?\n",
    "        \n",
    "        Test set. global v.s. local compositional generalization. In the test set, we \n",
    "        can pick different/more aspect of differeent/more obj that matter for the\n",
    "        correctly reasonings, and generate test cases with  more distractors.\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        Calling in this way to create distractors:\n",
    "\n",
    "        simulator.sample_distractor_grammer_by_relation(\n",
    "            grammer_pattern, \n",
    "            obj_pattern_map, \n",
    "            rel_map, \n",
    "            obj_map, \n",
    "            sampled_world\n",
    "        )\n",
    "        \"\"\"\n",
    "        temp_sampled_world = {\n",
    "            \"obj_map\" : obj_placed_map,\n",
    "            \"pos_map\" : obj_position_map,\n",
    "            \"referred_obj\" : referred_obj,\n",
    "            \"situation\" : copy.deepcopy(self._world.get_current_situation())\n",
    "        }\n",
    "        \n",
    "        # Three types of distractor sampling for different purposes:\n",
    "        # sample_distractor_grammer_by_relation()\n",
    "        # - We will edit one leaf node, so that it makes sure\n",
    "        #   the command is necessary!\n",
    "        # sample_distractor_grammer_by_size()\n",
    "        # - Size relatives need to be meaningful. We will add relational\n",
    "        #   objects to make sure.\n",
    "        # sample_distractor_grammer_by_isomorphism()\n",
    "        # - This is to ensure syntax learning.\n",
    "        \n",
    "        distractor_switch_map = OrderedDict({\n",
    "            \"relation\" : [],\n",
    "            \"attribute\" : False,\n",
    "            \"isomorphism\" : False, \n",
    "            \"random\" : False,\n",
    "        })\n",
    "        relation_distractors_dicts = [{\n",
    "            \"distractor_metadata\": {}\n",
    "        }]\n",
    "        attribute_distractors_dicts = [{\n",
    "            \"distractor_metadata\": {}\n",
    "        }]\n",
    "        isomorphism_distractors_dicts = [{\n",
    "            \"distractor_metadata\": {}\n",
    "        }]\n",
    "        \n",
    "        if random.random() < full_relation_probability:\n",
    "            full_relation_set=True\n",
    "        else:\n",
    "            full_relation_set=False\n",
    "        if include_relation_distractor:\n",
    "            \"\"\"\n",
    "            Relation Distractors: Count=3*n, at max 6.\n",
    "            \"\"\"\n",
    "            relation_distractors_dicts = self.sample_distractor_grammer_by_relation(\n",
    "                grammer_pattern, \n",
    "                obj_pattern_map, \n",
    "                rel_map, \n",
    "                obj_map, \n",
    "                temp_sampled_world,\n",
    "                obj_base_count=len(obj_placed_map),\n",
    "                full_set=full_relation_set,\n",
    "            )\n",
    "            if len(relation_distractors_dicts) == 0:\n",
    "                pass # Size distractor is not applicable \n",
    "            else:\n",
    "                distractor_switch = []\n",
    "                for distractors_dict in relation_distractors_dicts:\n",
    "                    succeed = self.place_distractor_from_dict(\n",
    "                        distractors_dict, \n",
    "                        obj_placed_map, \n",
    "                        obj_position_map,\n",
    "                        debug=debug,\n",
    "                        special_shape_size_bound=special_shape_size_bound,\n",
    "                        mentioned_shapes=mentioned_shapes,\n",
    "                        # This is needed as maybe distractors also \n",
    "                        # need to be bounded by global constraints.\n",
    "                    )\n",
    "                    if succeed:\n",
    "                        distractor_switch += [True]\n",
    "                    else:\n",
    "                        distractor_switch += [False]\n",
    "                distractor_switch_map[\"relation\"] = distractor_switch\n",
    "                    \n",
    "        if include_attribute_distractor:\n",
    "            \"\"\"\n",
    "            Attribution Distractors: Count=3-6.\n",
    "            \"\"\"\n",
    "            # If the command is small, we can overwrite this\n",
    "            if len(rel_map) <= 1:\n",
    "                full_set = True\n",
    "            else:\n",
    "                full_set = not full_relation_set\n",
    "            attribute_distractors_dicts = self.sample_distractor_grammer_by_attribute(\n",
    "                grammer_pattern, \n",
    "                obj_pattern_map, \n",
    "                rel_map, \n",
    "                obj_map, \n",
    "                temp_sampled_world,\n",
    "                special_shape_size_bound,\n",
    "                obj_base_count=len(obj_placed_map),\n",
    "                full_set=full_set,\n",
    "            )\n",
    "            if len(attribute_distractors_dicts) == 0:\n",
    "                pass # Size distractor is not applicable \n",
    "            else:\n",
    "                succeed = self.place_distractor_from_dict(\n",
    "                    attribute_distractors_dicts[0], \n",
    "                    obj_placed_map, \n",
    "                    obj_position_map,\n",
    "                    debug=debug,\n",
    "                    special_shape_size_bound=special_shape_size_bound,\n",
    "                    mentioned_shapes=mentioned_shapes,\n",
    "                    # This is needed as maybe distractors also \n",
    "                    # need to be bounded by global constraints.\n",
    "                )\n",
    "                if succeed:\n",
    "                    distractor_switch_map[\"attribute\"] = True # If one time it is true, it is true.\n",
    "                else:\n",
    "                    return -1 # Maybe this is too restrict? Let us think about it!\n",
    "        \n",
    "        if include_isomorphism_distractor:\n",
    "            \"\"\"\n",
    "            Syntax Distractors: Count=3.\n",
    "            \"\"\"\n",
    "            isomorphism_distractors_dicts = self.sample_distractor_grammer_by_isomorphism(\n",
    "                grammer_pattern, \n",
    "                obj_pattern_map, \n",
    "                rel_map, \n",
    "                obj_map, \n",
    "                temp_sampled_world,\n",
    "                obj_base_count=len(obj_placed_map)\n",
    "            )\n",
    "            if len(isomorphism_distractors_dicts) == 0:\n",
    "                pass # Size distractor is not applicable \n",
    "            else:\n",
    "                succeed = self.place_distractor_from_dict(\n",
    "                    isomorphism_distractors_dicts[0], \n",
    "                    obj_placed_map, \n",
    "                    obj_position_map,\n",
    "                    debug=debug,\n",
    "                    special_shape_size_bound=special_shape_size_bound,\n",
    "                    mentioned_shapes=mentioned_shapes,\n",
    "                    # This is needed as maybe distractors also \n",
    "                    # need to be bounded by global constraints.\n",
    "                )\n",
    "                if succeed:\n",
    "                    distractor_switch_map[\"isomorphism\"] = True\n",
    "        \n",
    "        if distractor_switch_map[\"relation\"]:\n",
    "            for k, v in relation_distractors_dicts[0][\"obj_pattern_map\"].items():\n",
    "                obj_pattern_map[k] = v\n",
    "        \n",
    "        if distractor_switch_map[\"attribute\"]:\n",
    "            for k, v in attribute_distractors_dicts[0][\"obj_pattern_map\"].items():\n",
    "                obj_pattern_map[k] = v\n",
    "        \n",
    "        if distractor_switch_map[\"isomorphism\"]:\n",
    "            for k, v in isomorphism_distractors_dicts[0][\"obj_pattern_map\"].items():\n",
    "                obj_pattern_map[k] = v\n",
    "        \n",
    "        # Probably never need this!\n",
    "        \"\"\"\n",
    "        Random Distractors.\n",
    "        \"\"\"\n",
    "        # Place random distractors. These are gSCAN like distractors\n",
    "        # which are often not very meaningful for testing agents language\n",
    "        # knowledge. We recommand always turn this off and use other\n",
    "        # relation-based distractor sampling strategies.\n",
    "        \n",
    "        random_distractor_metadata = {}\n",
    "        n_random_distractor = -1\n",
    "        if include_random_distractor:\n",
    "            if len(obj_placed_map) >= self.n_object_max or len(mentioned_shapes) == len(self.vocabulary.get_semantic_shapes())-1:\n",
    "                pass # Do nothing!\n",
    "            else:\n",
    "                n_distractor = min(4, self.n_object_max-len(obj_placed_map)) # at max 2 random, how about?\n",
    "                n_random_distractor = n_distractor\n",
    "                core_obj_count = len(obj_placed_map)\n",
    "                for i in range(0, n_distractor):\n",
    "                    distractor_idx = core_obj_count+i\n",
    "                    distractor_name = f\"$OBJ_{distractor_idx}\"\n",
    "                    \n",
    "                    # Let us only sample shapes that are not exist\n",
    "                    sampled_distractor = self.sample_random_object_spec(\n",
    "                        shape_exclude=list(mentioned_shapes)\n",
    "                    )\n",
    "                    \n",
    "                    # Ok, we need to consider global size constraint!\n",
    "                    special_shape_super = sampled_distractor.shape\n",
    "                    special_shape_sub = sampled_distractor.color + \" \" +sampled_distractor.shape\n",
    "\n",
    "                    # e.g., small circle exists in the command, then any colored circle needs to be constrain\n",
    "                    size_idx = -1\n",
    "                    if special_shape_super in special_shape_size_bound.keys():\n",
    "                        size_idx = random.randint(0,1)\n",
    "                        updated_size = special_shape_size_bound[special_shape_super][size_idx]\n",
    "                        sampled_distractor = Object(\n",
    "                            color=sampled_distractor.color,\n",
    "                            size=updated_size,\n",
    "                            shape=sampled_distractor.shape\n",
    "                        )\n",
    "                    elif special_shape_sub in special_shape_size_bound.keys():\n",
    "                        size_idx = random.randint(0,1)\n",
    "                        updated_size = special_shape_size_bound[special_shape_sub][size_idx]\n",
    "                        sampled_distractor = Object(\n",
    "                            color=sampled_distractor.color,\n",
    "                            size=updated_size,\n",
    "                            shape=sampled_distractor.shape\n",
    "                        )\n",
    "                    \n",
    "                    sampled_dis_pos = self._world.sample_position()\n",
    "                    self._world.place_object(\n",
    "                        sampled_distractor, \n",
    "                        position=sampled_dis_pos, target=False\n",
    "                    )\n",
    "                    obj_placed_map[distractor_name] = sampled_distractor\n",
    "                    obj_position_map[distractor_name] = sampled_dis_pos\n",
    "                    size_str = \"\"\n",
    "                    if size_idx != -1:\n",
    "                        size_str = \"big\" if size_idx == 1 else \"small\"\n",
    "                    random_distractor_metadata[distractor_name] = \" \".join([\n",
    "                        size_str,\n",
    "                        sampled_distractor.color,\n",
    "                        sampled_distractor.shape\n",
    "                    ])\n",
    "                distractor_switch_map[\"random\"] = True\n",
    "\n",
    "        agent_position = self._world.sample_position()\n",
    "        self._world.place_agent_at(agent_position)\n",
    "        if is_plot:\n",
    "            _ = self._world.render_simple()\n",
    "        \n",
    "        situation_snapshot = copy.deepcopy(self._world.get_current_situation())\n",
    "        \n",
    "        return {\n",
    "            \"obj_map\" : obj_placed_map,\n",
    "            \"pos_map\" : obj_position_map,\n",
    "            \"obj_pattern_map\" : obj_pattern_map,\n",
    "            \"referred_obj\" : referred_obj,\n",
    "            \"situation\" : situation_snapshot, \n",
    "            \"distractor_switch_map\" : distractor_switch_map,\n",
    "            \"relation_distractor_metadata\" : [md[\"distractor_metadata\"] for md in relation_distractors_dicts],\n",
    "            \"attribute_distractor_metadata\" : [md[\"distractor_metadata\"] for md in attribute_distractors_dicts],\n",
    "            \"isomorphism_distractor_metadata\" : [md[\"distractor_metadata\"] for md in isomorphism_distractors_dicts],\n",
    "            \"random_distractor_metadata\" : [random_distractor_metadata],\n",
    "            \"n_random_distractor\" : n_random_distractor\n",
    "        }\n",
    "    \n",
    "    def get_action_list(\n",
    "        self,\n",
    "        verb=None,\n",
    "        adverb=None,\n",
    "    ):\n",
    "        pass\n",
    "    \n",
    "    def extract_size(self, obj_str):\n",
    "        obj_descriptors = obj_str.split(\" \")\n",
    "        for descriptor in obj_descriptors:\n",
    "            if descriptor in [\"small\", \"big\"]:\n",
    "                return descriptor\n",
    "        return \"\"\n",
    "\n",
    "    def extract_color(self, obj_str):\n",
    "        obj_descriptors = obj_str.split(\" \")\n",
    "        for descriptor in obj_descriptors:\n",
    "            if descriptor in self.object_vocabulary.object_colors:\n",
    "                return descriptor\n",
    "        return \"\"\n",
    "    \n",
    "    def extract_shape(self, obj_str):\n",
    "        obj_descriptors = obj_str.split(\" \")\n",
    "        for descriptor in obj_descriptors:\n",
    "            if descriptor in self.object_vocabulary.object_shapes:\n",
    "                return descriptor\n",
    "        return \"\"\n",
    "\n",
    "    def convert_object_str_to_grammer(self, obj_str):\n",
    "        size_g = False\n",
    "        color_g = False\n",
    "        abs_shape_g = False\n",
    "\n",
    "        obj_descriptors = obj_str.split(\" \")\n",
    "        for descriptor in obj_descriptors:\n",
    "            if descriptor in [\"small\", \"big\"]:\n",
    "                size_g = True\n",
    "            elif descriptor in self.object_vocabulary.object_colors:\n",
    "                color_g = True\n",
    "            elif descriptor in self.object_vocabulary.object_shapes:\n",
    "                pass\n",
    "            elif descriptor == \"object\":\n",
    "                abs_shape_g = True\n",
    "\n",
    "        grammer = []\n",
    "        if size_g:\n",
    "            grammer.append(\"$SIZE\")\n",
    "        if color_g:\n",
    "            grammer.append(\"$COLOR\")\n",
    "        if abs_shape_g:\n",
    "            grammer.append(\"$ABS_SHAPE\") # Mark as deprecated!\n",
    "        else:\n",
    "            grammer.append(\"$SHAPE\")\n",
    "        \n",
    "        return \" \".join(grammer)\n",
    "\n",
    "    def snap_pattern_to_referent_map(self, distractor_grammer_pattern, base_count):\n",
    "        distractor_grammer_pattern_snapped = []\n",
    "        for item in distractor_grammer_pattern.split(\" \"):\n",
    "            if item.startswith(\"$\"):\n",
    "                new_id = int(item.split(\"_\")[1])+base_count\n",
    "                distractor_grammer_pattern_snapped.append(f\"$OBJ_{new_id}\")\n",
    "            else:\n",
    "                distractor_grammer_pattern_snapped.append(item)\n",
    "        return \" \".join(distractor_grammer_pattern_snapped)\n",
    "\n",
    "    def snap_object_map_to_referent_map(self, distractor_map, base_count):\n",
    "        distractor_map_snapped = OrderedDict({})\n",
    "        for obj_name, item in distractor_map.items():\n",
    "            new_id = int(obj_name.split(\"_\")[1])+base_count\n",
    "            new_obj_name = f\"$OBJ_{new_id}\"\n",
    "            distractor_map_snapped[new_obj_name] = item\n",
    "        return distractor_map_snapped\n",
    "\n",
    "    def snap_relation_map_to_referent_map(self, distractor_rel_map, base_count):\n",
    "        distractor_rel_map_snapped = OrderedDict({})\n",
    "        for edge, item in distractor_rel_map.items():\n",
    "            if edge[0].startswith(\"$\"):\n",
    "                new_id_left = int(edge[0].split(\"_\")[1])+base_count\n",
    "                new_obj_name_left = f\"$OBJ_{new_id_left}\"\n",
    "            else:\n",
    "                new_obj_name_left = edge[0]\n",
    "            \n",
    "            if edge[1].startswith(\"$\"):\n",
    "                new_id_right = int(edge[1].split(\"_\")[1])+base_count\n",
    "                new_obj_name_right = f\"$OBJ_{new_id_right}\"\n",
    "            else:\n",
    "                new_obj_name_right = edge[1]\n",
    "            distractor_rel_map_snapped[(new_obj_name_left, new_obj_name_right)] = item\n",
    "        return distractor_rel_map_snapped\n",
    "    \n",
    "    def sample_distractor_grammer_by_relation(\n",
    "        self, \n",
    "        referent_grammer_pattern, \n",
    "        referent_obj_pattern_map,\n",
    "        referent_rel_map,\n",
    "        referent_obj_map, \n",
    "        sampled_world,\n",
    "        obj_base_count=0,\n",
    "        full_set=True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        This will select 1 relation mentioned in the command\n",
    "        and modify it to a new one. Then, sample distractors\n",
    "        based on that command (sampling step is outside of \n",
    "        this function). This function only construct the semantics\n",
    "        of distractors.\n",
    "        \"\"\"\n",
    "\n",
    "        distractors_dicts = []\n",
    "        # We first collect all the relations\n",
    "        relation_edges = []\n",
    "        for edge, relation in referent_rel_map.items():\n",
    "            relation_edges.append(edge)\n",
    "        random.shuffle(relation_edges)\n",
    "        if full_set:\n",
    "            pass\n",
    "        else:\n",
    "            relation_edges = relation_edges[:1] # select only the first element.\n",
    "        \n",
    "        existing_relations = set([v for k, v in referent_rel_map.items()])\n",
    "        # print(referent_rel_map)\n",
    "        for selected_leaf_edge in relation_edges:\n",
    "\n",
    "            # First, let us make copies.\n",
    "            distractor_grammer_pattern = copy.deepcopy(referent_grammer_pattern)\n",
    "            distractor_obj_pattern_map = copy.deepcopy(referent_obj_pattern_map)\n",
    "            distractor_rel_map = copy.deepcopy(referent_rel_map)\n",
    "            distractor_obj_map = copy.deepcopy(referent_obj_map)\n",
    "\n",
    "            # We may need to enforce the size of the distractor due to size descriptors!\n",
    "            distractor_size_map = {}\n",
    "        \n",
    "            selected_surgery = \"REL_ADJUST\" # Dummy\n",
    "\n",
    "            distractor_metadata = {\n",
    "                \"edge\" : selected_leaf_edge,\n",
    "                \"relation_old_type\" : distractor_rel_map[selected_leaf_edge]\n",
    "            }\n",
    "\n",
    "            if selected_surgery == \"REL_ADJUST\":\n",
    "                # Determine the new relation as not the same one as the current one.\n",
    "                new_rels = [\"$SAME_ROW\", \"$SAME_COLUMN\", \"$SAME_SHAPE\", \"$SAME_COLOR\", \"$SAME_SIZE\", \"$IS_INSIDE\"]\n",
    "                new_rels = set(new_rels) - existing_relations # make this very strict!\n",
    "                # There are something else do not make sense to sample!\n",
    "                # if \"$SIZE\" in distractor_obj_pattern_map[selected_leaf_edge[0]]:\n",
    "                #     new_rels -= set([\"$SAME_SIZE\"])\n",
    "                # if \"$COLOR\" in distractor_obj_pattern_map[selected_leaf_edge[0]]:\n",
    "                #     new_rels -= set([\"$SAME_COLOR\"])\n",
    "                # if \"$SHAPE\" in distractor_obj_pattern_map[selected_leaf_edge[0]]:\n",
    "                #    new_rels -= set([\"$SAME_SHAPE\"])\n",
    "                new_rel = random.choice(list(new_rels))\n",
    "                existing_relations.add(new_rel)\n",
    "                distractor_metadata[\"relation_new_type\"] = new_rel\n",
    "                distractor_rel_map[selected_leaf_edge] = new_rel\n",
    "                if new_rel == \"$IS_INSIDE\":\n",
    "                    # We can still try to keep the color and size the same.\n",
    "                    distractor_size_map[selected_leaf_edge[1]] = sampled_world[\"obj_map\"][selected_leaf_edge[1]].size\n",
    "                    distractor_obj_map[selected_leaf_edge[1]] = sampled_world[\"obj_map\"][selected_leaf_edge[1]].color + \" box\"\n",
    "                    distractor_obj_pattern_map[selected_leaf_edge[1]] = '$COLOR $SHAPE'\n",
    "                else:\n",
    "                    distractor_size_map[selected_leaf_edge[1]] = sampled_world[\"obj_map\"][selected_leaf_edge[1]].size\n",
    "                    if \"box\" in distractor_obj_map[selected_leaf_edge[1]]:\n",
    "                        # it used to box type object.\n",
    "                        distractor_size_map[selected_leaf_edge[1]] = sampled_world[\"obj_map\"][selected_leaf_edge[1]].size\n",
    "                        distractor_obj_map[selected_leaf_edge[1]] = sampled_world[\"obj_map\"][selected_leaf_edge[1]].color + \" object\"\n",
    "                        distractor_obj_pattern_map[selected_leaf_edge[1]] = '$COLOR $ABS_SHAPE'\n",
    "                    else:\n",
    "                        distractor_size_map[selected_leaf_edge[1]] = sampled_world[\"obj_map\"][selected_leaf_edge[1]].size\n",
    "                        distractor_obj_map[selected_leaf_edge[1]] = \\\n",
    "                            sampled_world[\"obj_map\"][selected_leaf_edge[1]].color + \" \" + \\\n",
    "                            sampled_world[\"obj_map\"][selected_leaf_edge[1]].shape\n",
    "                        distractor_obj_pattern_map[selected_leaf_edge[1]] = '$COLOR $SHAPE'\n",
    "            else:\n",
    "                assert False\n",
    "        \n",
    "            # We need to increment the object counters.\n",
    "            distractors_dicts += [{\n",
    "                                    \"grammer_pattern\" : self.snap_pattern_to_referent_map(\n",
    "                                        distractor_grammer_pattern,\n",
    "                                        obj_base_count\n",
    "                                    ),\n",
    "                                    \"obj_pattern_map\" : self.snap_object_map_to_referent_map(\n",
    "                                        distractor_obj_pattern_map,\n",
    "                                        obj_base_count\n",
    "                                    ),\n",
    "                                    \"rel_map\" : self.snap_relation_map_to_referent_map(\n",
    "                                        distractor_rel_map,\n",
    "                                        obj_base_count\n",
    "                                    ),\n",
    "                                    \"obj_map\" : self.snap_object_map_to_referent_map(\n",
    "                                        distractor_obj_map,\n",
    "                                        obj_base_count\n",
    "                                    ),\n",
    "                                    \"size_map\" : self.snap_object_map_to_referent_map(\n",
    "                                        distractor_size_map,\n",
    "                                        obj_base_count\n",
    "                                    ),\n",
    "                                    \"distractor_metadata\" : distractor_metadata\n",
    "                                }]\n",
    "            obj_base_count += len(distractor_obj_pattern_map)\n",
    "\n",
    "        return distractors_dicts\n",
    "\n",
    "    def sample_distractor_grammer_by_isomorphism(\n",
    "        self,\n",
    "        referent_grammer_pattern, \n",
    "        referent_obj_pattern_map,\n",
    "        referent_rel_map,\n",
    "        referent_obj_map, \n",
    "        sampled_world,\n",
    "        obj_base_count=0,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        This set of distractors are for learning syntax and grammers.\n",
    "        If you simply use BoW approach, it will not work because we \n",
    "        always instill confusing targets for you with isomorphism of the\n",
    "        referent graph.\n",
    "\n",
    "        For example, if the original grounded command is:\n",
    "        Go to the red square that is inside of the yellow box.\n",
    "\n",
    "        We can do a isomorphism which is\n",
    "        Go to the yellow square that is inside of the red box.\n",
    "\n",
    "        If the model is not understanding the language correctly,\n",
    "        it will not able to find the referent target correctly.\n",
    "        \"\"\"\n",
    "        # First, let us make copies.\n",
    "        distractor_grammer_pattern = copy.deepcopy(referent_grammer_pattern)\n",
    "        distractor_obj_pattern_map = copy.deepcopy(referent_obj_pattern_map)\n",
    "        distractor_rel_map = copy.deepcopy(referent_rel_map)\n",
    "        distractor_obj_map = copy.deepcopy(referent_obj_map)\n",
    "        # We may need to enforce the size of the distractor due to size descriptors!\n",
    "        distractor_size_map = {}\n",
    "\n",
    "        shufflable_objects = []\n",
    "        for obj_name, obj_str in distractor_obj_map.items():\n",
    "            if obj_name == \"$OBJ_0\":\n",
    "                continue # We need to sample distractors of object 0, thus, we keep it intact!\n",
    "            obj_descriptors = obj_str.split(\" \")\n",
    "            if \"object\" in obj_descriptors:\n",
    "                # \"object\" itself is not shufflable!\n",
    "                if len(obj_descriptors) > 1:\n",
    "                    shufflable_objects.append((obj_name, obj_str))\n",
    "            else:\n",
    "                shufflable_objects.append((obj_name, obj_str))\n",
    "        if len(shufflable_objects) > 2:\n",
    "            random.shuffle(shufflable_objects)\n",
    "        shufflable_objects = shufflable_objects[:2]\n",
    "        \n",
    "        if len(shufflable_objects) == 1:\n",
    "            return [] # We simply don't have enough objects to do this.\n",
    "\n",
    "        # We will shuffle attributes between two objects.\n",
    "        # We actually shuffle by looking at their relations.\n",
    "        obj_name_left = shufflable_objects[0][0]\n",
    "        obj_name_right = shufflable_objects[1][0]\n",
    "        swap_color = True\n",
    "        swap_size = False # Let us stop swapping size for now.\n",
    "        swap_shape = True\n",
    "        if (obj_name_left, obj_name_right) in distractor_rel_map.keys() or \\\n",
    "            (obj_name_right, obj_name_left) in distractor_rel_map.keys():\n",
    "            if ((obj_name_left, obj_name_right) in distractor_rel_map.keys() and \\\n",
    "                    distractor_rel_map[(obj_name_left, obj_name_right)] == \"SameColor\") or \\\n",
    "                ((obj_name_right, obj_name_left) in distractor_rel_map.keys() and \\\n",
    "                     distractor_rel_map[(obj_name_right, obj_name_left)] == \"SameColor\"):\n",
    "                swap_color = False\n",
    "            elif ((obj_name_left, obj_name_right) in distractor_rel_map.keys() and \\\n",
    "                    distractor_rel_map[(obj_name_left, obj_name_right)] == \"SameSize\") or \\\n",
    "                ((obj_name_right, obj_name_left) in distractor_rel_map.keys() and \\\n",
    "                     distractor_rel_map[(obj_name_right, obj_name_left)] == \"SameSize\"):\n",
    "                swap_size = False\n",
    "            elif ((obj_name_left, obj_name_right) in distractor_rel_map.keys() and \\\n",
    "                    distractor_rel_map[(obj_name_left, obj_name_right)] == \"SameShape\") or \\\n",
    "                ((obj_name_right, obj_name_left) in distractor_rel_map.keys() and \\\n",
    "                     distractor_rel_map[(obj_name_right, obj_name_left)] == \"SameShape\"):\n",
    "                swap_shape = False\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        size_left = self.extract_size(shufflable_objects[0][1])\n",
    "        size_right = self.extract_size(shufflable_objects[1][1])\n",
    "        color_left = self.extract_color(shufflable_objects[0][1])\n",
    "        color_right = self.extract_color(shufflable_objects[1][1])\n",
    "        shape_left = self.extract_shape(shufflable_objects[0][1])\n",
    "        shape_right = self.extract_shape(shufflable_objects[1][1])\n",
    "        \n",
    "        if size_left == \"\" and size_right == \"\":\n",
    "            swap_size = False\n",
    "        if color_left == \"\" and color_right == \"\":\n",
    "            swap_color = False\n",
    "        if shape_left == \"\" and shape_right == \"\":\n",
    "            swap_shape = False\n",
    "        if shape_left == \"box\" or shape_right == \"box\":\n",
    "            swap_shape = False\n",
    "        \n",
    "        if not swap_color and not swap_size and not swap_shape:\n",
    "            return []\n",
    "        \n",
    "        swapping_attribute = []\n",
    "        if swap_color:\n",
    "            swapping_attribute += [\"color\"]\n",
    "        if swap_size and swap_shape:\n",
    "            swapping_attribute += [\"size+shape\"]\n",
    "        if not swap_size and swap_shape:\n",
    "            swapping_attribute += [\"size+shape\"]\n",
    "        swapping_attribute = random.choice(swapping_attribute)\n",
    "\n",
    "        left_rebuild = []\n",
    "        right_rebuild = []\n",
    "        \n",
    "        size_shuffled = False\n",
    "        color_shuffled = False\n",
    "        shape_shuffled = False\n",
    "        if swapping_attribute == \"color\":\n",
    "            tmp = color_left\n",
    "            color_left = color_right\n",
    "            color_right = tmp\n",
    "            color_shuffled = True\n",
    "        elif swapping_attribute == \"shape\":\n",
    "            tmp = shape_left\n",
    "            shape_left = shape_right\n",
    "            shape_right = tmp\n",
    "            shape_shuffled = True\n",
    "        elif swapping_attribute == \"size+shape\":\n",
    "            tmp = shape_left\n",
    "            shape_left = shape_right\n",
    "            shape_right = tmp\n",
    "            shape_shuffled = True\n",
    "            \n",
    "            tmp = size_left\n",
    "            size_left = size_right\n",
    "            size_right = tmp\n",
    "            size_shuffled = True\n",
    "            \n",
    "        # We don't swap size!\n",
    "        if size_left != \"\":\n",
    "            left_rebuild.append(size_left)\n",
    "        if size_right != \"\":\n",
    "            right_rebuild.append(size_right)\n",
    "            \n",
    "        if color_left != \"\":\n",
    "            left_rebuild.append(color_left)\n",
    "        if color_right != \"\":\n",
    "            right_rebuild.append(color_right)\n",
    "\n",
    "        if shape_left != \"\":\n",
    "            left_rebuild.append(shape_left)\n",
    "        else:\n",
    "            left_rebuild.append(\"object\")\n",
    "        if shape_right != \"\":\n",
    "            right_rebuild.append(shape_right)\n",
    "        else:\n",
    "            right_rebuild.append(\"object\")\n",
    "        \n",
    "        if not color_shuffled and not shape_shuffled:\n",
    "            return []\n",
    "                \n",
    "        left_rebuild = \" \".join(left_rebuild)\n",
    "        right_rebuild = \" \".join(right_rebuild)\n",
    "        left_grammer_rebuild = self.convert_object_str_to_grammer(left_rebuild)\n",
    "        right_grammer_rebuild = self.convert_object_str_to_grammer(right_rebuild)\n",
    "        \n",
    "        # It seems like it is possible with our case\n",
    "        # You need extra cautious of you want to extend for longer logics\n",
    "        # if left_rebuild == shufflable_objects[1][1] or right_rebuild == shufflable_objects[0][1]:\n",
    "        #     return [] # we don't allow complete swap!\n",
    "        \n",
    "        distractor_obj_pattern_map[obj_name_left] = left_grammer_rebuild \n",
    "        distractor_obj_pattern_map[obj_name_right] = right_grammer_rebuild \n",
    "        distractor_obj_map[obj_name_left] = left_rebuild\n",
    "        distractor_obj_map[obj_name_right] = right_rebuild\n",
    "        \n",
    "        distractor_metadata = {\n",
    "            \"swapped_pair\" : (obj_name_left, obj_name_right),\n",
    "            \"before_pair_obj_str\" : (shufflable_objects[0][1], shufflable_objects[1][1]),\n",
    "            \"after_pair_obj_str\" : (left_rebuild, right_rebuild),\n",
    "            \"size_shuffled\" : size_shuffled,\n",
    "            \"color_shuffled\" : color_shuffled,\n",
    "            \"shape_shuffled\" : shape_shuffled\n",
    "        }\n",
    "        \n",
    "        return [{\n",
    "                    \"grammer_pattern\" : self.snap_pattern_to_referent_map(\n",
    "                        distractor_grammer_pattern,\n",
    "                        obj_base_count\n",
    "                    ),\n",
    "                    \"obj_pattern_map\" : self.snap_object_map_to_referent_map(\n",
    "                        distractor_obj_pattern_map,\n",
    "                        obj_base_count\n",
    "                    ),\n",
    "                    \"rel_map\" : self.snap_relation_map_to_referent_map(\n",
    "                        distractor_rel_map,\n",
    "                        obj_base_count\n",
    "                    ),\n",
    "                    \"obj_map\" : self.snap_object_map_to_referent_map(\n",
    "                        distractor_obj_map,\n",
    "                        obj_base_count\n",
    "                    ),\n",
    "                    \"size_map\" : self.snap_object_map_to_referent_map(\n",
    "                        distractor_size_map,\n",
    "                        obj_base_count\n",
    "                    ),\n",
    "                    \"distractor_metadata\" : [distractor_metadata]\n",
    "                }]\n",
    "\n",
    "    def sample_distractor_grammer_by_attribute(\n",
    "        self,\n",
    "        referent_grammer_pattern, \n",
    "        referent_obj_pattern_map,\n",
    "        referent_rel_map,\n",
    "        referent_obj_map, \n",
    "        sampled_world,\n",
    "        special_shape_size_bound,\n",
    "        obj_base_count=0,\n",
    "        full_set=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        We randomly select 1 object and 1 attribute\n",
    "        that exists in the command to do the attack.\n",
    "        \n",
    "        Then, for all objects if size attribute exists\n",
    "        this function is also responsible for sampling\n",
    "        dummy size distractors!\n",
    "        \"\"\"\n",
    "        # First, let us make copies.\n",
    "        distractor_grammer_pattern = copy.deepcopy(referent_grammer_pattern)\n",
    "        distractor_obj_pattern_map = copy.deepcopy(referent_obj_pattern_map)\n",
    "        distractor_rel_map = copy.deepcopy(referent_rel_map)\n",
    "        distractor_obj_map = copy.deepcopy(referent_obj_map)\n",
    "        # We may need to enforce the size of the distractor due to size descriptors!\n",
    "        distractor_size_map = OrderedDict({})\n",
    "        sizing_covered = []\n",
    "        if full_set:\n",
    "            obj_pool = []\n",
    "            for obj_name, obj_grammer in referent_obj_pattern_map.items():\n",
    "                if \"$ABS_SHAPE\" in obj_grammer:\n",
    "                    continue\n",
    "                obj_pool += [obj_name]\n",
    "            obj_selected = random.choice(obj_pool)\n",
    "            attribute_pool = referent_obj_pattern_map[obj_selected].split(\" \")\n",
    "            attribute_pool = list(set(attribute_pool)-set([\"$ABS_SHAPE\"]))\n",
    "            attribute_selected = random.choice(attribute_pool)\n",
    "\n",
    "            distractor_metadata = {\n",
    "                \"modified_obj\" : obj_selected,\n",
    "                \"modified_attribute\" : attribute_selected,\n",
    "            }\n",
    "\n",
    "            if attribute_selected == \"$SIZE\":\n",
    "                sizing_covered.append(obj_selected)\n",
    "                obj_name = obj_selected\n",
    "                original_object_str = distractor_obj_map[obj_name]\n",
    "                obj_grammer = distractor_obj_pattern_map[obj_name]\n",
    "                original_object = sampled_world['obj_map'][obj_name]\n",
    "                original_object_size = original_object.size\n",
    "                if \"$COLOR\" in obj_grammer:\n",
    "                    special_shape = \\\n",
    "                        sampled_world['obj_map'][obj_name].color + \\\n",
    "                        \" \" + sampled_world['obj_map'][obj_name].shape\n",
    "                else:\n",
    "                    special_shape = sampled_world['obj_map'][obj_name].shape\n",
    "                \n",
    "                if \"small\" in original_object_str:\n",
    "                    distractor_size = special_shape_size_bound[special_shape][1]\n",
    "                elif \"big\" in original_object_str:\n",
    "                    distractor_size = special_shape_size_bound[special_shape][0]\n",
    "                distractor_size_map[obj_name] = distractor_size\n",
    "                distractor_shape = original_object.shape\n",
    "                tmp_name = \"\"\n",
    "                if \"$COLOR\" in obj_grammer:\n",
    "                    distractor_color = original_object.color\n",
    "                    new_object_grammer = \"$SIZE $COLOR $SHAPE\" # $SIZE is a must right?\n",
    "                    tmp_name = distractor_color + \" \" + distractor_shape\n",
    "                else:\n",
    "                    distractor_color = self.object_vocabulary.sample_color()\n",
    "                    new_object_grammer = \"$SIZE $SHAPE\"\n",
    "                    tmp_name = distractor_shape\n",
    "                if \"small\" in original_object_str:\n",
    "                    tmp_name = \"big\" + \" \" + tmp_name\n",
    "                elif \"big\" in original_object_str:\n",
    "                    tmp_name = \"small\" + \" \" + tmp_name\n",
    "                else:\n",
    "                    pass # Not Implemented\n",
    "                distractor_obj_map[obj_name] = tmp_name\n",
    "                distractor_obj_pattern_map[obj_name] = new_object_grammer\n",
    "\n",
    "                # Then, we will also consider other object sizes. Basically,\n",
    "                # we keep them the same, unless they form SameShape relation\n",
    "                # with our core object.\n",
    "                for _obj_name, _obj in sampled_world['obj_map'].items():\n",
    "                    if _obj_name != obj_name:\n",
    "                        if (_obj_name, obj_name) in referent_rel_map and \\\n",
    "                            referent_rel_map[(_obj_name, obj_name)] == \"SameSize\":\n",
    "                            distractor_size_map[_obj_name] = distractor_size\n",
    "                        elif (obj_name, _obj_name) in referent_rel_map and \\\n",
    "                            referent_rel_map[(obj_name, _obj_name)] == \"SameSize\":\n",
    "                            distractor_size_map[_obj_name] = distractor_size\n",
    "                        else:\n",
    "                            distractor_size_map[_obj_name] = _obj.size\n",
    "            elif attribute_selected == \"$COLOR\":\n",
    "                original_object_name = obj_selected\n",
    "                original_object_str = distractor_obj_map[original_object_name]\n",
    "                original_object = sampled_world['obj_map'][original_object_name]\n",
    "                new_color = self.object_vocabulary.sample_color(_exclude=[original_object.color])\n",
    "                new_object_str = new_color + \" \" + original_object.shape\n",
    "                new_object_grammer = \"$COLOR $SHAPE\"\n",
    "                distractor_obj_map[original_object_name] = new_object_str\n",
    "                distractor_obj_pattern_map[original_object_name] = new_object_grammer\n",
    "            elif attribute_selected == \"$SHAPE\":\n",
    "\n",
    "                original_object_name = obj_selected\n",
    "                original_object_str = distractor_obj_map[original_object_name]\n",
    "                original_object = sampled_world['obj_map'][original_object_name]\n",
    "                new_shape = self.object_vocabulary.sample_shape(_exclude=[original_object.shape])\n",
    "                new_object_str = original_object.color + \" \" + new_shape\n",
    "                new_object_grammer = \"$COLOR $SHAPE\"\n",
    "                distractor_obj_map[original_object_name] = new_object_str\n",
    "                distractor_obj_pattern_map[original_object_name] = new_object_grammer\n",
    "                \n",
    "            # Now for all other objects with size attribute, we need\n",
    "            # to ground them even if it is not relational.\n",
    "            base_distractor_count = len(list(distractor_obj_map.keys()))\n",
    "            for obj_name, obj_grammer in referent_obj_pattern_map.items():\n",
    "                if \"$SIZE\" in obj_grammer:\n",
    "                    if obj_name not in sizing_covered:\n",
    "                        # Just sample a single one.\n",
    "                        new_obj_name = f\"OBJ_{base_distractor_count}\"\n",
    "                        original_object_str = referent_obj_map[obj_name]\n",
    "\n",
    "                        tmp_name = \" \".join(original_object_str.split(\" \")[1:])\n",
    "                        if \"small\" in original_object_str:\n",
    "                            tmp_name = \"big\" + \" \" + tmp_name\n",
    "                        elif \"big\" in original_object_str:\n",
    "                            tmp_name = \"small\" + \" \" + tmp_name\n",
    "                        else:\n",
    "                            pass # Not Implemented\n",
    "\n",
    "                        if \"$COLOR\" in obj_grammer:\n",
    "                            special_shape = \\\n",
    "                                sampled_world['obj_map'][obj_name].color + \\\n",
    "                                \" \" + sampled_world['obj_map'][obj_name].shape\n",
    "                        else:\n",
    "                            special_shape = sampled_world['obj_map'][obj_name].shape\n",
    "                        if \"small\" in original_object_str:\n",
    "                            distractor_size = special_shape_size_bound[special_shape][1]\n",
    "                        elif \"big\" in original_object_str:\n",
    "                            distractor_size = special_shape_size_bound[special_shape][0]\n",
    "                        # the above size if the proposed size!\n",
    "\n",
    "                        # Let us iterate through the map, if there is\n",
    "                        # already a shape working as the size counterparts\n",
    "                        # we don't need it!\n",
    "                        color = self.extract_color(original_object_str)\n",
    "                        shape = self.extract_shape(original_object_str)\n",
    "                        if color != \"\" and shape != \"object\":\n",
    "                            found = False\n",
    "                            for obj_str, obj in sampled_world['obj_map'].items():\n",
    "                                if obj.color == color and obj.shape == shape:\n",
    "                                    if obj.size == distractor_size:\n",
    "                                        found = True\n",
    "                                        break\n",
    "                            if found:\n",
    "                                continue\n",
    "                        elif color != \"\" and shape == \"object\":\n",
    "                            found = False\n",
    "                            for obj_str, obj in sampled_world['obj_map'].items():\n",
    "                                if obj.color == color:\n",
    "                                    if obj.size == distractor_size:\n",
    "                                        found = True\n",
    "                                        break\n",
    "                            if found:\n",
    "                                continue\n",
    "                        elif color == \"\" and shape == \"object\":\n",
    "                            found = False\n",
    "                            for obj_str, obj in sampled_world['obj_map'].items():\n",
    "                                if obj.size == distractor_size:\n",
    "                                    found = True\n",
    "                                    break\n",
    "                            if found:\n",
    "                                continue\n",
    "                        elif color == \"\" and shape != \"object\":\n",
    "                            found = False\n",
    "                            for obj_str, obj in sampled_world['obj_map'].items():\n",
    "                                if obj.shape == shape:\n",
    "                                    if obj.size == distractor_size:\n",
    "                                        found = True\n",
    "                                        break\n",
    "                            if found:\n",
    "                                continue\n",
    "\n",
    "                        distractor_obj_map[new_obj_name] = tmp_name\n",
    "                        distractor_obj_pattern_map[new_obj_name] = obj_grammer\n",
    "                        distractor_size_map[new_obj_name] = distractor_size\n",
    "                        base_distractor_count += 1\n",
    "                \n",
    "        else:\n",
    "            # We cleanup, and simply place random objects.\n",
    "            distractor_grammer_pattern = \"DUMMY\"\n",
    "            distractor_obj_pattern_map.clear()\n",
    "            distractor_rel_map.clear()\n",
    "            distractor_obj_map.clear()\n",
    "            \n",
    "            distractor_metadata = {\n",
    "                \"modified_obj\" : None,\n",
    "                \"modified_attribute\" : None,\n",
    "            }\n",
    "            # Now for all other objects with size attribute, we need\n",
    "            # to ground them even if it is not relational.\n",
    "            base_distractor_count = len(list(distractor_obj_map.keys()))\n",
    "            for obj_name, obj_grammer in referent_obj_pattern_map.items():\n",
    "                if \"$SIZE\" in obj_grammer:\n",
    "                    if obj_name not in sizing_covered:\n",
    "                        # Just sample a single one.\n",
    "                        new_obj_name = f\"OBJ_{base_distractor_count}\"\n",
    "                        original_object_str = referent_obj_map[obj_name]\n",
    "                        \n",
    "                        tmp_name = \" \".join(original_object_str.split(\" \")[1:])\n",
    "                        if \"small\" in original_object_str:\n",
    "                            tmp_name = \"big\" + \" \" + tmp_name\n",
    "                        elif \"big\" in original_object_str:\n",
    "                            tmp_name = \"small\" + \" \" + tmp_name\n",
    "                        else:\n",
    "                            pass # Not Implemented\n",
    "\n",
    "                        if \"$COLOR\" in obj_grammer:\n",
    "                            special_shape = \\\n",
    "                                sampled_world['obj_map'][obj_name].color + \\\n",
    "                                \" \" + sampled_world['obj_map'][obj_name].shape\n",
    "                        else:\n",
    "                            special_shape = sampled_world['obj_map'][obj_name].shape\n",
    "                        \n",
    "                        # We need to be a little careful when\n",
    "                        # dealing with abstract shape object\n",
    "                        # for example, big object -> small object.\n",
    "                            \n",
    "                        if \"small\" in original_object_str:\n",
    "                            distractor_size = special_shape_size_bound[special_shape][1]\n",
    "                        elif \"big\" in original_object_str:\n",
    "                            distractor_size = special_shape_size_bound[special_shape][0]\n",
    "                        # the above size if the proposed size!\n",
    "                        \n",
    "                        # Let us iterate through the map, if there is\n",
    "                        # already a shape working as the size counterparts\n",
    "                        # we don't need it!\n",
    "                        color = self.extract_color(original_object_str)\n",
    "                        shape = self.extract_shape(original_object_str)\n",
    "                        if color != \"\" and shape != \"object\":\n",
    "                            found = False\n",
    "                            for obj_str, obj in sampled_world['obj_map'].items():\n",
    "                                if obj.color == color and obj.shape == shape:\n",
    "                                    if obj.size == distractor_size:\n",
    "                                        found = True\n",
    "                                        break\n",
    "                            if found:\n",
    "                                continue\n",
    "                        elif color != \"\" and shape == \"object\":\n",
    "                            found = False\n",
    "                            for obj_str, obj in sampled_world['obj_map'].items():\n",
    "                                if obj.color == color:\n",
    "                                    if obj.size == distractor_size:\n",
    "                                        found = True\n",
    "                                        break\n",
    "                            if found:\n",
    "                                continue\n",
    "                        elif color == \"\" and shape == \"object\":\n",
    "                            found = False\n",
    "                            for obj_str, obj in sampled_world['obj_map'].items():\n",
    "                                if obj.size == distractor_size:\n",
    "                                    found = True\n",
    "                                    break\n",
    "                            if found:\n",
    "                                continue\n",
    "                        elif color == \"\" and shape != \"object\":\n",
    "                            found = False\n",
    "                            for obj_str, obj in sampled_world['obj_map'].items():\n",
    "                                if obj.shape == shape:\n",
    "                                    if obj.size == distractor_size:\n",
    "                                        found = True\n",
    "                                        break\n",
    "                            if found:\n",
    "                                continue\n",
    "                            \n",
    "                        distractor_obj_map[new_obj_name] = tmp_name\n",
    "                        distractor_obj_pattern_map[new_obj_name] = obj_grammer\n",
    "                        distractor_size_map[new_obj_name] = distractor_size\n",
    "                        base_distractor_count += 1\n",
    "        return [{\n",
    "            \"grammer_pattern\" : self.snap_pattern_to_referent_map(\n",
    "                distractor_grammer_pattern,\n",
    "                obj_base_count\n",
    "            ),\n",
    "            \"obj_pattern_map\" : self.snap_object_map_to_referent_map(\n",
    "                distractor_obj_pattern_map,\n",
    "                obj_base_count\n",
    "            ),\n",
    "            \"rel_map\" : self.snap_relation_map_to_referent_map(\n",
    "                distractor_rel_map,\n",
    "                obj_base_count\n",
    "            ),\n",
    "            \"obj_map\" : self.snap_object_map_to_referent_map(\n",
    "                distractor_obj_map,\n",
    "                obj_base_count\n",
    "            ),\n",
    "            \"size_map\" : self.snap_object_map_to_referent_map(\n",
    "                distractor_size_map,\n",
    "                obj_base_count\n",
    "            ),\n",
    "            \"distractor_metadata\" : [distractor_metadata]\n",
    "        }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passing rate = 100/10000\n",
      "passing rate = 200/10000\n",
      "passing rate = 300/10000\n",
      "passing rate = 400/10000\n",
      "passing rate = 500/10000\n",
      "passing rate = 600/10000\n",
      "passing rate = 700/10000\n",
      "passing rate = 800/10000\n",
      "passing rate = 900/10000\n",
      "passing rate = 1000/10000\n",
      "passing rate = 1100/10000\n",
      "passing rate = 1200/10000\n",
      "passing rate = 1300/10000\n",
      "passing rate = 1400/10000\n",
      "passing rate = 1500/10000\n",
      "passing rate = 1600/10000\n",
      "passing rate = 1700/10000\n",
      "passing rate = 1800/10000\n",
      "passing rate = 1900/10000\n",
      "passing rate = 2000/10000\n",
      "passing rate = 2100/10000\n",
      "passing rate = 2200/10000\n",
      "passing rate = 2300/10000\n",
      "passing rate = 2400/10000\n",
      "passing rate = 2500/10000\n",
      "passing rate = 2600/10000\n",
      "passing rate = 2700/10000\n",
      "passing rate = 2800/10000\n",
      "passing rate = 2900/10000\n",
      "passing rate = 3000/10000\n",
      "passing rate = 3100/10000\n",
      "passing rate = 3200/10000\n",
      "passing rate = 3300/10000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Sample larger than population or is negative",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-2fe4888a6610>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0minclude_random_distractor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mfull_relation_probability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# 0.5 seems to work as well!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         )\n",
      "\u001b[0;32m<ipython-input-18-a2c9396dfd9f>\u001b[0m in \u001b[0;36msample_situations_from_grounded_grammer\u001b[0;34m(self, grammer_pattern, obj_pattern_map, rel_map, obj_map, root, is_plot, include_random_distractor, include_relation_distractor, include_attribute_distractor, include_isomorphism_distractor, full_relation_probability, debug)\u001b[0m\n\u001b[1;32m    762\u001b[0m                     \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m                     \u001b[0mspecial_shape_size_bound\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspecial_shape_size_bound\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m                     \u001b[0mmentioned_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmentioned_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m                     \u001b[0;31m# This is needed as maybe distractors also\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m                     \u001b[0;31m# need to be bounded by global constraints.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-a2c9396dfd9f>\u001b[0m in \u001b[0;36mplace_distractor_from_dict\u001b[0;34m(self, distractors_dict, obj_placed_map, obj_position_map, debug, special_shape_size_bound, mentioned_shapes)\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0msampled_dis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistractor_root\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                 \u001b[0mdis_grammer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistractors_rel_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m                 \u001b[0mobj_placed_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_position_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m             )\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-a2c9396dfd9f>\u001b[0m in \u001b[0;36msample_object_position\u001b[0;34m(self, sampled_obj, root, obj_grammer, rel_map, obj_placed_map, obj_position_map, retry_max)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0mobj_random_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_world\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                 \u001b[0mobj_random_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_world\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_position_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj_random_pos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/user/wuzhengx/workspace/Reason-SCAN/code/dataset/world.py\u001b[0m in \u001b[0;36msample_position_box\u001b[0;34m(self, box_size)\u001b[0m\n\u001b[1;32m    379\u001b[0m                                                                             list(range(self.grid_size-box_size+1)))\n\u001b[1;32m    380\u001b[0m                                if (col, row) not in self._occupied_positions]\n\u001b[0;32m--> 381\u001b[0;31m         \u001b[0msampled_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavailable_positions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mPosition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampled_position\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampled_position\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/random.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, population, k)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sample larger than population or is negative\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0msetsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m21\u001b[0m        \u001b[0;31m# size of a small set minus size of an empty list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Sample larger than population or is negative"
     ]
    }
   ],
   "source": [
    "# Simulator robustness tests.\n",
    "# random.shuffle(command_structs)\n",
    "simulator = Simulator(\n",
    "    object_vocabulary, vocabulary, \n",
    "    grid_size=6, \n",
    "    n_object_max=10,\n",
    ")\n",
    "count = 0\n",
    "for test_struct in command_structs[:10000]:\n",
    "    count += 1\n",
    "    if count%100==0:\n",
    "        print(f\"passing rate = {count}/{10000}\")\n",
    "    obj_pattern_map = test_struct[\"obj_pattern_map\"]\n",
    "    rel_map = test_struct[\"rel_map\"]\n",
    "    obj_map = test_struct[\"obj_map\"]\n",
    "    grammer_pattern = test_struct[\"grammer_pattern\"]\n",
    "    verb = test_struct[\"verb\"]\n",
    "    adverb = test_struct[\"adverb\"]\n",
    "\n",
    "    test_unique_find = 0\n",
    "    for i in range(200):\n",
    "        sampled_world = simulator.sample_situations_from_grounded_grammer(\n",
    "            copy.deepcopy(grammer_pattern), \n",
    "            copy.deepcopy(obj_pattern_map), \n",
    "            copy.deepcopy(rel_map), \n",
    "            copy.deepcopy(obj_map),\n",
    "            is_plot=False,\n",
    "            include_relation_distractor=True, \n",
    "            include_attribute_distractor=True, \n",
    "            include_isomorphism_distractor=True, \n",
    "            include_random_distractor=True,\n",
    "            full_relation_probability=0.5, # 0.5 seems to work as well!\n",
    "            debug=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'obj_pattern_map': {'$OBJ_0': '$SHAPE',\n",
       "  '$OBJ_1': '$SHAPE',\n",
       "  '$OBJ_2': '$SIZE $COLOR $SHAPE'},\n",
       " 'rel_map': OrderedDict([(('$OBJ_0', '$OBJ_1'), '$SAME_SIZE'),\n",
       "              (('$OBJ_0', '$OBJ_2'), '$IS_INSIDE')]),\n",
       " 'obj_map': {'$OBJ_0': 'square',\n",
       "  '$OBJ_1': 'circle',\n",
       "  '$OBJ_2': 'big green box'},\n",
       " 'grammer_pattern': '$OBJ_0 ^ $OBJ_1 & $OBJ_2',\n",
       " 'adverb': 'hesitantly',\n",
       " 'verb': 'push'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sample larger than population or is negative",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-968852ff46c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0minclude_random_distractor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mfull_relation_probability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# 0.5 seems to work as well!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         )\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-a2c9396dfd9f>\u001b[0m in \u001b[0;36msample_situations_from_grounded_grammer\u001b[0;34m(self, grammer_pattern, obj_pattern_map, rel_map, obj_map, root, is_plot, include_random_distractor, include_relation_distractor, include_attribute_distractor, include_isomorphism_distractor, full_relation_probability, debug)\u001b[0m\n\u001b[1;32m    762\u001b[0m                     \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m                     \u001b[0mspecial_shape_size_bound\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspecial_shape_size_bound\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m                     \u001b[0mmentioned_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmentioned_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m                     \u001b[0;31m# This is needed as maybe distractors also\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m                     \u001b[0;31m# need to be bounded by global constraints.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-a2c9396dfd9f>\u001b[0m in \u001b[0;36mplace_distractor_from_dict\u001b[0;34m(self, distractors_dict, obj_placed_map, obj_position_map, debug, special_shape_size_bound, mentioned_shapes)\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0msampled_dis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistractor_root\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                 \u001b[0mdis_grammer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistractors_rel_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m                 \u001b[0mobj_placed_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_position_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m             )\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-a2c9396dfd9f>\u001b[0m in \u001b[0;36msample_object_position\u001b[0;34m(self, sampled_obj, root, obj_grammer, rel_map, obj_placed_map, obj_position_map, retry_max)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0mobj_random_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_world\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                 \u001b[0mobj_random_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_world\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_position_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj_random_pos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/user/wuzhengx/workspace/Reason-SCAN/code/dataset/world.py\u001b[0m in \u001b[0;36msample_position_box\u001b[0;34m(self, box_size)\u001b[0m\n\u001b[1;32m    379\u001b[0m                                                                             list(range(self.grid_size-box_size+1)))\n\u001b[1;32m    380\u001b[0m                                if (col, row) not in self._occupied_positions]\n\u001b[0;32m--> 381\u001b[0;31m         \u001b[0msampled_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavailable_positions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mPosition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampled_position\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampled_position\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/random.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, population, k)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sample larger than population or is negative\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0msetsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m21\u001b[0m        \u001b[0;31m# size of a small set minus size of an empty list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Sample larger than population or is negative"
     ]
    }
   ],
   "source": [
    "test_struct = {'obj_pattern_map': {'$OBJ_0': '$SHAPE',\n",
    "  '$OBJ_1': '$SHAPE',\n",
    "  '$OBJ_2': '$SIZE $COLOR $SHAPE'},\n",
    " 'rel_map': OrderedDict([(('$OBJ_0', '$OBJ_1'), '$SAME_SIZE'),\n",
    "              (('$OBJ_0', '$OBJ_2'), '$IS_INSIDE')]),\n",
    " 'obj_map': {'$OBJ_0': 'square',\n",
    "  '$OBJ_1': 'circle',\n",
    "  '$OBJ_2': 'big green box'},\n",
    " 'grammer_pattern': '$OBJ_0 ^ $OBJ_1 & $OBJ_2',\n",
    " 'adverb': 'hesitantly',\n",
    " 'verb': 'push'}\n",
    "\n",
    "simulator = Simulator(\n",
    "    object_vocabulary, vocabulary, \n",
    "    grid_size=6, \n",
    "    n_object_max=10,\n",
    ")\n",
    "\n",
    "obj_pattern_map = test_struct[\"obj_pattern_map\"]\n",
    "rel_map = test_struct[\"rel_map\"]\n",
    "obj_map = test_struct[\"obj_map\"]\n",
    "grammer_pattern = test_struct[\"grammer_pattern\"]\n",
    "verb = test_struct[\"verb\"]\n",
    "adverb = test_struct[\"adverb\"]\n",
    "\n",
    "test_unique_find = 0\n",
    "for i in range(20000):\n",
    "    sampled_world = simulator.sample_situations_from_grounded_grammer(\n",
    "            copy.deepcopy(grammer_pattern), \n",
    "            copy.deepcopy(obj_pattern_map), \n",
    "            copy.deepcopy(rel_map), \n",
    "            copy.deepcopy(obj_map),\n",
    "            is_plot=False,\n",
    "            include_relation_distractor=True, \n",
    "            include_attribute_distractor=True, \n",
    "            include_isomorphism_distractor=True, \n",
    "            include_random_distractor=True,\n",
    "            full_relation_probability=0.5, # 0.5 seems to work as well!\n",
    "            debug=False\n",
    "        )\n",
    "    \n",
    "    continue\n",
    "    \n",
    "    graph = ReaSCANGraph(\n",
    "        objects=sampled_world[\"obj_map\"], \n",
    "        object_patterns=sampled_world[\"obj_pattern_map\"], \n",
    "        vocabulary=vocabulary,\n",
    "        positions=sampled_world[\"pos_map\"], \n",
    "        referred_object=sampled_world[\"referred_obj\"],\n",
    "        debug=False\n",
    "    )\n",
    "\n",
    "    pattern_graph = ReaSCANGraph(\n",
    "        objects=obj_map, \n",
    "        object_patterns=None,\n",
    "        vocabulary=vocabulary,\n",
    "        relations=rel_map, \n",
    "        referred_object='$OBJ_0', \n",
    "        debug=False\n",
    "    )\n",
    "\n",
    "    potential_referent_target = graph.find_referred_object(\n",
    "        pattern_graph, referred_object='$OBJ_0', \n",
    "        debug=False\n",
    "    )\n",
    "\n",
    "    if len(potential_referent_target) == 1:\n",
    "        print(f\"{test_unique_find+1} / {i+1} unique solution find!\")\n",
    "        test_unique_find += 1\n",
    "        \n",
    "        simulator._world.render_simple()\n",
    "        \n",
    "        obj_determiner_map = graph.find_determiners(\n",
    "            pattern_graph, \n",
    "            referred_object='$OBJ_0', \n",
    "            debug=False,\n",
    "        )\n",
    "        \n",
    "        command_str = grammer.repre_str_command(\n",
    "            grammer_pattern, rel_map, obj_map, \n",
    "            obj_determiner_map, \n",
    "            verb,\n",
    "            adverb,\n",
    "        )\n",
    "        \n",
    "        # Get the target command\n",
    "        is_transitive = False\n",
    "        if verb in simulator.vocabulary.get_transitive_verbs():\n",
    "            is_transitive = True\n",
    "        \n",
    "        # Direct walk.\n",
    "        action = \"walk\" # this is definit!\n",
    "        primitive_command = simulator.vocabulary.translate_word(action)\n",
    "        target_position = sampled_world[\"situation\"].target_object.position\n",
    "\n",
    "        simulator._world.go_to_position(\n",
    "            position=target_position, manner=adverb, \n",
    "            primitive_command=primitive_command\n",
    "        )\n",
    "\n",
    "        # Object actions.\n",
    "        if is_transitive:\n",
    "            semantic_action = simulator.vocabulary.translate_word(verb)\n",
    "            simulator._world.move_object_to_wall(action=semantic_action, manner=adverb)\n",
    "        target_commands, _ = simulator._world.get_current_observations()\n",
    "        \n",
    "        task_struct = OrderedDict({\n",
    "            \"command\": \",\".join(command_str.split(\" \")),\n",
    "            \"meaning\": \",\".join(command_str.split(\" \")),\n",
    "            \"derivation\": grammer_pattern,\n",
    "            \"situation\": sampled_world[\"situation\"].to_representation(),\n",
    "            \"target_commands\": \",\".join(target_commands),\n",
    "            \"verb_in_command\": verb,\n",
    "            \"adverb_in_command\": adverb,\n",
    "            \"referred_target\": obj_map[\"$OBJ_0\"],\n",
    "            \"object_pattern_map\": obj_pattern_map,\n",
    "            \"relation_map\": rel_map,\n",
    "            \"object_expression\": obj_map,\n",
    "            \"n_object\": len(sampled_world[\"obj_map\"]),\n",
    "            \"n_distractor\": len(sampled_world[\"obj_map\"])-len(obj_map),\n",
    "            \"full_relation_distractor\": True if len(sampled_world[\"distractor_switch_map\"][\"relation\"]) == len(rel_map) else False,\n",
    "            \"has_relation_distractor\": True if len(sampled_world[\"distractor_switch_map\"][\"relation\"]) > 0 else False,\n",
    "            \"has_attribute_distractor\": sampled_world[\"distractor_switch_map\"][\"attribute\"],\n",
    "            \"has_isomorphism_distractor\": sampled_world[\"distractor_switch_map\"][\"isomorphism\"],\n",
    "            \"has_random_distractor\": True if sampled_world[\"n_random_distractor\"] != -1 else False,\n",
    "            \"n_random_distractor\": sampled_world[\"n_random_distractor\"] if sampled_world[\"n_random_distractor\"] != -1 else 0,\n",
    "            \"relation_distractor_metadata\": sampled_world[\"relation_distractor_metadata\"],\n",
    "            \"attribute_distractor_metadata\": sampled_world[\"attribute_distractor_metadata\"],\n",
    "            \"isomorphism_distractor_metadata\": sampled_world[\"isomorphism_distractor_metadata\"],\n",
    "            \"random_distractor_metadata\": sampled_world[\"random_distractor_metadata\"],\n",
    "        })\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

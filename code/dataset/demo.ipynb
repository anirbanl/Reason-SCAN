{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple, OrderedDict\n",
    "import itertools\n",
    "import os\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "from typing import List\n",
    "from typing import Dict\n",
    "import random\n",
    "from itertools import product\n",
    "import copy\n",
    "import re\n",
    "import random\n",
    "\n",
    "from utils import one_hot\n",
    "from utils import generate_possible_object_names\n",
    "from utils import numpy_array_to_image\n",
    "\n",
    "from vocabulary import *\n",
    "from object_vocabulary import *\n",
    "from world import *\n",
    "from grammer import *\n",
    "from simulator import *\n",
    "from relation_graph import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test out the vocabulary\n",
    "intransitive_verbs = [\"walk\"]\n",
    "transitive_verbs = [\"push\", \"pull\"]\n",
    "adverbs = [\"while zigzagging\", \"while spinning\", \"cautiously\", \"hesitantly\"]\n",
    "nouns = [\"circle\", \"cylinder\", \"square\", \"box\"]\n",
    "color_adjectives = [\"red\", \"blue\", \"green\", \"yellow\"]\n",
    "size_adjectives = [\"big\", \"small\"]\n",
    "relative_pronouns = [\"that is\"]\n",
    "relation_clauses = [\"in the same row as\", \n",
    "                    \"in the same column as\", \n",
    "                    \"in the same color as\", \n",
    "                    \"in the same shape as\", \n",
    "                    \"in the same size as\",\n",
    "                    \"inside of\"]\n",
    "vocabulary = Vocabulary.initialize(intransitive_verbs=intransitive_verbs,\n",
    "                                   transitive_verbs=transitive_verbs, adverbs=adverbs, nouns=nouns,\n",
    "                                   color_adjectives=color_adjectives,\n",
    "                                   size_adjectives=size_adjectives, \n",
    "                                   relative_pronouns=relative_pronouns, \n",
    "                                   relation_clauses=relation_clauses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test out the object vocab\n",
    "min_object_size = 1\n",
    "max_object_size = 4\n",
    "object_vocabulary = ObjectVocabulary(shapes=vocabulary.get_semantic_shapes(),\n",
    "                                     colors=vocabulary.get_semantic_colors(),\n",
    "                                     min_size=min_object_size, max_size=max_object_size)\n",
    "# object_vocabulary.generate_objects()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Situtation Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test out situation repr\n",
    "TEST_SITUATION_1 = Situation(grid_size=15, agent_position=Position(row=7, column=2), agent_direction=INT_TO_DIR[0],\n",
    "                             target_object=PositionedObject(object=Object(size=2, color='red', shape='circle'),\n",
    "                                                            position=Position(row=10, column=4),\n",
    "                                                            vector=np.array([1, 0, 1])),\n",
    "                             placed_objects=[PositionedObject(object=Object(size=2, color='red', shape='circle'),\n",
    "                                                              position=Position(row=10, column=4),\n",
    "                                                              vector=np.array([1, 0, 1])),\n",
    "                                             PositionedObject(object=Object(size=4, color='green', shape='circle'),\n",
    "                                                              position=Position(row=3, column=12),\n",
    "                                                              vector=np.array([0, 1, 0]))], carrying=None)\n",
    "# TEST_SITUATION_1.to_representation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PositionedObject(object=Object(size=4, color='green', shape='box'), position=Position(column=12, row=3), vector=array([0, 1, 0]), overflow=True, overlap=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test out our new object definition\n",
    "PositionedObject(object=Object(size=4, color='green', shape='box'),\n",
    "                 position=Position(row=3, column=12),\n",
    "                 vector=np.array([0, 1, 0]), overflow=True, overlap=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### World Module with Mini-Gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOsAAADrCAYAAACICmHVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAEbElEQVR4nO3dMW4cZRiA4R2UiipFaNJQukwR9xwDX2CVC9BbrklDvReg4gB09GlS0xhROqKkoRiKiGDCGu/Ga2bemeeRLEvesfVppVff7/FqPYzjuAHm77OpBwAOI1aIECtEiBUixAoRYoWIJ8dc/PkwjE8faxJW6/nLl1OPMBvX19ebd+/eDfseOyrWp5vN5tVJRoK/Xb55M/UIs3F+fn7nY47BECFWiDjqGLzPpZcr/sN2u93sdrupx5iFq2Hvr158IpsVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChHziPWnN+8/gDs9+D2YTurjYL+6+20ZYW3msVmBe807Vsdj+GBex+C7OB7DzDfrXWxcVqixWe9yO1jbloVrx3qbcFm45jEYVmg5m/U2W5YFWmastwmXhVh+rLcJl7D1/s7qTz/ErDdWiFnXMdjRl7B1xCpSFmCZsYqTBVpWrCJlwZYRq0hZAXeDIaK5WW1SVqgTq0BZuXnHKlD4YH6xChT2mk+sIoX/5G4wRMwjVlsV7jWPWIF7iRUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiBArRAzjOB588fNhGF999LXLI75/aV68vph6BBbm5+9+3Pz+62/DvsdsVogQK0SIFSLEChEPfpPv7XZ7ijmazqYegDV5cKy73e4UcyS5G8z/yTEYIsQKEWKFiPn8F7kFe/vN91OPMImrYe8Lcf7Fq+AOY7NChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0Q8eegPuBqGU8zR9O3XB1226ueIk7FZIUKsECFWiBArRDz4BhM81Ha7nXqE6ZwdfqnNChE2K5Pb7XZTjzCZF68vDr7WZoUIsULEUcfgP54921ze3DzWLDk/HHiEuRzHR56k46+bSWs++n4qmxUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsEPFk6gHW4MXri6lHmI+z9588J8ezWSFCrBAhVogQK0QM4zgefvEw3Gw2m18ebxxYvS/Hcfxi3wNHxQpMxzEYIsQKEWKFCLFChFghQqwQIVaIECtEiBUi/gRR2WglxlSTcgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test out the world\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import os\n",
    "os.environ['QT_QPA_PLATFORM']='offscreen'\n",
    "\n",
    "world = World(grid_size=3, colors=vocabulary.get_semantic_colors(),\n",
    "              object_vocabulary=object_vocabulary,\n",
    "              shapes=vocabulary.get_semantic_shapes(),\n",
    "              save_directory=\"./tmp/\")\n",
    "\n",
    "world.place_object(Object(size=2, color=\"green\", shape=\"box\"), position=Position(row=1, column=1))\n",
    "world.place_object(Object(size=2, color=\"red\", shape=\"box\"), position=Position(row=0, column=0))\n",
    "_ = world.render_simple()\n",
    "world.position_taken(position=Position(row=0, column=0), condition=\"box\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "world = World(grid_size=6, colors=vocabulary.get_semantic_colors(),\n",
    "              object_vocabulary=object_vocabulary,\n",
    "              shapes=vocabulary.get_semantic_shapes(),\n",
    "              save_directory=\"./tmp/\")\n",
    "\n",
    "# try to place an object on to the map\n",
    "world.clear_situation()\n",
    "# world.place_object(Object(size=4, color=\"green\", shape=\"box\"), position=Position(row=3, column=3))\n",
    "world.place_object(Object(size=2, color=\"green\", shape=\"box\"), position=Position(row=2, column=2))\n",
    "world.place_object(Object(size=2, color=\"green\", shape=\"box\"), position=Position(row=1, column=1))\n",
    "world.place_object(Object(size=3, color=\"red\", shape=\"cylinder\"), position=Position(row=3, column=2))\n",
    "world.place_agent_at(Position(row=5, column=2))\n",
    "\n",
    "_ = world.render_simple()\n",
    "\n",
    "verb = \"push\"\n",
    "adverb = \"cautiously\"\n",
    "\n",
    "# Direct walk.\n",
    "action = \"walk\" # this is definit!\n",
    "primitive_command = vocabulary.translate_word(action)\n",
    "target_position = Position(row=3, column=2)\n",
    "# simulator._world.get_current_situation().to_dict()[\"target_object\"].position\n",
    "world.go_to_position(position=target_position, manner=adverb, primitive_command=primitive_command)\n",
    "\n",
    "# Object actions.\n",
    "if True:\n",
    "    semantic_action = vocabulary.translate_word(verb)\n",
    "    world.move_object_to_wall(action=semantic_action, manner=adverb)\n",
    "target_commands, target_demonstration = world.get_current_observations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = world.render_simple()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReaSCAN Grammer Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['push', 'pull', 'walk']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammer = Grammer(vocabulary)\n",
    "vocabulary.get_transitive_verbs() + vocabulary.get_intransitive_verbs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammer_pattern = '$OBJ_0 ^ $OBJ_1 & $OBJ_2'\n",
    "\n",
    "relations = grammer.sample_object_relation_grammer(\n",
    "    '$OBJ_0', \n",
    "    grammer.build_dependency_graph(grammer_pattern))\n",
    "\n",
    "command_structs = []\n",
    "for relation in relations:\n",
    "    obj_pattern_map = relation[0]\n",
    "    rel_map = relation[1]\n",
    "    grammer_bindings = grammer.grounding_grammer_with_vocabulary(grammer_pattern, obj_pattern_map, rel_map)\n",
    "    for obj_map in grammer_bindings:\n",
    "        # here, we also sample the verb and adverb bindings!\n",
    "        \n",
    "        command_struct = {\n",
    "            \"obj_pattern_map\" : obj_pattern_map,\n",
    "            \"rel_map\" : rel_map,\n",
    "            \"obj_map\" : obj_map,\n",
    "            \"grammer_pattern\" : grammer_pattern,\n",
    "            \"adverb\" : random.choice(vocabulary.get_adverbs()),\n",
    "            \"verb\" : random.choice(vocabulary.get_transitive_verbs() + vocabulary.get_intransitive_verbs()),\n",
    "        }\n",
    "        command_structs += [command_struct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# command_struct_stats = get_command_struct_statistics(command_structs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReaSCAN Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = Simulator(\n",
    "    object_vocabulary, vocabulary, \n",
    "    grid_size=6, \n",
    "    n_object_max=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_pattern_map = {'$OBJ_0': '$ABS_SHAPE', '$OBJ_1': '$SHAPE', '$OBJ_2': '$SHAPE'}\n",
    "rel_map = {('$OBJ_0', '$OBJ_1'): '$SAME_SHAPE', ('$OBJ_0', '$OBJ_2'): '$IS_INSIDE'}\n",
    "obj_map = {'$OBJ_0': 'object', '$OBJ_1': 'circle', '$OBJ_2': 'box'}\n",
    "grammer_pattern = '$OBJ_0 ^ $OBJ_1 & $OBJ_2'\n",
    "verb = \"push\"\n",
    "adverb = \"slowly\"\n",
    "sampled_world = simulator.sample_situations_from_grounded_grammer(\n",
    "    copy.deepcopy(grammer_pattern), \n",
    "    copy.deepcopy(obj_pattern_map), \n",
    "    copy.deepcopy(rel_map), \n",
    "    copy.deepcopy(obj_map),\n",
    "    is_plot=True,\n",
    "    include_relation_distractor=False, \n",
    "    include_attribute_distractor=False, \n",
    "    include_isomorphism_distractor=False, \n",
    "    include_random_distractor=False,\n",
    "    full_relation_probability=0.5,\n",
    "    debug=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_transitive = False\n",
    "if verb in simulator.vocabulary.get_transitive_verbs():\n",
    "    is_transitive = True\n",
    "\n",
    "# Direct walk.\n",
    "action = \"walk\" # this is definit!\n",
    "primitive_command = simulator.vocabulary.translate_word(action)\n",
    "target_position = sampled_world[\"situation\"].target_object.position\n",
    "\n",
    "simulator._world.go_to_position(position=target_position, manner=adverb, primitive_command=primitive_command)\n",
    "\n",
    "# Object actions.\n",
    "if is_transitive:\n",
    "    semantic_action = simulator.vocabulary.translate_word(verb)\n",
    "    simulator._world.move_object_to_wall(action=semantic_action, manner=adverb)\n",
    "target_commands, target_demonstration = simulator._world.get_current_observations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End-to-end Task Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulator(object):\n",
    "    \"\"\"\n",
    "    This convert generated grammers into a world/situation.\n",
    "    \n",
    "    Sample Situation:\n",
    "    Situation(grid_size=15, agent_position=Position(row=7, column=2), agent_direction=INT_TO_DIR[0],\n",
    "              target_object=PositionedObject(object=Object(size=2, color='red', shape='circle'),\n",
    "                                             position=Position(row=10, column=4),\n",
    "                                             vector=np.array([1, 0, 1])),\n",
    "              placed_objects=[PositionedObject(object=Object(size=2, color='red', shape='circle'),\n",
    "                                               position=Position(row=10, column=4),\n",
    "                                               vector=np.array([1, 0, 1])),\n",
    "                              PositionedObject(object=Object(size=4, color='green', shape='circle'),\n",
    "                                               position=Position(row=3, column=12),\n",
    "                                               vector=np.array([0, 1, 0]))], carrying=None)\n",
    "                                               \n",
    "    Sample Placement in the World:\n",
    "    world.place_object(Object(size=2, color=\"green\", shape=\"box\"), position=Position(row=2, column=2))\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, object_vocabulary, vocabulary, grid_size=6, \n",
    "                 n_object_min=6,\n",
    "                 n_object_max=12,\n",
    "                 save_directory=\"./tmp/\"):\n",
    "        self.object_vocabulary = object_vocabulary\n",
    "        self.vocabulary = vocabulary\n",
    "        self.grid_size = grid_size\n",
    "        self.n_object_min = n_object_min\n",
    "        self.n_object_max = n_object_max\n",
    "\n",
    "        self._world = World(grid_size=grid_size, colors=vocabulary.get_semantic_colors(),\n",
    "                            object_vocabulary=object_vocabulary,\n",
    "                            shapes=vocabulary.get_semantic_shapes(),\n",
    "                            save_directory=save_directory)\n",
    "        self._world.clear_situation()\n",
    "    \n",
    "    def sample_object_shape(\n",
    "        self, obj_grammer, obj_pattern, obj_str, rel_map, \n",
    "        is_root, shape_map\n",
    "    ):\n",
    "        obj_pattern = obj_pattern.split(\" \")\n",
    "        obj_str = obj_str.split(\" \")\n",
    "        shape = None\n",
    "        if len(obj_str) == 3:\n",
    "            shape = obj_str[2]\n",
    "        elif len(obj_str) == 2:\n",
    "            shape = obj_str[1]\n",
    "        elif len(obj_str) == 1:\n",
    "            # it must be the object\n",
    "            shape = obj_str[0]\n",
    "        # Final handling for the shape.\n",
    "        if shape == \"object\":\n",
    "            shape = self.object_vocabulary.sample_shape()\n",
    "            \n",
    "        # Override size, color and shape based on relations.\n",
    "        if not is_root:\n",
    "            # Go through the rel.\n",
    "            for pair, rel in rel_map.items():\n",
    "                if obj_grammer == pair[-1]:\n",
    "                    if pair[0] in shape_map.keys():\n",
    "                        # if this obj is acting as a child node\n",
    "                        # then have to complain with parent node\n",
    "                        if rel == \"$SAME_SHAPE\":\n",
    "                            shape = shape_map[pair[0]]\n",
    "                        elif rel == \"$IS_INSIDE\":\n",
    "                            shape = \"box\"\n",
    "        return shape\n",
    "    \n",
    "    def sample_object_spec(\n",
    "        self, obj_grammer, obj_pattern, obj_str, rel_map, \n",
    "        is_root, obj_placed_map, \n",
    "        size_restriction_map=None,\n",
    "        mentioned_shapes=None\n",
    "    ):\n",
    "        obj_pattern = obj_pattern.split(\" \")\n",
    "        obj_str = obj_str.split(\" \")\n",
    "        color = None\n",
    "        size = None\n",
    "        shape = None\n",
    "        if len(obj_str) == 3:\n",
    "            size = self.object_vocabulary.sample_size_with_prior(prior=obj_str[0])\n",
    "            color = obj_str[1]\n",
    "            shape = obj_str[2]\n",
    "        elif len(obj_str) == 2:\n",
    "            if \"$COLOR\" in obj_pattern: # color + shape.\n",
    "                size = self.object_vocabulary.sample_size()\n",
    "                color = obj_str[0]\n",
    "                shape = obj_str[1]\n",
    "            elif \"$SIZE\" in obj_pattern: # size + shape.\n",
    "                size = self.object_vocabulary.sample_size_with_prior(prior=obj_str[0])\n",
    "                color = self.object_vocabulary.sample_color()\n",
    "                shape = obj_str[1]\n",
    "        elif len(obj_str) == 1:\n",
    "            # it must be the object\n",
    "            size = self.object_vocabulary.sample_size()\n",
    "            color = self.object_vocabulary.sample_color()\n",
    "            shape = obj_str[0]\n",
    "        # Final handling for the shape.\n",
    "        if shape == \"object\":\n",
    "            # WARNING: this is a corner case you will hit\n",
    "            # if your logic chain is long, you may need to\n",
    "            # consider remove object option!\n",
    "            if mentioned_shapes != None and len(mentioned_shapes) == self.object_vocabulary._shapes:\n",
    "                assert False\n",
    "            if is_root:\n",
    "                shape = self.object_vocabulary.sample_shape() # _exclude=mentioned_shapes\n",
    "            else:\n",
    "                shape = self.object_vocabulary.sample_shape()\n",
    "                \n",
    "        return Object(color=color,size=size,shape=shape)\n",
    "                    \n",
    "    def sample_object_position(\n",
    "        self, sampled_obj, root, obj_grammer, \n",
    "        rel_map, obj_placed_map, \n",
    "        obj_position_map\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Return:\n",
    "        -1: No position can be sampled.\n",
    "        \"\"\"\n",
    "        # If it is the first node, we directly return.\n",
    "        if sampled_obj.shape != \"box\":\n",
    "            obj_random_pos = self._world.sample_position_complex(\n",
    "                condition=\"normal\", sample_one=True\n",
    "            )\n",
    "        else:\n",
    "            obj_random_pos = self._world.sample_position_complex(\n",
    "                condition=\"box\", box_size=sampled_obj.size, sample_one=True\n",
    "            )\n",
    "        if obj_grammer == root:\n",
    "            return obj_random_pos # for this round, the root node can be placed anywhere!\n",
    "        \n",
    "        # For some relations, we might need to resample positions!\n",
    "        for pair, rel in rel_map.items():\n",
    "            if obj_grammer == pair[-1]:\n",
    "                if not pair[0] in obj_placed_map.keys():\n",
    "                    assert False # this should never be the case! the position sampling in from top to bottom!\n",
    "\n",
    "                # if this obj is acting as a child node\n",
    "                # then have to complain with parent node\n",
    "                if rel == \"$SAME_ROW\":\n",
    "                    row = obj_position_map[pair[0]].row\n",
    "                    for i in range(0, self.grid_size):\n",
    "                        proposed_position = Position(row=row, column=i)\n",
    "                        if not self._world.position_taken(proposed_position, condition=\"normal\"):\n",
    "                            return proposed_position\n",
    "                    return -1 # too many objs\n",
    "                if rel == \"$SAME_COLUMN\":\n",
    "                    col = obj_position_map[pair[0]].column\n",
    "                    for i in range(0, self.grid_size):\n",
    "                        proposed_position = Position(row=i, column=col)\n",
    "                        if not self._world.position_taken(proposed_position, condition=\"normal\"):\n",
    "                            return proposed_position\n",
    "                    return -1 # too many objs\n",
    "                elif rel == \"$IS_INSIDE\":\n",
    "                    # we need to make sure enclosure\n",
    "                    assert sampled_obj.shape == \"box\"\n",
    "                    size = sampled_obj.size\n",
    "                    potential_positions = []\n",
    "                    row = obj_position_map[pair[0]].row\n",
    "                    col = obj_position_map[pair[0]].column\n",
    "                    for i in range(0, self.grid_size-size+1):\n",
    "                        for j in range(0, self.grid_size-size+1):\n",
    "                            # we need to cover the is inside obj\n",
    "                            if row >= i and row < i + sampled_obj.size and \\\n",
    "                                col >= j and col < j + sampled_obj.size:\n",
    "                                proposed_position = Position(row=i, column=j)\n",
    "                                if not self._world.position_taken(proposed_position, condition=\"box\"):\n",
    "                                    potential_positions.append(Position(row=i, column=j))\n",
    "                    random.shuffle(potential_positions)\n",
    "                    if len(potential_positions) < 1:\n",
    "                        return -1\n",
    "                    return potential_positions[0]\n",
    "\n",
    "        return obj_random_pos\n",
    "    \n",
    "    def sample_random_object_spec(\n",
    "        self, \n",
    "        size_exclude=None, \n",
    "        color_exclude=None, shape_exclude=None\n",
    "    ):\n",
    "        d_size = self.object_vocabulary.sample_size(_exclude=size_exclude)\n",
    "        d_color = self.object_vocabulary.sample_color(_exclude=color_exclude)\n",
    "        d_shape = self.object_vocabulary.sample_shape(_exclude=shape_exclude)\n",
    "        return Object(color=d_color,size=d_size,shape=d_shape)\n",
    "    \n",
    "    def place_distractor_from_dict(\n",
    "        self, distractors_dict, \n",
    "        obj_placed_map, obj_position_map, \n",
    "        debug=False, \n",
    "        special_shape_size_bound=None,\n",
    "        mentioned_shapes=None,\n",
    "    ):\n",
    "        if debug:\n",
    "            import pprint\n",
    "            pp = pprint.PrettyPrinter(indent=4)\n",
    "            pp.pprint(distractors_dict)\n",
    "        distractor_root = f\"$OBJ_{len(obj_placed_map)}\"\n",
    "        success = True\n",
    "        distractors_obj_map = distractors_dict[\"obj_map\"]\n",
    "        distractors_rel_map = distractors_dict[\"rel_map\"]\n",
    "        distractors_obj_pattern_map = distractors_dict[\"obj_pattern_map\"]\n",
    "        distractors_size_map = distractors_dict[\"size_map\"]\n",
    "        \n",
    "        distractors_sampled_obj_map = {}\n",
    "        for dis_grammer, dis_str in distractors_obj_map.items():\n",
    "            # 1. Sample object.\n",
    "            sampled_dis = self.sample_object_spec(\n",
    "                dis_grammer,\n",
    "                distractors_obj_pattern_map[dis_grammer], \n",
    "                dis_str, distractors_rel_map, \n",
    "                is_root=dis_grammer==distractor_root, \n",
    "                obj_placed_map=obj_placed_map,\n",
    "                mentioned_shapes=mentioned_shapes,\n",
    "            )\n",
    "            # 1.1. Update the size of the object if needed.\n",
    "            if dis_grammer in distractors_size_map.keys():\n",
    "                sampled_dis = Object(\n",
    "                    color=sampled_dis.color,\n",
    "                    size=distractors_size_map[dis_grammer],\n",
    "                    shape=sampled_dis.shape\n",
    "                )\n",
    "            # 1.2. Another pass of override by using global constraints.\n",
    "            special_shape_super = sampled_dis.shape\n",
    "            special_shape_sub = sampled_dis.color + \" \" + sampled_dis.shape\n",
    "            # e.g., small circle exists in the command, then any colored circle needs to be constrain\n",
    "            if special_shape_super in special_shape_size_bound.keys():\n",
    "                if \"small\" in dis_str:\n",
    "                    updated_size = special_shape_size_bound[special_shape_super][0]\n",
    "                else:\n",
    "                    updated_size = special_shape_size_bound[special_shape_super][1]\n",
    "                sampled_dis = Object(\n",
    "                    color=sampled_dis.color,\n",
    "                    size=updated_size,\n",
    "                    shape=sampled_dis.shape\n",
    "                )\n",
    "            elif special_shape_sub in special_shape_size_bound.keys():\n",
    "                if \"small\" in dis_str:\n",
    "                    updated_size = special_shape_size_bound[special_shape_sub][0]\n",
    "                else:\n",
    "                    updated_size = special_shape_size_bound[special_shape_sub][1]\n",
    "                sampled_dis = Object(\n",
    "                    color=sampled_dis.color,\n",
    "                    size=updated_size,\n",
    "                    shape=sampled_dis.shape\n",
    "                )\n",
    "            else:\n",
    "                pass # Do nothing.\n",
    "            distractors_sampled_obj_map[dis_grammer] = sampled_dis\n",
    "        \n",
    "        # 2. Update it using relationships.\n",
    "        for pair, rel in distractors_rel_map.items():\n",
    "            if rel == \"$SAME_SHAPE\":\n",
    "                pass\n",
    "            elif rel == \"$SAME_COLOR\":\n",
    "                pass\n",
    "            elif rel == \"$SAME_SIZE\":\n",
    "                # Update the src node size information.\n",
    "                size = distractors_sampled_obj_map[pair[1]].size\n",
    "                distractors_sampled_obj_map[pair[0]] = Object(\n",
    "                    color=distractors_sampled_obj_map[pair[0]].color,\n",
    "                    size=size,\n",
    "                    shape=distractors_sampled_obj_map[pair[0]].shape\n",
    "                )\n",
    "            elif rel == \"$IS_INSIDE\":\n",
    "                pass # Do nothing!\n",
    "\n",
    "        placed_dis_grammer = []\n",
    "        for dis_grammer, sampled_dis in distractors_sampled_obj_map.items():\n",
    "            # 2. Place on the world map.\n",
    "            sampled_pos = self.sample_object_position(\n",
    "                sampled_dis, distractor_root, \n",
    "                dis_grammer, distractors_rel_map, \n",
    "                obj_placed_map, obj_position_map\n",
    "            )\n",
    "\n",
    "            if sampled_dis == -1 or sampled_pos == -1:\n",
    "                # We allow partial placement as they add difficulties!\n",
    "                return False\n",
    "\n",
    "            return_code = self._world.place_object(\n",
    "                sampled_dis, \n",
    "                position=sampled_pos, target=False # Distractor is never the target!\n",
    "            )\n",
    "            if return_code == -1:\n",
    "                assert False # Due to our design, this should never happen!\n",
    "            obj_placed_map[dis_grammer] = sampled_dis\n",
    "            obj_position_map[dis_grammer] = sampled_pos\n",
    "            \n",
    "        return True\n",
    "    \n",
    "    def sample_situations_from_grounded_grammer(\n",
    "        self, grammer_pattern, \n",
    "        obj_pattern_map, rel_map, obj_map, root=\"$OBJ_0\", \n",
    "        is_plot=False, \n",
    "        include_random_distractor=False, \n",
    "        include_relation_distractor=False, \n",
    "        include_attribute_distractor=False, \n",
    "        include_isomorphism_distractor=False, \n",
    "        full_relation_probability=0.5,\n",
    "        debug=False,\n",
    "    ):\n",
    "        # Clear current world.\n",
    "        self._world.clear_situation()\n",
    "        \n",
    "        # Start placing objects with specs.\n",
    "        obj_placed_map = OrderedDict({})\n",
    "        obj_position_map = OrderedDict({})\n",
    "        referred_obj = root\n",
    "        \n",
    "        # Preliminary size check!\n",
    "        \"\"\"\n",
    "        Here is a list of potential internal conflicts:\n",
    "        (1) ... to a small box ... to a yellow box ...\n",
    "        Explain: we need to adjust the size of two boxes\n",
    "        so that small box has 1 size, and all other boxes \n",
    "        have the same other size.\n",
    "        There will at max two different size of same type objects.\n",
    "        \n",
    "        So this is the rule:\n",
    "        For 1 type of shape, max two different sizes.\n",
    "        \"\"\"\n",
    "        # Ok, we need to determine shapes first!\n",
    "        # Even there is any abstract object, the\n",
    "        # shape is now determined.\n",
    "        object_map = {}\n",
    "        mentioned_shapes = set([]) # this is used to sample shapes for object.\n",
    "        for obj_grammer, obj_str in obj_map.items():\n",
    "            shape = self.extract_shape(obj_str)\n",
    "            if shape != \"\":\n",
    "                mentioned_shapes.add(shape)\n",
    "        for obj_grammer, obj_str in obj_map.items():\n",
    "            # 1. Sample object.\n",
    "            sampled_obj = self.sample_object_spec(\n",
    "                obj_grammer,\n",
    "                obj_pattern_map[obj_grammer], obj_str, rel_map, \n",
    "                is_root=obj_grammer==root, \n",
    "                obj_placed_map=object_map,\n",
    "                mentioned_shapes=mentioned_shapes,\n",
    "            )\n",
    "            object_map[obj_grammer] = sampled_obj\n",
    "        \n",
    "        # Next, we update all of them based on relations.\n",
    "        # Final pass, we need to change attributes of objects based\n",
    "        # on relations.\n",
    "        # Here, we only change size!\n",
    "        for pair, rel in rel_map.items():\n",
    "            if rel == \"$SAME_SHAPE\":\n",
    "                # Update the src node shape information.\n",
    "                shape = object_map[pair[1]].shape\n",
    "                object_map[pair[0]] = Object(\n",
    "                    color=object_map[pair[0]].color,\n",
    "                    size=object_map[pair[0]].size,\n",
    "                    shape=shape\n",
    "                )\n",
    "                pass\n",
    "            elif rel == \"$SAME_COLOR\":\n",
    "                # Update the src node color information.\n",
    "                color = object_map[pair[1]].color\n",
    "                object_map[pair[0]] = Object(\n",
    "                    color=color,\n",
    "                    size=object_map[pair[0]].size,\n",
    "                    shape=object_map[pair[0]].shape\n",
    "                )\n",
    "                pass\n",
    "            elif rel == \"$SAME_SIZE\":\n",
    "                # Update the src node size information.\n",
    "                size = object_map[pair[1]].size\n",
    "                object_map[pair[0]] = Object(\n",
    "                    color=object_map[pair[0]].color,\n",
    "                    size=size,\n",
    "                    shape=object_map[pair[0]].shape\n",
    "                )\n",
    "            elif rel == \"$IS_INSIDE\":\n",
    "                pass\n",
    "            \n",
    "        # Then, we will determine size bounds.\n",
    "        special_shape_size_bound = {}\n",
    "        for obj_grammer, obj_pattern in obj_pattern_map.items():\n",
    "            \n",
    "            small_size = random.randint(\n",
    "                self.object_vocabulary._min_size, \n",
    "                self.object_vocabulary._max_size-1\n",
    "            )\n",
    "            big_size = random.randint(\n",
    "                small_size+1, \n",
    "                self.object_vocabulary._max_size\n",
    "            )\n",
    "            \n",
    "            if \"$SIZE\" in obj_pattern and \"$COLOR\" in obj_pattern:\n",
    "                special_shape = object_map[obj_grammer].color + \" \" + object_map[obj_grammer].shape\n",
    "                if object_map[obj_grammer].shape in special_shape_size_bound.keys():\n",
    "                    # e.g., small circle exists\n",
    "                    special_shape_size_bound[special_shape] = special_shape_size_bound[object_map[obj_grammer].shape]\n",
    "                else:\n",
    "                    # e.g., small yellow circle\n",
    "                    special_shape_size_bound[special_shape] = [small_size, big_size]\n",
    "            elif \"$SIZE\" in obj_pattern and not \"$COLOR\" in obj_pattern:\n",
    "                # e.g., small circle\n",
    "                # overwrite any existing bounds.\n",
    "                special_shape = object_map[obj_grammer].shape\n",
    "                for ss, bound in special_shape_size_bound.items():\n",
    "                    if special_shape in ss:\n",
    "                        special_shape_size_bound[ss] = [small_size, big_size]\n",
    "                # for shape, it adds.\n",
    "                special_shape_size_bound[special_shape] = [small_size, big_size]\n",
    "                # for non-sized shape, it also adds as long as shape is the same.\n",
    "                for obj_grammer, obj_pattern in obj_pattern_map.items():\n",
    "                    if special_shape in obj_map[obj_grammer]:\n",
    "                        if \"$COLOR\" in obj_pattern:\n",
    "                            special_shape = object_map[obj_grammer].color + \" \" + object_map[obj_grammer].shape\n",
    "                            special_shape_size_bound[special_shape] = [small_size, big_size]\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        # Update object size based on global scanning results.\n",
    "        updated_object_map = {}\n",
    "        for obj_grammer, obj_pattern in obj_pattern_map.items():\n",
    "\n",
    "            special_shape_super = object_map[obj_grammer].shape\n",
    "            special_shape_sub = object_map[obj_grammer].color + \" \" + object_map[obj_grammer].shape\n",
    "            \n",
    "            # e.g., small circle exists in the command, then any colored circle needs to be constrain\n",
    "            if special_shape_super in special_shape_size_bound.keys():\n",
    "                if \"small\" in obj_map[obj_grammer]:\n",
    "                    updated_size = special_shape_size_bound[special_shape_super][0]\n",
    "                else:\n",
    "                    updated_size = special_shape_size_bound[special_shape_super][1]\n",
    "                updated_object_map[obj_grammer] = Object(\n",
    "                    color=object_map[obj_grammer].color,\n",
    "                    size=updated_size,\n",
    "                    shape=object_map[obj_grammer].shape\n",
    "                )\n",
    "            elif special_shape_sub in special_shape_size_bound.keys():\n",
    "                if \"small\" in obj_map[obj_grammer]:\n",
    "                    updated_size = special_shape_size_bound[special_shape_sub][0]\n",
    "                else:\n",
    "                    updated_size = special_shape_size_bound[special_shape_sub][1]\n",
    "                updated_object_map[obj_grammer] = Object(\n",
    "                    color=object_map[obj_grammer].color,\n",
    "                    size=updated_size,\n",
    "                    shape=object_map[obj_grammer].shape\n",
    "                )\n",
    "            else:\n",
    "                # If nothing exists in the special size map, then we don't need\n",
    "                # to alter the size.\n",
    "                updated_object_map[obj_grammer] = object_map[obj_grammer]\n",
    "\n",
    "        # Final pass, we need to change attributes of objects based\n",
    "        # on relations.\n",
    "        # Here, we only change size!\n",
    "        for pair, rel in rel_map.items():\n",
    "            if rel == \"$SAME_SHAPE\":\n",
    "                pass\n",
    "            elif rel == \"$SAME_COLOR\":\n",
    "                pass\n",
    "            elif rel == \"$SAME_SIZE\":\n",
    "                # Update the src node size information.\n",
    "                size = updated_object_map[pair[1]].size\n",
    "                updated_object_map[pair[0]] = Object(\n",
    "                    color=object_map[pair[0]].color,\n",
    "                    size=size,\n",
    "                    shape=object_map[pair[0]].shape\n",
    "                )\n",
    "            elif rel == \"$IS_INSIDE\":\n",
    "                pass\n",
    "        \n",
    "        # Next, we sample positions of all objects and place them.\n",
    "        for obj_grammer, obj_str in obj_map.items():\n",
    "            # 1. Sample object (bu fetching the updated one).\n",
    "            sampled_obj = updated_object_map[obj_grammer]\n",
    "            \n",
    "            # 2. Place on the world map.\n",
    "            sampled_pos = self.sample_object_position(\n",
    "                sampled_obj, root, obj_grammer, rel_map, \n",
    "                obj_placed_map, obj_position_map\n",
    "            )\n",
    "            \n",
    "            if sampled_obj == -1 or sampled_pos == -1:\n",
    "                assert False # we can assert false as it is impossible!\n",
    "        \n",
    "            self._world.place_object(\n",
    "                sampled_obj, \n",
    "                position=sampled_pos, target=obj_grammer==root\n",
    "            )\n",
    "            obj_placed_map[obj_grammer] = sampled_obj\n",
    "            obj_position_map[obj_grammer] = sampled_pos\n",
    "            \n",
    "        \"\"\"\n",
    "        Distractor Sampling Strategies and Design\n",
    "        \n",
    "        Giving a complex command as:\n",
    "        \"the small red circle(1) that is in the same row(a) \n",
    "        as a big green square(2) and that is in the same column(b) \n",
    "        as a small yellow cylinder(3).\"\n",
    "        \n",
    "        We have 4 types of distractors (objects):\n",
    "        - Attribute-based Distractors\n",
    "        - Relation-based Distractors\n",
    "        - Sytax-based Distractors\n",
    "        - Random Distractors\n",
    "        \n",
    "        For each type of distractors, we will modify the command\n",
    "        to generate a new command for distractors. Then, we will\n",
    "        ensure such every command-world pair needs to reason about\n",
    "        attribute, relation and syntax. \n",
    "        \n",
    "        There are some caveats around this design. Due to the \n",
    "        complexity of the command, to make sure\n",
    "        every attribute/relation is necessary becomes unfeasible. For\n",
    "        example, if we want to make \"small\" in \"the small red circle (1)\"\n",
    "        necessary, then, we need to put another non-\"small\" \"red circle\".\n",
    "        This is easy. However, if we want to make \"big\" in \"the big\n",
    "        green square\" necessary, we essentially need to sample another\n",
    "        set of objects (at max 3) that complies with a modified command\n",
    "        \"the small red circle(1) that is in the same row(a) \n",
    "        as a small green square(2*) and that is in the same column(b) \n",
    "        as a small yellow cylinder(3).\"\n",
    "        \n",
    "        Following this logic, if we want to make sure *every descriptor*\\\n",
    "        (i.e., every adjective) is necessary to identity the referent\n",
    "        target, we could flood the system easily with way too many\n",
    "        distractors that cannot fit in our grid world.\n",
    "        \n",
    "        On the other hand, the goal of having the distractors is to\n",
    "        have the system learn the importantce of relations, attributes\n",
    "        and linguistic syntax. So, are these distractors necessary?\n",
    "        Do we need to actually have an exhaustive list of distractors\n",
    "        for each command-world pair in order to have the model to learn\n",
    "        this? We propose the answer is No, but Yes in the dataset level. In\n",
    "        the command level, we will not make sure *every descriptor* is\n",
    "        necessary, but in the command level, we will make sure \n",
    "        *every descriptor* matters for at least some of the command.\n",
    "        Otherwise, the model may just completely ignores one part of\n",
    "        the command and relies on the rest.\n",
    "        \n",
    "        In our design, we ensure for each command-world pair, some attribute\n",
    "        and some relation and some syntax are needed. In the dataset\n",
    "        level, we ensure different attribute, relation and syntax are \n",
    "        weighted equally.\n",
    "        \n",
    "        We propose to sample distractors following the design below:\n",
    "        \n",
    "        For a command such as\n",
    "        \"A that is X B and that is Y C\"\n",
    "        (1) We generate two distractor commands: \"A that X B\"; and \"A that Y C\"\n",
    "        without guarantee all relations in the original command. This samples\n",
    "        4 distractors. This ensures X and Y are necessary!\n",
    "        \n",
    "        (2) Next, we need to ensure that if we change some descriptors for\n",
    "        A, B or C, referent target cannot be identified. For example, if\n",
    "        we change B from \"yellow square\" to \"blue square\" the referent target\n",
    "        should change. In this case, we need to sample a new set of {A,B,C}.\n",
    "        And if we do this for each object, this results in 9 new distractors.\n",
    "        If size is not selected, we potentially need 3 more distractors to\n",
    "        ground the size aspects.\n",
    "        \n",
    "        (3) Next, to ensure model learns linguistic syntax, instead of simple\n",
    "        BoW approach to represent the command, we would perform swap attributes\n",
    "        between objects. We pick a pair of objects, and swap attributes \n",
    "        randomly. This results in 3 more distractors.\n",
    "        \n",
    "        (1) + (2) + (3) results in at max 19 distractors for each command-world pair.\n",
    "        Plus the original 3 objects, we have in total 21 distractors.\n",
    "        This is still a lot higher than gSCAN which is at max about 12.\n",
    "        \n",
    "        Then, we design another way to sample distractors:\n",
    "        (1) We pick 1 relations from {X, Y}, and generate distracotrs: 3 distractors.\n",
    "        \n",
    "        (2) We pick 1 object from {A, B, C} and modify its attribute, sample 3 distractors.\n",
    "        if size is not selected for any object, we need to randomly sample non-relational\n",
    "        counterparts, at max 3.\n",
    "        \n",
    "        (3) Same, so 3.\n",
    "        \n",
    "        (1) + (2) + (3) results in 3 + 3 + 3 + 3 = 12, 12 + 3 -> at max 15. Is this doable?\n",
    "        \n",
    "        Test set. global v.s. local compositional generalization. In the test set, we \n",
    "        can pick different/more aspect of differeent/more obj that matter for the\n",
    "        correctly reasonings, and generate test cases with  more distractors.\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        Calling in this way to create distractors:\n",
    "\n",
    "        simulator.sample_distractor_grammer_by_relation(\n",
    "            grammer_pattern, \n",
    "            obj_pattern_map, \n",
    "            rel_map, \n",
    "            obj_map, \n",
    "            sampled_world\n",
    "        )\n",
    "        \"\"\"\n",
    "        temp_sampled_world = {\n",
    "            \"obj_map\" : obj_placed_map,\n",
    "            \"pos_map\" : obj_position_map,\n",
    "            \"referred_obj\" : referred_obj,\n",
    "            \"situation\" : copy.deepcopy(self._world.get_current_situation())\n",
    "        }\n",
    "        \n",
    "        # Three types of distractor sampling for different purposes:\n",
    "        # sample_distractor_grammer_by_relation()\n",
    "        # - We will edit one leaf node, so that it makes sure\n",
    "        #   the command is necessary!\n",
    "        # sample_distractor_grammer_by_size()\n",
    "        # - Size relatives need to be meaningful. We will add relational\n",
    "        #   objects to make sure.\n",
    "        # sample_distractor_grammer_by_isomorphism()\n",
    "        # - This is to ensure syntax learning.\n",
    "        \n",
    "        distractor_switch_map = OrderedDict({\n",
    "            \"relation\" : [],\n",
    "            \"attribute\" : False,\n",
    "            \"isomorphism\" : False, \n",
    "            \"random\" : False,\n",
    "        })\n",
    "        relation_distractors_dicts = [{\n",
    "            \"distractor_metadata\": {}\n",
    "        }]\n",
    "        attribute_distractors_dicts = [{\n",
    "            \"distractor_metadata\": {}\n",
    "        }]\n",
    "        isomorphism_distractors_dicts = [{\n",
    "            \"distractor_metadata\": {}\n",
    "        }]\n",
    "        \n",
    "        if random.random() < full_relation_probability:\n",
    "            full_relation_set=True\n",
    "        else:\n",
    "            full_relation_set=False\n",
    "            \n",
    "        obj_drafted_count = len(obj_placed_map)\n",
    "        if include_relation_distractor:\n",
    "            \"\"\"\n",
    "            Relation Distractors: Count=3*n, at max 6.\n",
    "            Relation Distractors (fast): Count=2*n, at max 4.\n",
    "            \"\"\"\n",
    "            relation_distractors_dicts = self.sample_distractor_grammer_by_relation_fast(\n",
    "                grammer_pattern, \n",
    "                obj_pattern_map, \n",
    "                rel_map, \n",
    "                obj_map, \n",
    "                temp_sampled_world,\n",
    "                obj_base_count=len(obj_placed_map),\n",
    "                full_set=full_relation_set,\n",
    "            )\n",
    "            if len(relation_distractors_dicts) == 0:\n",
    "                pass # Size distractor is not applicable \n",
    "            else:\n",
    "                distractor_switch = []\n",
    "                is_full_relation = True\n",
    "                for distractors_dict in relation_distractors_dicts:\n",
    "                    obj_drafted_count += len(distractors_dict[\"obj_map\"])\n",
    "                    succeed = self.place_distractor_from_dict(\n",
    "                        distractors_dict, \n",
    "                        obj_placed_map, \n",
    "                        obj_position_map,\n",
    "                        debug=debug,\n",
    "                        special_shape_size_bound=special_shape_size_bound,\n",
    "                        mentioned_shapes=mentioned_shapes,\n",
    "                        # This is needed as maybe distractors also \n",
    "                        # need to be bounded by global constraints.\n",
    "                    )\n",
    "                    if succeed:\n",
    "                        distractor_switch_map[\"relation\"].append(True)\n",
    "                    else:\n",
    "                        distractor_switch_map[\"relation\"].append(False)\n",
    "\n",
    "        if include_attribute_distractor:\n",
    "            \"\"\"\n",
    "            Attribution Distractors: Count=3-6.\n",
    "            \"\"\"\n",
    "            # If the command is small, we can overwrite this\n",
    "            if len(rel_map) <= 1:\n",
    "                full_set = True\n",
    "            else:\n",
    "                full_set = not full_relation_set\n",
    "            attribute_distractors_dicts = self.sample_distractor_grammer_by_attribute(\n",
    "                grammer_pattern, \n",
    "                obj_pattern_map, \n",
    "                rel_map, \n",
    "                obj_map, \n",
    "                temp_sampled_world,\n",
    "                special_shape_size_bound,\n",
    "                obj_base_count=obj_drafted_count, # This is important, as previous draft may success but placement can fail!\n",
    "                full_set=full_set,\n",
    "            )\n",
    "            if len(attribute_distractors_dicts) == 0:\n",
    "                pass # Size distractor is not applicable \n",
    "            else:\n",
    "                obj_drafted_count += len(attribute_distractors_dicts[0][\"obj_map\"])\n",
    "                succeed = self.place_distractor_from_dict(\n",
    "                    attribute_distractors_dicts[0], \n",
    "                    obj_placed_map, \n",
    "                    obj_position_map,\n",
    "                    debug=debug,\n",
    "                    special_shape_size_bound=special_shape_size_bound,\n",
    "                    mentioned_shapes=mentioned_shapes,\n",
    "                    # This is needed as maybe distractors also \n",
    "                    # need to be bounded by global constraints.\n",
    "                )\n",
    "                if succeed:\n",
    "                    distractor_switch_map[\"attribute\"] = True # If one time it is true, it is true.\n",
    "                else:\n",
    "                    pass\n",
    "        \n",
    "        if include_isomorphism_distractor:\n",
    "            \"\"\"\n",
    "            Syntax Distractors: Count=3.\n",
    "            \"\"\"\n",
    "            isomorphism_distractors_dicts = self.sample_distractor_grammer_by_isomorphism(\n",
    "                grammer_pattern, \n",
    "                obj_pattern_map, \n",
    "                rel_map, \n",
    "                obj_map, \n",
    "                temp_sampled_world,\n",
    "                obj_base_count=obj_drafted_count # This is important, as previous draft may success but placement can fail!\n",
    "            )\n",
    "            if len(isomorphism_distractors_dicts) == 0:\n",
    "                pass # Size distractor is not applicable \n",
    "            else:\n",
    "                obj_drafted_count += len(isomorphism_distractors_dicts[0][\"obj_map\"])\n",
    "                succeed = self.place_distractor_from_dict(\n",
    "                    isomorphism_distractors_dicts[0], \n",
    "                    obj_placed_map, \n",
    "                    obj_position_map,\n",
    "                    debug=debug,\n",
    "                    special_shape_size_bound=special_shape_size_bound,\n",
    "                    mentioned_shapes=mentioned_shapes,\n",
    "                    # This is needed as maybe distractors also \n",
    "                    # need to be bounded by global constraints.\n",
    "                )\n",
    "                if succeed:\n",
    "                    distractor_switch_map[\"isomorphism\"] = True\n",
    "        \n",
    "        # Probably never need this!\n",
    "        \"\"\"\n",
    "        Random Distractors.\n",
    "        \"\"\"\n",
    "        # Place random distractors. These are gSCAN like distractors\n",
    "        # which are often not very meaningful for testing agents language\n",
    "        # knowledge. We recommand always turn this off and use other\n",
    "        # relation-based distractor sampling strategies.\n",
    "        \n",
    "        random_distractor_metadata = {}\n",
    "        n_random_distractor = -1\n",
    "        if include_random_distractor:\n",
    "            if len(obj_placed_map) >= self.n_object_max or len(mentioned_shapes) == len(self.vocabulary.get_semantic_shapes())-1:\n",
    "                pass # Do nothing!\n",
    "            else:\n",
    "                n_distractor = min(4, self.n_object_max-len(obj_placed_map)) # at max 2 random, how about?\n",
    "                n_random_distractor = n_distractor\n",
    "                core_obj_count = obj_drafted_count\n",
    "                for i in range(0, n_distractor):\n",
    "                    distractor_idx = core_obj_count+i\n",
    "                    distractor_name = f\"$OBJ_{distractor_idx}\"\n",
    "                    \n",
    "                    # Let us only sample shapes that are not exist\n",
    "                    sampled_distractor = self.sample_random_object_spec(\n",
    "                        shape_exclude=list(mentioned_shapes)\n",
    "                    )\n",
    "                    \n",
    "                    # Ok, we need to consider global size constraint!\n",
    "                    special_shape_super = sampled_distractor.shape\n",
    "                    special_shape_sub = sampled_distractor.color + \" \" +sampled_distractor.shape\n",
    "\n",
    "                    # e.g., small circle exists in the command, then any colored circle needs to be constrain\n",
    "                    size_idx = -1\n",
    "                    if special_shape_super in special_shape_size_bound.keys():\n",
    "                        size_idx = random.randint(0,1)\n",
    "                        updated_size = special_shape_size_bound[special_shape_super][size_idx]\n",
    "                        sampled_distractor = Object(\n",
    "                            color=sampled_distractor.color,\n",
    "                            size=updated_size,\n",
    "                            shape=sampled_distractor.shape\n",
    "                        )\n",
    "                    elif special_shape_sub in special_shape_size_bound.keys():\n",
    "                        size_idx = random.randint(0,1)\n",
    "                        updated_size = special_shape_size_bound[special_shape_sub][size_idx]\n",
    "                        sampled_distractor = Object(\n",
    "                            color=sampled_distractor.color,\n",
    "                            size=updated_size,\n",
    "                            shape=sampled_distractor.shape\n",
    "                        )\n",
    "                    \n",
    "                    if sampled_distractor.shape == \"box\":\n",
    "                        sampled_dis_pos = self._world.sample_position_complex(\n",
    "                            condition=\"box\", box_size=sampled_distractor.size, sample_one=True\n",
    "                        )\n",
    "                    else:\n",
    "                        sampled_dis_pos = self._world.sample_position_complex(\n",
    "                            condition=\"normal\", sample_one=True\n",
    "                        )\n",
    "                    \n",
    "                    self._world.place_object(\n",
    "                        sampled_distractor, \n",
    "                        position=sampled_dis_pos, target=False\n",
    "                    )\n",
    "                    obj_placed_map[distractor_name] = sampled_distractor\n",
    "                    obj_position_map[distractor_name] = sampled_dis_pos\n",
    "                    size_str = \"\"\n",
    "                    if size_idx != -1:\n",
    "                        size_str = \"big\" if size_idx == 1 else \"small\"\n",
    "                    random_distractor_metadata[distractor_name] = \" \".join([\n",
    "                        size_str,\n",
    "                        sampled_distractor.color,\n",
    "                        sampled_distractor.shape\n",
    "                    ])\n",
    "                distractor_switch_map[\"random\"] = True\n",
    "\n",
    "        agent_position = self._world.sample_position_complex(\n",
    "                            condition=\"normal\", sample_one=True\n",
    "                        )\n",
    "        self._world.place_agent_at(agent_position)\n",
    "        if is_plot:\n",
    "            _ = self._world.render_simple()\n",
    "        \n",
    "        situation_snapshot = copy.deepcopy(self._world.get_current_situation())\n",
    "        \n",
    "        return {\n",
    "            \"obj_map\" : obj_placed_map,\n",
    "            \"pos_map\" : obj_position_map,\n",
    "            \"obj_pattern_map\" : obj_pattern_map,\n",
    "            \"referred_obj\" : referred_obj,\n",
    "            \"situation\" : situation_snapshot, \n",
    "            \"distractor_switch_map\" : distractor_switch_map,\n",
    "            \"relation_distractor_metadata\" : [\n",
    "                {\n",
    "                    \"distractor_metadata\": md[\"distractor_metadata\"],\n",
    "                    \"obj_map\": md[\"obj_map\"],\n",
    "                    \"rel_map\": md[\"rel_map\"],\n",
    "                } for md in relation_distractors_dicts\n",
    "            ],\n",
    "            \"attribute_distractor_metadata\" : [\n",
    "                {\n",
    "                    \"distractor_metadata\": md[\"distractor_metadata\"],\n",
    "                    \"obj_map\": md[\"obj_map\"],\n",
    "                    \"rel_map\": md[\"rel_map\"],\n",
    "                } for md in attribute_distractors_dicts\n",
    "            ],\n",
    "            \"isomorphism_distractor_metadata\" : [\n",
    "                {\n",
    "                    \"distractor_metadata\": md[\"distractor_metadata\"],\n",
    "                    \"obj_map\": md[\"obj_map\"],\n",
    "                    \"rel_map\": md[\"rel_map\"],\n",
    "                } for md in isomorphism_distractors_dicts\n",
    "            ],\n",
    "            \"random_distractor_metadata\" : [random_distractor_metadata],\n",
    "            \"n_random_distractor\" : n_random_distractor\n",
    "        }\n",
    "    \n",
    "    def get_action_list(\n",
    "        self,\n",
    "        verb=None,\n",
    "        adverb=None,\n",
    "    ):\n",
    "        pass\n",
    "    \n",
    "    def extract_size(self, obj_str):\n",
    "        obj_descriptors = obj_str.split(\" \")\n",
    "        for descriptor in obj_descriptors:\n",
    "            if descriptor in [\"small\", \"big\"]:\n",
    "                return descriptor\n",
    "        return \"\"\n",
    "\n",
    "    def extract_color(self, obj_str):\n",
    "        obj_descriptors = obj_str.split(\" \")\n",
    "        for descriptor in obj_descriptors:\n",
    "            if descriptor in self.object_vocabulary.object_colors:\n",
    "                return descriptor\n",
    "        return \"\"\n",
    "    \n",
    "    def extract_shape(self, obj_str):\n",
    "        obj_descriptors = obj_str.split(\" \")\n",
    "        for descriptor in obj_descriptors:\n",
    "            if descriptor in self.object_vocabulary.object_shapes:\n",
    "                return descriptor\n",
    "        return \"\"\n",
    "\n",
    "    def convert_object_str_to_grammer(self, obj_str):\n",
    "        size_g = False\n",
    "        color_g = False\n",
    "        abs_shape_g = False\n",
    "\n",
    "        obj_descriptors = obj_str.split(\" \")\n",
    "        for descriptor in obj_descriptors:\n",
    "            if descriptor in [\"small\", \"big\"]:\n",
    "                size_g = True\n",
    "            elif descriptor in self.object_vocabulary.object_colors:\n",
    "                color_g = True\n",
    "            elif descriptor in self.object_vocabulary.object_shapes:\n",
    "                pass\n",
    "            elif descriptor == \"object\":\n",
    "                abs_shape_g = True\n",
    "\n",
    "        grammer = []\n",
    "        if size_g:\n",
    "            grammer.append(\"$SIZE\")\n",
    "        if color_g:\n",
    "            grammer.append(\"$COLOR\")\n",
    "        if abs_shape_g:\n",
    "            grammer.append(\"$ABS_SHAPE\") # Mark as deprecated!\n",
    "        else:\n",
    "            grammer.append(\"$SHAPE\")\n",
    "        \n",
    "        return \" \".join(grammer)\n",
    "\n",
    "    def snap_pattern_to_referent_map(self, distractor_grammer_pattern, base_count):\n",
    "        distractor_grammer_pattern_snapped = []\n",
    "        for item in distractor_grammer_pattern.split(\" \"):\n",
    "            if item.startswith(\"$\"):\n",
    "                new_id = int(item.split(\"_\")[1])+base_count\n",
    "                distractor_grammer_pattern_snapped.append(f\"$OBJ_{new_id}\")\n",
    "            else:\n",
    "                distractor_grammer_pattern_snapped.append(item)\n",
    "        return \" \".join(distractor_grammer_pattern_snapped)\n",
    "\n",
    "    def snap_object_map_to_referent_map(self, distractor_map, base_count):\n",
    "        distractor_map_snapped = OrderedDict({})\n",
    "        for obj_name, item in distractor_map.items():\n",
    "            new_id = int(obj_name.split(\"_\")[1])+base_count\n",
    "            new_obj_name = f\"$OBJ_{new_id}\"\n",
    "            distractor_map_snapped[new_obj_name] = item\n",
    "        return distractor_map_snapped\n",
    "\n",
    "    def snap_relation_map_to_referent_map(self, distractor_rel_map, base_count):\n",
    "        distractor_rel_map_snapped = OrderedDict({})\n",
    "        for edge, item in distractor_rel_map.items():\n",
    "            if edge[0].startswith(\"$\"):\n",
    "                new_id_left = int(edge[0].split(\"_\")[1])+base_count\n",
    "                new_obj_name_left = f\"$OBJ_{new_id_left}\"\n",
    "            else:\n",
    "                new_obj_name_left = edge[0]\n",
    "            \n",
    "            if edge[1].startswith(\"$\"):\n",
    "                new_id_right = int(edge[1].split(\"_\")[1])+base_count\n",
    "                new_obj_name_right = f\"$OBJ_{new_id_right}\"\n",
    "            else:\n",
    "                new_obj_name_right = edge[1]\n",
    "            distractor_rel_map_snapped[(new_obj_name_left, new_obj_name_right)] = item\n",
    "        return distractor_rel_map_snapped\n",
    "\n",
    "    def sample_distractor_grammer_by_relation_fast(\n",
    "        self, \n",
    "        referent_grammer_pattern, \n",
    "        referent_obj_pattern_map,\n",
    "        referent_rel_map,\n",
    "        referent_obj_map, \n",
    "        sampled_world,\n",
    "        obj_base_count=0,\n",
    "        full_set=True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        You can choose between two versions.\n",
    "        In this fast version, we only sample objects for the \n",
    "        selected edge.\n",
    "        \"\"\"\n",
    "        distractors_dicts = []\n",
    "        # We first collect all the relations\n",
    "        relation_edges = []\n",
    "        for edge, relation in referent_rel_map.items():\n",
    "            relation_edges.append(edge)\n",
    "        random.shuffle(relation_edges)\n",
    "        if full_set:\n",
    "            pass\n",
    "        else:\n",
    "            relation_edges = relation_edges[:1] # select only the first element.\n",
    "        \n",
    "        existing_relations = set([v for k, v in referent_rel_map.items()])\n",
    "\n",
    "        for selected_leaf_edge in relation_edges:\n",
    "\n",
    "            distractor_metadata = {\n",
    "                \"edge\" : selected_leaf_edge,\n",
    "                \"relation_old_type\" : referent_rel_map[selected_leaf_edge],\n",
    "                \"full_set\" : full_set,\n",
    "            }\n",
    "\n",
    "            distractor_size_map = {}\n",
    "            # First, let us make copies.\n",
    "            distractor_grammer_pattern = \"$OBJ_0 ^ $OBJ_1\"\n",
    "            distractor_obj_pattern_map = {}\n",
    "            node_left = selected_leaf_edge[0]\n",
    "            node_right = selected_leaf_edge[1]\n",
    "\n",
    "            distractor_obj_pattern_map[\"$OBJ_0\"] = referent_obj_pattern_map[node_left]\n",
    "            distractor_obj_pattern_map[\"$OBJ_1\"] = referent_obj_pattern_map[node_right]\n",
    "            distractor_rel_map = OrderedDict({})\n",
    "            distractor_rel_map[(\"$OBJ_0\", \"$OBJ_1\")] = referent_rel_map[selected_leaf_edge]\n",
    "            distractor_obj_map = {}\n",
    "            distractor_obj_map[\"$OBJ_0\"] = referent_obj_map[node_left]\n",
    "            distractor_obj_map[\"$OBJ_1\"] = referent_obj_map[node_right]\n",
    "            \n",
    "            # We need to increment the object counters.\n",
    "            distractors_dicts += [{\n",
    "                                    \"grammer_pattern\" : self.snap_pattern_to_referent_map(\n",
    "                                        distractor_grammer_pattern,\n",
    "                                        obj_base_count\n",
    "                                    ),\n",
    "                                    \"obj_pattern_map\" : self.snap_object_map_to_referent_map(\n",
    "                                        distractor_obj_pattern_map,\n",
    "                                        obj_base_count\n",
    "                                    ),\n",
    "                                    \"rel_map\" : self.snap_relation_map_to_referent_map(\n",
    "                                        distractor_rel_map,\n",
    "                                        obj_base_count\n",
    "                                    ),\n",
    "                                    \"obj_map\" : self.snap_object_map_to_referent_map(\n",
    "                                        distractor_obj_map,\n",
    "                                        obj_base_count\n",
    "                                    ),\n",
    "                                    \"size_map\" : self.snap_object_map_to_referent_map(\n",
    "                                        distractor_size_map,\n",
    "                                        obj_base_count\n",
    "                                    ),\n",
    "                                    \"distractor_metadata\" : distractor_metadata\n",
    "                                }]\n",
    "            obj_base_count += len(distractor_obj_pattern_map)\n",
    "\n",
    "        return distractors_dicts\n",
    "            \n",
    "            \n",
    "    def sample_distractor_grammer_by_relation(\n",
    "        self, \n",
    "        referent_grammer_pattern, \n",
    "        referent_obj_pattern_map,\n",
    "        referent_rel_map,\n",
    "        referent_obj_map, \n",
    "        sampled_world,\n",
    "        obj_base_count=0,\n",
    "        full_set=True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        This will select 1 relation mentioned in the command\n",
    "        and modify it to a new one. Then, sample distractors\n",
    "        based on that command (sampling step is outside of \n",
    "        this function). This function only construct the semantics\n",
    "        of distractors.\n",
    "        \"\"\"\n",
    "\n",
    "        distractors_dicts = []\n",
    "        # We first collect all the relations\n",
    "        relation_edges = []\n",
    "        for edge, relation in referent_rel_map.items():\n",
    "            relation_edges.append(edge)\n",
    "        random.shuffle(relation_edges)\n",
    "        if full_set:\n",
    "            pass\n",
    "        else:\n",
    "            relation_edges = relation_edges[:1] # select only the first element.\n",
    "        \n",
    "        existing_relations = set([v for k, v in referent_rel_map.items()])\n",
    "        # print(referent_rel_map)\n",
    "        for selected_leaf_edge in relation_edges:\n",
    "\n",
    "            # First, let us make copies.\n",
    "            distractor_grammer_pattern = copy.deepcopy(referent_grammer_pattern)\n",
    "            distractor_obj_pattern_map = copy.deepcopy(referent_obj_pattern_map)\n",
    "            distractor_rel_map = copy.deepcopy(referent_rel_map)\n",
    "            distractor_obj_map = copy.deepcopy(referent_obj_map)\n",
    "\n",
    "            # We may need to enforce the size of the distractor due to size descriptors!\n",
    "            distractor_size_map = {}\n",
    "        \n",
    "            selected_surgery = \"REL_ADJUST\" # Dummy\n",
    "\n",
    "            distractor_metadata = {\n",
    "                \"edge\" : selected_leaf_edge,\n",
    "                \"relation_old_type\" : distractor_rel_map[selected_leaf_edge]\n",
    "            }\n",
    "\n",
    "            if selected_surgery == \"REL_ADJUST\":\n",
    "                # Determine the new relation as not the same one as the current one.\n",
    "                new_rels = [\"$SAME_ROW\", \"$SAME_COLUMN\", \"$SAME_SHAPE\", \"$SAME_COLOR\", \"$SAME_SIZE\", \"$IS_INSIDE\"]\n",
    "                new_rels = set(new_rels) - existing_relations # make this very strict!\n",
    "                # There are something else do not make sense to sample!\n",
    "                # if \"$SIZE\" in distractor_obj_pattern_map[selected_leaf_edge[0]]:\n",
    "                #     new_rels -= set([\"$SAME_SIZE\"])\n",
    "                # if \"$COLOR\" in distractor_obj_pattern_map[selected_leaf_edge[0]]:\n",
    "                #     new_rels -= set([\"$SAME_COLOR\"])\n",
    "                # if \"$SHAPE\" in distractor_obj_pattern_map[selected_leaf_edge[0]]:\n",
    "                #    new_rels -= set([\"$SAME_SHAPE\"])\n",
    "                new_rel = random.choice(list(new_rels))\n",
    "                existing_relations.add(new_rel)\n",
    "                distractor_metadata[\"relation_new_type\"] = new_rel\n",
    "                distractor_rel_map[selected_leaf_edge] = new_rel\n",
    "                if new_rel == \"$IS_INSIDE\":\n",
    "                    # We can still try to keep the color and size the same.\n",
    "                    distractor_size_map[selected_leaf_edge[1]] = sampled_world[\"obj_map\"][selected_leaf_edge[1]].size\n",
    "                    distractor_obj_map[selected_leaf_edge[1]] = sampled_world[\"obj_map\"][selected_leaf_edge[1]].color + \" box\"\n",
    "                    distractor_obj_pattern_map[selected_leaf_edge[1]] = '$COLOR $SHAPE'\n",
    "                else:\n",
    "                    distractor_size_map[selected_leaf_edge[1]] = sampled_world[\"obj_map\"][selected_leaf_edge[1]].size\n",
    "                    if \"box\" in distractor_obj_map[selected_leaf_edge[1]]:\n",
    "                        # it used to box type object.\n",
    "                        distractor_size_map[selected_leaf_edge[1]] = sampled_world[\"obj_map\"][selected_leaf_edge[1]].size\n",
    "                        distractor_obj_map[selected_leaf_edge[1]] = sampled_world[\"obj_map\"][selected_leaf_edge[1]].color + \" object\"\n",
    "                        distractor_obj_pattern_map[selected_leaf_edge[1]] = '$COLOR $ABS_SHAPE'\n",
    "                    else:\n",
    "                        distractor_size_map[selected_leaf_edge[1]] = sampled_world[\"obj_map\"][selected_leaf_edge[1]].size\n",
    "                        distractor_obj_map[selected_leaf_edge[1]] = \\\n",
    "                            sampled_world[\"obj_map\"][selected_leaf_edge[1]].color + \" \" + \\\n",
    "                            sampled_world[\"obj_map\"][selected_leaf_edge[1]].shape\n",
    "                        distractor_obj_pattern_map[selected_leaf_edge[1]] = '$COLOR $SHAPE'\n",
    "            else:\n",
    "                assert False\n",
    "        \n",
    "            # We need to increment the object counters.\n",
    "            distractors_dicts += [{\n",
    "                                    \"grammer_pattern\" : self.snap_pattern_to_referent_map(\n",
    "                                        distractor_grammer_pattern,\n",
    "                                        obj_base_count\n",
    "                                    ),\n",
    "                                    \"obj_pattern_map\" : self.snap_object_map_to_referent_map(\n",
    "                                        distractor_obj_pattern_map,\n",
    "                                        obj_base_count\n",
    "                                    ),\n",
    "                                    \"rel_map\" : self.snap_relation_map_to_referent_map(\n",
    "                                        distractor_rel_map,\n",
    "                                        obj_base_count\n",
    "                                    ),\n",
    "                                    \"obj_map\" : self.snap_object_map_to_referent_map(\n",
    "                                        distractor_obj_map,\n",
    "                                        obj_base_count\n",
    "                                    ),\n",
    "                                    \"size_map\" : self.snap_object_map_to_referent_map(\n",
    "                                        distractor_size_map,\n",
    "                                        obj_base_count\n",
    "                                    ),\n",
    "                                    \"distractor_metadata\" : distractor_metadata\n",
    "                                }]\n",
    "            obj_base_count += len(distractor_obj_pattern_map)\n",
    "\n",
    "        return distractors_dicts\n",
    "\n",
    "    def sample_distractor_grammer_by_isomorphism(\n",
    "        self,\n",
    "        referent_grammer_pattern, \n",
    "        referent_obj_pattern_map,\n",
    "        referent_rel_map,\n",
    "        referent_obj_map, \n",
    "        sampled_world,\n",
    "        obj_base_count=0,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        This set of distractors are for learning syntax and grammers.\n",
    "        If you simply use BoW approach, it will not work because we \n",
    "        always instill confusing targets for you with isomorphism of the\n",
    "        referent graph.\n",
    "\n",
    "        For example, if the original grounded command is:\n",
    "        Go to the red square that is inside of the yellow box.\n",
    "\n",
    "        We can do a isomorphism which is\n",
    "        Go to the yellow square that is inside of the red box.\n",
    "\n",
    "        If the model is not understanding the language correctly,\n",
    "        it will not able to find the referent target correctly.\n",
    "        \"\"\"\n",
    "        # First, let us make copies.\n",
    "        distractor_grammer_pattern = copy.deepcopy(referent_grammer_pattern)\n",
    "        distractor_obj_pattern_map = copy.deepcopy(referent_obj_pattern_map)\n",
    "        distractor_rel_map = copy.deepcopy(referent_rel_map)\n",
    "        distractor_obj_map = copy.deepcopy(referent_obj_map)\n",
    "        # We may need to enforce the size of the distractor due to size descriptors!\n",
    "        distractor_size_map = {}\n",
    "\n",
    "        shufflable_objects = []\n",
    "        for obj_name, obj_str in distractor_obj_map.items():\n",
    "            if obj_name == \"$OBJ_0\":\n",
    "                continue # We need to sample distractors of object 0, thus, we keep it intact!\n",
    "            obj_descriptors = obj_str.split(\" \")\n",
    "            # if this is a box, we don't swap it\n",
    "            if \"box\" in obj_descriptors:\n",
    "                continue\n",
    "            if \"object\" in obj_descriptors:\n",
    "                # \"object\" itself is not shufflable!\n",
    "                if len(obj_descriptors) > 1:\n",
    "                    shufflable_objects.append((obj_name, obj_str))\n",
    "            else:\n",
    "                shufflable_objects.append((obj_name, obj_str))\n",
    "        if len(shufflable_objects) > 2:\n",
    "            random.shuffle(shufflable_objects)\n",
    "        shufflable_objects = shufflable_objects[:2]\n",
    "        \n",
    "        if len(shufflable_objects) == 1:\n",
    "            return [] # We simply don't have enough objects to do this.\n",
    "\n",
    "        # We will shuffle attributes between two objects.\n",
    "        # We actually shuffle by looking at their relations.\n",
    "        obj_name_left = shufflable_objects[0][0]\n",
    "        obj_name_right = shufflable_objects[1][0]\n",
    "        swap_color = True\n",
    "        swap_size = False # Let us stop swapping size for now.\n",
    "        swap_shape = True\n",
    "        if (obj_name_left, obj_name_right) in distractor_rel_map.keys() or \\\n",
    "            (obj_name_right, obj_name_left) in distractor_rel_map.keys():\n",
    "            if ((obj_name_left, obj_name_right) in distractor_rel_map.keys() and \\\n",
    "                    distractor_rel_map[(obj_name_left, obj_name_right)] == \"SameColor\") or \\\n",
    "                ((obj_name_right, obj_name_left) in distractor_rel_map.keys() and \\\n",
    "                     distractor_rel_map[(obj_name_right, obj_name_left)] == \"SameColor\"):\n",
    "                swap_color = False\n",
    "            elif ((obj_name_left, obj_name_right) in distractor_rel_map.keys() and \\\n",
    "                    distractor_rel_map[(obj_name_left, obj_name_right)] == \"SameSize\") or \\\n",
    "                ((obj_name_right, obj_name_left) in distractor_rel_map.keys() and \\\n",
    "                     distractor_rel_map[(obj_name_right, obj_name_left)] == \"SameSize\"):\n",
    "                swap_size = False\n",
    "            elif ((obj_name_left, obj_name_right) in distractor_rel_map.keys() and \\\n",
    "                    distractor_rel_map[(obj_name_left, obj_name_right)] == \"SameShape\") or \\\n",
    "                ((obj_name_right, obj_name_left) in distractor_rel_map.keys() and \\\n",
    "                     distractor_rel_map[(obj_name_right, obj_name_left)] == \"SameShape\"):\n",
    "                swap_shape = False\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        size_left = self.extract_size(shufflable_objects[0][1])\n",
    "        size_right = self.extract_size(shufflable_objects[1][1])\n",
    "        color_left = self.extract_color(shufflable_objects[0][1])\n",
    "        color_right = self.extract_color(shufflable_objects[1][1])\n",
    "        shape_left = self.extract_shape(shufflable_objects[0][1])\n",
    "        shape_right = self.extract_shape(shufflable_objects[1][1])\n",
    "        \n",
    "        if size_left == \"\" and size_right == \"\":\n",
    "            swap_size = False\n",
    "        if color_left == \"\" and color_right == \"\":\n",
    "            swap_color = False\n",
    "        if shape_left == \"\" and shape_right == \"\":\n",
    "            swap_shape = False\n",
    "        if shape_left == \"box\" or shape_right == \"box\":\n",
    "            swap_shape = False\n",
    "        \n",
    "        if not swap_color and not swap_size and not swap_shape:\n",
    "            return []\n",
    "        \n",
    "        swapping_attribute = []\n",
    "        if swap_color:\n",
    "            swapping_attribute += [\"color\"]\n",
    "        if swap_size and swap_shape:\n",
    "            swapping_attribute += [\"size+shape\"]\n",
    "        if not swap_size and swap_shape:\n",
    "            swapping_attribute += [\"size+shape\"]\n",
    "        swapping_attribute = random.choice(swapping_attribute)\n",
    "\n",
    "        left_rebuild = []\n",
    "        right_rebuild = []\n",
    "        \n",
    "        size_shuffled = False\n",
    "        color_shuffled = False\n",
    "        shape_shuffled = False\n",
    "        if swapping_attribute == \"color\":\n",
    "            tmp = color_left\n",
    "            color_left = color_right\n",
    "            color_right = tmp\n",
    "            color_shuffled = True\n",
    "        elif swapping_attribute == \"shape\":\n",
    "            tmp = shape_left\n",
    "            shape_left = shape_right\n",
    "            shape_right = tmp\n",
    "            shape_shuffled = True\n",
    "        elif swapping_attribute == \"size+shape\":\n",
    "            tmp = shape_left\n",
    "            shape_left = shape_right\n",
    "            shape_right = tmp\n",
    "            shape_shuffled = True\n",
    "            \n",
    "            tmp = size_left\n",
    "            size_left = size_right\n",
    "            size_right = tmp\n",
    "            size_shuffled = True\n",
    "            \n",
    "        # We don't swap size!\n",
    "        if size_left != \"\":\n",
    "            left_rebuild.append(size_left)\n",
    "        if size_right != \"\":\n",
    "            right_rebuild.append(size_right)\n",
    "            \n",
    "        if color_left != \"\":\n",
    "            left_rebuild.append(color_left)\n",
    "        if color_right != \"\":\n",
    "            right_rebuild.append(color_right)\n",
    "\n",
    "        if shape_left != \"\":\n",
    "            left_rebuild.append(shape_left)\n",
    "        else:\n",
    "            left_rebuild.append(\"object\")\n",
    "        if shape_right != \"\":\n",
    "            right_rebuild.append(shape_right)\n",
    "        else:\n",
    "            right_rebuild.append(\"object\")\n",
    "        \n",
    "        if not color_shuffled and not shape_shuffled:\n",
    "            return []\n",
    "                \n",
    "        left_rebuild = \" \".join(left_rebuild)\n",
    "        right_rebuild = \" \".join(right_rebuild)\n",
    "        left_grammer_rebuild = self.convert_object_str_to_grammer(left_rebuild)\n",
    "        right_grammer_rebuild = self.convert_object_str_to_grammer(right_rebuild)\n",
    "        \n",
    "        # It seems like it is possible with our case\n",
    "        # You need extra cautious of you want to extend for longer logics\n",
    "        # if left_rebuild == shufflable_objects[1][1] or right_rebuild == shufflable_objects[0][1]:\n",
    "        #     return [] # we don't allow complete swap!\n",
    "        \n",
    "        distractor_obj_pattern_map[obj_name_left] = left_grammer_rebuild \n",
    "        distractor_obj_pattern_map[obj_name_right] = right_grammer_rebuild \n",
    "        distractor_obj_map[obj_name_left] = left_rebuild\n",
    "        distractor_obj_map[obj_name_right] = right_rebuild\n",
    "        \n",
    "        distractor_metadata = {\n",
    "            \"swapped_pair\" : (obj_name_left, obj_name_right),\n",
    "            \"before_pair_obj_str\" : (shufflable_objects[0][1], shufflable_objects[1][1]),\n",
    "            \"after_pair_obj_str\" : (left_rebuild, right_rebuild),\n",
    "            \"size_shuffled\" : size_shuffled,\n",
    "            \"color_shuffled\" : color_shuffled,\n",
    "            \"shape_shuffled\" : shape_shuffled\n",
    "        }\n",
    "        \n",
    "        return [{\n",
    "                    \"grammer_pattern\" : self.snap_pattern_to_referent_map(\n",
    "                        distractor_grammer_pattern,\n",
    "                        obj_base_count\n",
    "                    ),\n",
    "                    \"obj_pattern_map\" : self.snap_object_map_to_referent_map(\n",
    "                        distractor_obj_pattern_map,\n",
    "                        obj_base_count\n",
    "                    ),\n",
    "                    \"rel_map\" : self.snap_relation_map_to_referent_map(\n",
    "                        distractor_rel_map,\n",
    "                        obj_base_count\n",
    "                    ),\n",
    "                    \"obj_map\" : self.snap_object_map_to_referent_map(\n",
    "                        distractor_obj_map,\n",
    "                        obj_base_count\n",
    "                    ),\n",
    "                    \"size_map\" : self.snap_object_map_to_referent_map(\n",
    "                        distractor_size_map,\n",
    "                        obj_base_count\n",
    "                    ),\n",
    "                    \"distractor_metadata\" : [distractor_metadata]\n",
    "                }]\n",
    "\n",
    "    def sample_distractor_grammer_by_attribute(\n",
    "        self,\n",
    "        referent_grammer_pattern, \n",
    "        referent_obj_pattern_map,\n",
    "        referent_rel_map,\n",
    "        referent_obj_map, \n",
    "        sampled_world,\n",
    "        special_shape_size_bound,\n",
    "        obj_base_count=0,\n",
    "        full_set=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        We randomly select 1 object and 1 attribute\n",
    "        that exists in the command to do the attack.\n",
    "        \n",
    "        Then, for all objects if size attribute exists\n",
    "        this function is also responsible for sampling\n",
    "        dummy size distractors!\n",
    "        \"\"\"\n",
    "        # First, let us make copies.\n",
    "        distractor_grammer_pattern = copy.deepcopy(referent_grammer_pattern)\n",
    "        distractor_obj_pattern_map = copy.deepcopy(referent_obj_pattern_map)\n",
    "        distractor_rel_map = copy.deepcopy(referent_rel_map)\n",
    "        distractor_obj_map = copy.deepcopy(referent_obj_map)\n",
    "        # We may need to enforce the size of the distractor due to size descriptors!\n",
    "        distractor_size_map = OrderedDict({})\n",
    "        sizing_covered = []\n",
    "        if full_set:\n",
    "            obj_pool = []\n",
    "            for obj_name, obj_grammer in referent_obj_pattern_map.items():\n",
    "                if \"$ABS_SHAPE\" in obj_grammer or \"box\" in distractor_obj_map[obj_name]:\n",
    "                    continue\n",
    "                obj_pool += [obj_name]\n",
    "            obj_selected = random.choice(obj_pool)\n",
    "            attribute_pool = referent_obj_pattern_map[obj_selected].split(\" \")\n",
    "            attribute_pool = list(set(attribute_pool)-set([\"$ABS_SHAPE\"]))\n",
    "            attribute_selected = random.choice(attribute_pool)\n",
    "\n",
    "            distractor_metadata = {\n",
    "                \"modified_obj\" : obj_selected,\n",
    "                \"modified_attribute\" : attribute_selected,\n",
    "            }\n",
    "\n",
    "            if attribute_selected == \"$SIZE\":\n",
    "                sizing_covered.append(obj_selected)\n",
    "                obj_name = obj_selected\n",
    "                original_object_str = distractor_obj_map[obj_name]\n",
    "                obj_grammer = distractor_obj_pattern_map[obj_name]\n",
    "                original_object = sampled_world['obj_map'][obj_name]\n",
    "                original_object_size = original_object.size\n",
    "                if \"$COLOR\" in obj_grammer:\n",
    "                    special_shape = \\\n",
    "                        sampled_world['obj_map'][obj_name].color + \\\n",
    "                        \" \" + sampled_world['obj_map'][obj_name].shape\n",
    "                else:\n",
    "                    special_shape = sampled_world['obj_map'][obj_name].shape\n",
    "                \n",
    "                if \"small\" in original_object_str:\n",
    "                    distractor_size = special_shape_size_bound[special_shape][1]\n",
    "                elif \"big\" in original_object_str:\n",
    "                    distractor_size = special_shape_size_bound[special_shape][0]\n",
    "                distractor_size_map[obj_name] = distractor_size\n",
    "                distractor_shape = original_object.shape\n",
    "                tmp_name = \"\"\n",
    "                if \"$COLOR\" in obj_grammer:\n",
    "                    distractor_color = original_object.color\n",
    "                    new_object_grammer = \"$SIZE $COLOR $SHAPE\" # $SIZE is a must right?\n",
    "                    tmp_name = distractor_color + \" \" + distractor_shape\n",
    "                else:\n",
    "                    distractor_color = self.object_vocabulary.sample_color()\n",
    "                    new_object_grammer = \"$SIZE $SHAPE\"\n",
    "                    tmp_name = distractor_shape\n",
    "                if \"small\" in original_object_str:\n",
    "                    tmp_name = \"big\" + \" \" + tmp_name\n",
    "                elif \"big\" in original_object_str:\n",
    "                    tmp_name = \"small\" + \" \" + tmp_name\n",
    "                else:\n",
    "                    pass # Not Implemented\n",
    "                distractor_obj_map[obj_name] = tmp_name\n",
    "                distractor_obj_pattern_map[obj_name] = new_object_grammer\n",
    "\n",
    "                # Then, we will also consider other object sizes. Basically,\n",
    "                # we keep them the same, unless they form SameShape relation\n",
    "                # with our core object.\n",
    "                for _obj_name, _obj in sampled_world['obj_map'].items():\n",
    "                    if _obj_name != obj_name:\n",
    "                        if (_obj_name, obj_name) in referent_rel_map and \\\n",
    "                            referent_rel_map[(_obj_name, obj_name)] == \"SameSize\":\n",
    "                            distractor_size_map[_obj_name] = distractor_size\n",
    "                        elif (obj_name, _obj_name) in referent_rel_map and \\\n",
    "                            referent_rel_map[(obj_name, _obj_name)] == \"SameSize\":\n",
    "                            distractor_size_map[_obj_name] = distractor_size\n",
    "                        else:\n",
    "                            distractor_size_map[_obj_name] = _obj.size\n",
    "            elif attribute_selected == \"$COLOR\":\n",
    "                original_object_name = obj_selected\n",
    "                original_object_str = distractor_obj_map[original_object_name]\n",
    "                original_object = sampled_world['obj_map'][original_object_name]\n",
    "                new_color = self.object_vocabulary.sample_color(_exclude=[original_object.color])\n",
    "                new_object_str = new_color + \" \" + original_object.shape\n",
    "                new_object_grammer = \"$COLOR $SHAPE\"\n",
    "                distractor_obj_map[original_object_name] = new_object_str\n",
    "                distractor_obj_pattern_map[original_object_name] = new_object_grammer\n",
    "            elif attribute_selected == \"$SHAPE\":\n",
    "\n",
    "                original_object_name = obj_selected\n",
    "                original_object_str = distractor_obj_map[original_object_name]\n",
    "                original_object = sampled_world['obj_map'][original_object_name]\n",
    "                new_shape = self.object_vocabulary.sample_shape(_exclude=[original_object.shape])\n",
    "                new_object_str = original_object.color + \" \" + new_shape\n",
    "                new_object_grammer = \"$COLOR $SHAPE\"\n",
    "                distractor_obj_map[original_object_name] = new_object_str\n",
    "                distractor_obj_pattern_map[original_object_name] = new_object_grammer\n",
    "                \n",
    "            # Now for all other objects with size attribute, we need\n",
    "            # to ground them even if it is not relational.\n",
    "            base_distractor_count = len(list(distractor_obj_map.keys()))\n",
    "            for obj_name, obj_grammer in referent_obj_pattern_map.items():\n",
    "                if \"$SIZE\" in obj_grammer:\n",
    "                    if obj_name not in sizing_covered:\n",
    "                        # Just sample a single one.\n",
    "                        new_obj_name = f\"OBJ_{base_distractor_count}\"\n",
    "                        original_object_str = referent_obj_map[obj_name]\n",
    "\n",
    "                        tmp_name = \" \".join(original_object_str.split(\" \")[1:])\n",
    "                        if \"small\" in original_object_str:\n",
    "                            tmp_name = \"big\" + \" \" + tmp_name\n",
    "                        elif \"big\" in original_object_str:\n",
    "                            tmp_name = \"small\" + \" \" + tmp_name\n",
    "                        else:\n",
    "                            pass # Not Implemented\n",
    "\n",
    "                        if \"$COLOR\" in obj_grammer:\n",
    "                            special_shape = \\\n",
    "                                sampled_world['obj_map'][obj_name].color + \\\n",
    "                                \" \" + sampled_world['obj_map'][obj_name].shape\n",
    "                        else:\n",
    "                            special_shape = sampled_world['obj_map'][obj_name].shape\n",
    "                        if \"small\" in original_object_str:\n",
    "                            distractor_size = special_shape_size_bound[special_shape][1]\n",
    "                        elif \"big\" in original_object_str:\n",
    "                            distractor_size = special_shape_size_bound[special_shape][0]\n",
    "                        # the above size if the proposed size!\n",
    "\n",
    "                        # Let us iterate through the map, if there is\n",
    "                        # already a shape working as the size counterparts\n",
    "                        # we don't need it!\n",
    "                        color = self.extract_color(original_object_str)\n",
    "                        shape = self.extract_shape(original_object_str)\n",
    "                        if color != \"\" and shape != \"object\":\n",
    "                            found = False\n",
    "                            for obj_str, obj in sampled_world['obj_map'].items():\n",
    "                                if obj.color == color and obj.shape == shape:\n",
    "                                    if obj.size == distractor_size:\n",
    "                                        found = True\n",
    "                                        break\n",
    "                            if found:\n",
    "                                continue\n",
    "                        elif color != \"\" and shape == \"object\":\n",
    "                            found = False\n",
    "                            for obj_str, obj in sampled_world['obj_map'].items():\n",
    "                                if obj.color == color:\n",
    "                                    if obj.size == distractor_size:\n",
    "                                        found = True\n",
    "                                        break\n",
    "                            if found:\n",
    "                                continue\n",
    "                        elif color == \"\" and shape == \"object\":\n",
    "                            found = False\n",
    "                            for obj_str, obj in sampled_world['obj_map'].items():\n",
    "                                if obj.size == distractor_size:\n",
    "                                    found = True\n",
    "                                    break\n",
    "                            if found:\n",
    "                                continue\n",
    "                        elif color == \"\" and shape != \"object\":\n",
    "                            found = False\n",
    "                            for obj_str, obj in sampled_world['obj_map'].items():\n",
    "                                if obj.shape == shape:\n",
    "                                    if obj.size == distractor_size:\n",
    "                                        found = True\n",
    "                                        break\n",
    "                            if found:\n",
    "                                continue\n",
    "\n",
    "                        distractor_obj_map[new_obj_name] = tmp_name\n",
    "                        distractor_obj_pattern_map[new_obj_name] = obj_grammer\n",
    "                        distractor_size_map[new_obj_name] = distractor_size\n",
    "                        base_distractor_count += 1\n",
    "                \n",
    "        else:\n",
    "            # We cleanup, and simply place random objects.\n",
    "            distractor_grammer_pattern = \"DUMMY\"\n",
    "            distractor_obj_pattern_map.clear()\n",
    "            distractor_rel_map.clear()\n",
    "            distractor_obj_map.clear()\n",
    "            \n",
    "            distractor_metadata = {\n",
    "                \"modified_obj\" : None,\n",
    "                \"modified_attribute\" : None,\n",
    "            }\n",
    "            # Now for all other objects with size attribute, we need\n",
    "            # to ground them even if it is not relational.\n",
    "            base_distractor_count = len(list(distractor_obj_map.keys()))\n",
    "            for obj_name, obj_grammer in referent_obj_pattern_map.items():\n",
    "                if \"$SIZE\" in obj_grammer:\n",
    "                    if obj_name not in sizing_covered:\n",
    "                        # Just sample a single one.\n",
    "                        new_obj_name = f\"OBJ_{base_distractor_count}\"\n",
    "                        original_object_str = referent_obj_map[obj_name]\n",
    "                        \n",
    "                        tmp_name = \" \".join(original_object_str.split(\" \")[1:])\n",
    "                        if \"small\" in original_object_str:\n",
    "                            tmp_name = \"big\" + \" \" + tmp_name\n",
    "                        elif \"big\" in original_object_str:\n",
    "                            tmp_name = \"small\" + \" \" + tmp_name\n",
    "                        else:\n",
    "                            pass # Not Implemented\n",
    "\n",
    "                        if \"$COLOR\" in obj_grammer:\n",
    "                            special_shape = \\\n",
    "                                sampled_world['obj_map'][obj_name].color + \\\n",
    "                                \" \" + sampled_world['obj_map'][obj_name].shape\n",
    "                        else:\n",
    "                            special_shape = sampled_world['obj_map'][obj_name].shape\n",
    "                        \n",
    "                        # We need to be a little careful when\n",
    "                        # dealing with abstract shape object\n",
    "                        # for example, big object -> small object.\n",
    "                            \n",
    "                        if \"small\" in original_object_str:\n",
    "                            distractor_size = special_shape_size_bound[special_shape][1]\n",
    "                        elif \"big\" in original_object_str:\n",
    "                            distractor_size = special_shape_size_bound[special_shape][0]\n",
    "                        # the above size if the proposed size!\n",
    "                        \n",
    "                        # Let us iterate through the map, if there is\n",
    "                        # already a shape working as the size counterparts\n",
    "                        # we don't need it!\n",
    "                        color = self.extract_color(original_object_str)\n",
    "                        shape = self.extract_shape(original_object_str)\n",
    "                        if color != \"\" and shape != \"object\":\n",
    "                            found = False\n",
    "                            for obj_str, obj in sampled_world['obj_map'].items():\n",
    "                                if obj.color == color and obj.shape == shape:\n",
    "                                    if obj.size == distractor_size:\n",
    "                                        found = True\n",
    "                                        break\n",
    "                            if found:\n",
    "                                continue\n",
    "                        elif color != \"\" and shape == \"object\":\n",
    "                            found = False\n",
    "                            for obj_str, obj in sampled_world['obj_map'].items():\n",
    "                                if obj.color == color:\n",
    "                                    if obj.size == distractor_size:\n",
    "                                        found = True\n",
    "                                        break\n",
    "                            if found:\n",
    "                                continue\n",
    "                        elif color == \"\" and shape == \"object\":\n",
    "                            found = False\n",
    "                            for obj_str, obj in sampled_world['obj_map'].items():\n",
    "                                if obj.size == distractor_size:\n",
    "                                    found = True\n",
    "                                    break\n",
    "                            if found:\n",
    "                                continue\n",
    "                        elif color == \"\" and shape != \"object\":\n",
    "                            found = False\n",
    "                            for obj_str, obj in sampled_world['obj_map'].items():\n",
    "                                if obj.shape == shape:\n",
    "                                    if obj.size == distractor_size:\n",
    "                                        found = True\n",
    "                                        break\n",
    "                            if found:\n",
    "                                continue\n",
    "                            \n",
    "                        distractor_obj_map[new_obj_name] = tmp_name\n",
    "                        distractor_obj_pattern_map[new_obj_name] = obj_grammer\n",
    "                        distractor_size_map[new_obj_name] = distractor_size\n",
    "                        base_distractor_count += 1\n",
    "        return [{\n",
    "            \"grammer_pattern\" : self.snap_pattern_to_referent_map(\n",
    "                distractor_grammer_pattern,\n",
    "                obj_base_count\n",
    "            ),\n",
    "            \"obj_pattern_map\" : self.snap_object_map_to_referent_map(\n",
    "                distractor_obj_pattern_map,\n",
    "                obj_base_count\n",
    "            ),\n",
    "            \"rel_map\" : self.snap_relation_map_to_referent_map(\n",
    "                distractor_rel_map,\n",
    "                obj_base_count\n",
    "            ),\n",
    "            \"obj_map\" : self.snap_object_map_to_referent_map(\n",
    "                distractor_obj_map,\n",
    "                obj_base_count\n",
    "            ),\n",
    "            \"size_map\" : self.snap_object_map_to_referent_map(\n",
    "                distractor_size_map,\n",
    "                obj_base_count\n",
    "            ),\n",
    "            \"distractor_metadata\" : [distractor_metadata]\n",
    "        }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1\n",
      "2/2\n",
      "3/3\n",
      "4/4\n",
      "5/5\n",
      "6/6\n",
      "7/7\n",
      "8/8\n",
      "9/9\n",
      "10/10\n",
      "11/11\n",
      "12/12\n",
      "13/13\n",
      "14/14\n",
      "15/15\n",
      "16/16\n",
      "17/17\n",
      "18/18\n",
      "19/19\n",
      "20/20\n",
      "21/21\n",
      "22/22\n",
      "23/23\n",
      "24/24\n",
      "25/25\n",
      "26/26\n",
      "27/27\n",
      "28/28\n",
      "29/29\n",
      "30/30\n",
      "31/31\n",
      "32/32\n",
      "33/33\n",
      "34/34\n",
      "35/35\n",
      "36/36\n",
      "37/37\n",
      "38/38\n",
      "39/39\n",
      "40/40\n",
      "41/41\n",
      "42/42\n",
      "43/43\n",
      "44/44\n",
      "45/45\n",
      "46/46\n",
      "47/47\n",
      "48/48\n",
      "49/49\n",
      "50/50\n",
      "51/51\n",
      "52/52\n",
      "53/53\n",
      "54/54\n",
      "55/55\n",
      "56/56\n",
      "57/57\n",
      "58/58\n",
      "59/59\n",
      "60/60\n",
      "61/61\n",
      "62/62\n",
      "63/63\n",
      "64/64\n",
      "65/65\n",
      "66/66\n",
      "67/67\n",
      "68/68\n",
      "69/69\n",
      "70/70\n",
      "71/71\n",
      "72/72\n",
      "73/73\n",
      "74/74\n",
      "75/75\n",
      "76/76\n",
      "77/77\n",
      "78/78\n",
      "79/79\n",
      "80/80\n",
      "81/81\n",
      "82/82\n",
      "83/83\n",
      "84/84\n",
      "85/85\n",
      "86/86\n",
      "87/87\n",
      "88/88\n",
      "89/89\n",
      "90/90\n",
      "91/91\n",
      "92/92\n",
      "93/93\n",
      "94/94\n",
      "95/95\n",
      "96/96\n",
      "97/97\n",
      "98/98\n",
      "99/99\n",
      "100/100\n",
      "101/101\n",
      "102/102\n",
      "103/103\n",
      "104/104\n",
      "105/105\n",
      "106/106\n",
      "107/107\n",
      "108/108\n",
      "109/109\n",
      "110/110\n",
      "111/111\n",
      "112/112\n",
      "113/113\n",
      "114/114\n",
      "115/115\n",
      "116/116\n",
      "117/117\n",
      "118/118\n",
      "119/119\n",
      "120/120\n",
      "121/121\n",
      "122/122\n",
      "123/123\n",
      "124/124\n",
      "125/125\n",
      "126/126\n",
      "127/127\n",
      "128/128\n",
      "129/129\n",
      "130/130\n",
      "131/131\n",
      "132/132\n",
      "133/133\n",
      "134/134\n",
      "135/135\n",
      "136/136\n",
      "137/137\n",
      "138/138\n",
      "139/139\n",
      "140/140\n",
      "141/141\n",
      "142/142\n",
      "143/143\n",
      "144/144\n",
      "145/145\n",
      "146/146\n",
      "147/147\n",
      "148/148\n",
      "149/149\n",
      "150/150\n",
      "151/151\n",
      "152/152\n",
      "153/153\n",
      "154/154\n",
      "155/155\n",
      "156/156\n",
      "157/157\n",
      "158/158\n",
      "159/159\n",
      "160/160\n",
      "161/161\n",
      "162/162\n",
      "163/163\n",
      "164/164\n",
      "165/165\n",
      "166/166\n",
      "167/167\n",
      "168/168\n",
      "169/169\n",
      "170/170\n",
      "171/171\n",
      "172/172\n",
      "173/173\n",
      "174/174\n",
      "175/175\n",
      "176/176\n",
      "177/177\n",
      "178/178\n",
      "179/179\n",
      "180/180\n",
      "181/181\n",
      "182/182\n",
      "183/183\n",
      "184/184\n",
      "185/186\n",
      "186/187\n",
      "187/188\n",
      "188/189\n",
      "189/190\n",
      "190/191\n",
      "191/192\n",
      "192/193\n",
      "193/194\n",
      "194/195\n",
      "195/196\n",
      "196/197\n",
      "197/198\n",
      "198/199\n",
      "199/200\n",
      "200/201\n",
      "201/202\n",
      "202/203\n",
      "203/204\n",
      "204/205\n",
      "205/206\n",
      "206/207\n",
      "207/208\n",
      "208/209\n",
      "209/210\n",
      "210/211\n",
      "211/212\n",
      "212/213\n",
      "213/214\n",
      "214/215\n",
      "215/216\n",
      "216/217\n",
      "217/218\n",
      "218/219\n",
      "219/220\n",
      "220/221\n",
      "221/222\n",
      "222/223\n",
      "223/224\n",
      "224/225\n",
      "225/226\n",
      "226/227\n",
      "227/228\n",
      "228/229\n",
      "229/230\n",
      "230/231\n",
      "231/232\n",
      "232/233\n",
      "233/234\n",
      "234/235\n",
      "235/236\n",
      "236/237\n",
      "237/238\n",
      "238/239\n",
      "239/240\n",
      "240/241\n",
      "241/242\n",
      "242/243\n",
      "243/244\n",
      "244/245\n",
      "245/246\n",
      "246/247\n",
      "247/248\n",
      "248/249\n",
      "249/250\n",
      "250/251\n",
      "251/252\n",
      "252/253\n",
      "253/254\n",
      "254/255\n",
      "255/256\n",
      "256/257\n",
      "257/258\n",
      "258/259\n",
      "259/260\n",
      "260/261\n",
      "261/262\n",
      "262/263\n",
      "263/264\n",
      "264/265\n",
      "265/266\n",
      "266/267\n",
      "267/268\n",
      "268/269\n",
      "269/270\n",
      "270/271\n",
      "271/272\n",
      "272/273\n",
      "273/274\n",
      "274/275\n",
      "275/276\n",
      "276/277\n",
      "277/278\n",
      "278/279\n",
      "279/280\n",
      "280/281\n",
      "281/282\n",
      "282/283\n",
      "283/284\n",
      "284/285\n",
      "285/286\n",
      "286/287\n",
      "287/288\n",
      "288/289\n",
      "289/290\n",
      "290/291\n",
      "291/292\n",
      "292/293\n",
      "293/294\n",
      "294/295\n",
      "295/296\n",
      "296/297\n",
      "297/298\n",
      "298/299\n",
      "299/300\n",
      "300/301\n",
      "301/302\n",
      "302/303\n",
      "303/304\n",
      "304/305\n",
      "305/306\n",
      "306/307\n",
      "307/308\n",
      "308/309\n",
      "309/310\n",
      "310/311\n",
      "311/312\n",
      "312/313\n",
      "313/314\n",
      "314/315\n",
      "315/316\n",
      "316/317\n",
      "317/318\n",
      "318/319\n",
      "319/320\n",
      "320/321\n",
      "321/322\n",
      "322/323\n",
      "323/324\n",
      "324/325\n",
      "325/326\n",
      "326/327\n",
      "327/328\n",
      "328/329\n",
      "329/330\n",
      "330/331\n",
      "331/332\n",
      "332/333\n",
      "333/334\n",
      "334/335\n",
      "335/336\n",
      "336/337\n",
      "337/338\n",
      "338/339\n",
      "339/340\n",
      "340/341\n",
      "341/342\n",
      "342/343\n",
      "343/344\n",
      "344/345\n",
      "345/346\n",
      "346/347\n",
      "347/348\n",
      "348/349\n",
      "349/350\n",
      "350/351\n",
      "351/352\n",
      "352/353\n",
      "353/354\n",
      "354/355\n",
      "355/356\n",
      "356/357\n",
      "357/358\n",
      "358/359\n",
      "359/360\n",
      "360/361\n",
      "361/362\n",
      "362/363\n",
      "363/364\n",
      "364/365\n",
      "365/366\n",
      "366/367\n",
      "367/368\n",
      "368/369\n",
      "369/370\n",
      "370/371\n",
      "371/372\n",
      "372/373\n",
      "373/374\n",
      "374/375\n",
      "375/376\n",
      "376/377\n",
      "377/378\n",
      "378/379\n",
      "379/380\n",
      "380/381\n",
      "381/382\n",
      "382/383\n",
      "383/384\n",
      "384/385\n",
      "385/386\n",
      "386/387\n",
      "387/388\n",
      "388/389\n",
      "389/390\n",
      "390/391\n",
      "391/392\n",
      "392/393\n",
      "393/394\n",
      "394/395\n",
      "395/396\n",
      "396/397\n",
      "397/398\n",
      "398/399\n",
      "399/400\n",
      "400/401\n",
      "401/402\n",
      "402/403\n",
      "403/404\n",
      "404/405\n",
      "405/406\n",
      "406/407\n",
      "407/408\n",
      "408/409\n",
      "409/410\n",
      "410/411\n",
      "411/412\n",
      "412/413\n",
      "413/414\n",
      "414/415\n",
      "415/416\n",
      "416/417\n",
      "417/418\n",
      "418/419\n",
      "419/420\n",
      "420/421\n",
      "421/422\n",
      "422/423\n",
      "423/424\n",
      "424/425\n",
      "425/426\n",
      "426/427\n",
      "427/428\n",
      "428/429\n",
      "429/430\n",
      "430/431\n",
      "431/432\n",
      "432/433\n",
      "433/434\n",
      "434/435\n",
      "435/436\n",
      "436/437\n",
      "437/438\n",
      "438/439\n",
      "439/440\n",
      "440/441\n",
      "441/442\n",
      "442/443\n",
      "443/444\n",
      "444/445\n",
      "445/446\n",
      "446/447\n",
      "447/448\n",
      "448/449\n",
      "449/450\n",
      "450/451\n",
      "451/452\n",
      "452/453\n",
      "453/454\n",
      "454/455\n",
      "455/456\n",
      "456/457\n",
      "457/458\n",
      "458/459\n",
      "459/460\n",
      "460/461\n",
      "461/462\n",
      "462/463\n",
      "463/464\n",
      "464/465\n",
      "465/466\n",
      "466/467\n",
      "467/468\n",
      "468/469\n",
      "469/470\n",
      "470/471\n",
      "471/472\n",
      "472/473\n",
      "473/474\n",
      "474/475\n",
      "475/476\n",
      "476/478\n",
      "477/479\n",
      "478/480\n",
      "479/481\n",
      "480/482\n",
      "481/483\n",
      "482/484\n",
      "483/485\n",
      "484/486\n",
      "485/487\n",
      "486/488\n",
      "487/489\n",
      "488/490\n",
      "489/491\n",
      "490/492\n",
      "491/493\n",
      "492/494\n",
      "493/495\n",
      "494/496\n",
      "495/497\n",
      "496/498\n",
      "497/499\n",
      "498/500\n",
      "499/501\n",
      "500/502\n",
      "501/503\n",
      "502/504\n",
      "503/505\n",
      "504/506\n",
      "505/507\n",
      "506/508\n",
      "507/509\n",
      "508/510\n",
      "509/511\n",
      "510/512\n",
      "511/513\n",
      "512/514\n",
      "513/515\n",
      "514/516\n",
      "515/517\n",
      "516/518\n",
      "517/519\n",
      "518/520\n",
      "519/521\n",
      "520/522\n",
      "521/523\n",
      "522/524\n",
      "523/525\n",
      "524/526\n",
      "525/527\n",
      "526/528\n",
      "527/529\n",
      "528/530\n",
      "529/531\n",
      "530/532\n",
      "531/533\n",
      "532/534\n",
      "533/535\n",
      "534/536\n",
      "535/537\n",
      "536/538\n",
      "537/539\n",
      "538/540\n",
      "539/541\n",
      "540/542\n",
      "541/543\n",
      "542/544\n",
      "543/545\n",
      "544/546\n",
      "545/547\n",
      "546/548\n",
      "547/549\n",
      "548/550\n",
      "549/551\n",
      "550/552\n",
      "551/553\n",
      "552/554\n",
      "553/555\n",
      "554/556\n",
      "555/557\n",
      "556/558\n",
      "557/559\n",
      "558/560\n",
      "559/561\n",
      "560/562\n",
      "561/563\n",
      "562/564\n",
      "563/565\n",
      "564/566\n",
      "565/567\n",
      "566/568\n",
      "567/569\n",
      "568/570\n",
      "569/571\n",
      "570/572\n",
      "571/573\n",
      "572/574\n",
      "573/575\n",
      "574/576\n",
      "575/577\n",
      "576/578\n",
      "577/579\n",
      "578/580\n",
      "579/581\n",
      "580/582\n",
      "581/583\n",
      "582/584\n",
      "583/585\n",
      "584/586\n",
      "585/587\n",
      "586/588\n",
      "587/589\n",
      "588/590\n",
      "589/591\n",
      "590/592\n",
      "591/593\n",
      "592/594\n",
      "593/595\n",
      "594/596\n",
      "595/597\n",
      "596/598\n",
      "597/599\n",
      "598/600\n",
      "599/601\n",
      "600/602\n",
      "601/603\n",
      "602/604\n",
      "603/605\n",
      "604/606\n",
      "605/607\n",
      "606/608\n",
      "607/609\n",
      "608/610\n",
      "609/611\n",
      "610/612\n",
      "611/613\n",
      "612/614\n",
      "613/615\n",
      "614/616\n",
      "615/617\n",
      "616/618\n",
      "617/619\n",
      "618/620\n",
      "619/621\n",
      "620/622\n",
      "621/623\n",
      "622/624\n",
      "623/625\n",
      "624/626\n",
      "625/627\n",
      "626/628\n",
      "627/629\n",
      "628/631\n",
      "629/632\n",
      "630/633\n",
      "631/634\n",
      "632/635\n",
      "633/636\n",
      "634/637\n",
      "635/638\n",
      "636/639\n",
      "637/640\n",
      "638/641\n",
      "639/642\n",
      "640/643\n",
      "641/644\n",
      "642/645\n",
      "643/646\n",
      "644/647\n",
      "645/648\n",
      "646/649\n",
      "647/650\n",
      "648/651\n",
      "649/652\n",
      "650/653\n",
      "651/654\n",
      "652/655\n",
      "653/656\n",
      "654/657\n",
      "655/658\n",
      "656/659\n",
      "657/660\n",
      "658/661\n",
      "659/662\n",
      "660/663\n",
      "661/664\n",
      "662/665\n",
      "663/666\n",
      "664/667\n",
      "665/668\n",
      "666/669\n",
      "667/670\n",
      "668/671\n",
      "669/672\n",
      "670/673\n",
      "671/674\n",
      "672/675\n",
      "673/676\n",
      "674/677\n",
      "675/678\n",
      "676/679\n",
      "677/680\n",
      "678/681\n",
      "679/682\n",
      "680/683\n",
      "681/684\n",
      "682/685\n",
      "683/686\n",
      "684/687\n",
      "685/688\n",
      "686/689\n",
      "687/690\n",
      "688/691\n",
      "689/692\n",
      "690/693\n",
      "691/694\n",
      "692/695\n",
      "693/696\n",
      "694/697\n",
      "695/698\n",
      "696/699\n",
      "697/700\n",
      "698/701\n",
      "699/702\n",
      "700/703\n",
      "701/704\n",
      "702/705\n",
      "703/706\n",
      "704/707\n",
      "705/708\n",
      "706/709\n",
      "707/710\n",
      "708/711\n",
      "709/712\n",
      "710/713\n",
      "711/714\n",
      "712/715\n",
      "713/716\n",
      "714/717\n",
      "715/718\n",
      "716/719\n",
      "717/720\n",
      "718/721\n",
      "719/722\n",
      "720/723\n",
      "721/724\n",
      "722/725\n",
      "723/726\n",
      "724/727\n",
      "725/728\n",
      "726/729\n",
      "727/730\n",
      "728/731\n",
      "729/732\n",
      "730/733\n",
      "731/734\n",
      "732/735\n",
      "733/736\n",
      "734/737\n",
      "735/738\n",
      "736/739\n",
      "737/740\n",
      "738/741\n",
      "739/742\n",
      "740/743\n",
      "741/744\n",
      "742/745\n",
      "743/746\n",
      "744/747\n",
      "745/748\n",
      "746/749\n",
      "747/750\n",
      "748/751\n",
      "749/752\n",
      "750/753\n",
      "751/754\n",
      "752/755\n",
      "753/756\n",
      "754/757\n",
      "755/758\n",
      "756/759\n",
      "757/760\n",
      "758/761\n",
      "759/762\n",
      "760/763\n",
      "761/764\n",
      "762/765\n",
      "763/766\n",
      "764/767\n",
      "765/768\n",
      "766/769\n",
      "767/770\n",
      "768/771\n",
      "769/772\n",
      "770/773\n",
      "771/774\n",
      "772/775\n",
      "773/776\n",
      "774/777\n",
      "775/778\n",
      "776/779\n",
      "777/780\n",
      "778/781\n",
      "779/782\n",
      "780/783\n",
      "781/784\n",
      "782/785\n",
      "783/786\n",
      "784/787\n",
      "785/788\n",
      "786/789\n",
      "787/790\n",
      "788/791\n",
      "789/792\n",
      "790/793\n",
      "791/794\n",
      "792/795\n",
      "793/796\n",
      "794/797\n",
      "795/798\n",
      "796/799\n",
      "797/800\n",
      "798/801\n",
      "799/802\n",
      "800/803\n",
      "801/804\n",
      "802/805\n",
      "803/806\n",
      "804/807\n",
      "805/808\n",
      "806/809\n",
      "807/810\n",
      "808/811\n",
      "809/812\n",
      "810/813\n",
      "811/814\n",
      "812/815\n",
      "813/816\n",
      "814/817\n",
      "815/818\n",
      "816/819\n",
      "817/820\n",
      "818/821\n",
      "819/822\n",
      "820/823\n",
      "821/824\n",
      "822/825\n",
      "823/826\n",
      "824/827\n",
      "825/828\n",
      "826/829\n",
      "827/830\n",
      "828/831\n",
      "829/832\n",
      "830/833\n",
      "831/834\n",
      "832/835\n",
      "833/836\n",
      "834/837\n",
      "835/838\n",
      "836/839\n",
      "837/840\n",
      "838/841\n",
      "839/842\n",
      "840/843\n",
      "841/844\n",
      "842/845\n",
      "843/846\n",
      "844/847\n",
      "845/848\n",
      "846/849\n",
      "847/850\n",
      "848/851\n",
      "849/852\n",
      "850/853\n",
      "851/854\n",
      "852/855\n",
      "853/856\n",
      "854/857\n",
      "855/858\n",
      "856/859\n",
      "857/860\n",
      "858/861\n",
      "859/862\n",
      "860/863\n",
      "861/864\n",
      "862/865\n",
      "863/866\n",
      "864/867\n",
      "865/868\n",
      "866/869\n",
      "867/870\n",
      "868/871\n",
      "869/872\n",
      "870/873\n",
      "871/874\n",
      "872/875\n",
      "873/876\n",
      "874/877\n",
      "875/878\n",
      "876/879\n",
      "877/880\n",
      "878/881\n",
      "879/882\n",
      "880/883\n",
      "881/884\n",
      "882/885\n",
      "883/886\n",
      "884/887\n",
      "885/888\n",
      "886/889\n",
      "887/890\n",
      "888/891\n",
      "889/892\n",
      "890/893\n",
      "891/894\n",
      "892/895\n",
      "893/896\n",
      "894/897\n",
      "895/898\n",
      "896/899\n",
      "897/900\n",
      "898/901\n",
      "899/902\n",
      "900/903\n",
      "901/904\n",
      "902/905\n",
      "903/906\n",
      "904/907\n",
      "905/908\n",
      "906/909\n",
      "907/910\n",
      "908/911\n",
      "909/912\n",
      "910/913\n",
      "911/914\n",
      "912/915\n",
      "913/916\n",
      "914/917\n",
      "915/918\n",
      "916/919\n",
      "917/920\n",
      "918/921\n",
      "919/922\n",
      "920/923\n",
      "921/924\n",
      "922/925\n",
      "923/926\n",
      "924/927\n",
      "925/928\n",
      "926/929\n",
      "927/930\n",
      "928/931\n",
      "929/932\n",
      "930/933\n",
      "931/934\n",
      "932/935\n",
      "933/936\n",
      "934/937\n",
      "935/938\n",
      "936/939\n",
      "937/940\n",
      "938/941\n",
      "939/942\n",
      "940/943\n",
      "941/944\n",
      "942/945\n",
      "943/946\n",
      "944/947\n",
      "945/948\n",
      "946/949\n",
      "947/950\n",
      "948/951\n",
      "949/952\n",
      "950/953\n",
      "951/954\n",
      "952/955\n",
      "953/956\n",
      "954/957\n",
      "955/958\n",
      "956/959\n",
      "957/960\n",
      "958/961\n",
      "959/962\n",
      "960/963\n",
      "961/964\n",
      "962/965\n",
      "963/966\n",
      "964/967\n",
      "965/968\n",
      "966/969\n",
      "967/970\n",
      "968/971\n",
      "969/972\n",
      "970/973\n",
      "971/974\n",
      "972/975\n",
      "973/976\n",
      "974/977\n",
      "975/978\n",
      "976/979\n",
      "977/980\n",
      "978/981\n",
      "979/982\n",
      "980/983\n",
      "981/984\n",
      "982/985\n",
      "983/986\n",
      "984/987\n",
      "985/988\n",
      "986/989\n",
      "987/990\n",
      "988/991\n",
      "989/992\n",
      "990/993\n",
      "991/994\n",
      "992/995\n",
      "993/996\n",
      "994/997\n",
      "995/998\n",
      "996/999\n",
      "997/1000\n",
      "998/1001\n",
      "999/1002\n",
      "1000/1003\n",
      "1001/1004\n",
      "1002/1005\n",
      "1003/1006\n",
      "1004/1007\n",
      "1005/1008\n",
      "1006/1009\n",
      "1007/1010\n",
      "1008/1011\n",
      "1009/1012\n",
      "1010/1013\n",
      "1011/1014\n",
      "1012/1015\n",
      "1013/1016\n",
      "1014/1017\n",
      "1015/1018\n",
      "1016/1019\n",
      "1017/1020\n",
      "1018/1021\n",
      "1019/1022\n",
      "1020/1023\n",
      "1021/1024\n",
      "1022/1025\n",
      "1023/1026\n",
      "1024/1027\n",
      "1025/1028\n",
      "1026/1029\n",
      "1027/1030\n",
      "1028/1031\n",
      "1029/1032\n",
      "1030/1033\n",
      "1031/1034\n",
      "1032/1035\n",
      "1033/1036\n",
      "1034/1037\n",
      "1035/1038\n",
      "1036/1039\n",
      "1037/1040\n",
      "1038/1041\n",
      "1039/1042\n",
      "1040/1043\n",
      "1041/1044\n",
      "1042/1045\n",
      "1043/1046\n",
      "1044/1047\n",
      "1045/1048\n",
      "1046/1049\n",
      "1047/1050\n",
      "1048/1051\n",
      "1049/1052\n",
      "1050/1053\n",
      "1051/1054\n",
      "1052/1055\n",
      "1053/1056\n",
      "1054/1057\n",
      "1055/1058\n",
      "1056/1059\n",
      "1057/1060\n",
      "1058/1061\n",
      "1059/1062\n",
      "1060/1063\n",
      "1061/1064\n",
      "1062/1065\n",
      "1063/1066\n",
      "1064/1067\n",
      "1065/1068\n",
      "1066/1069\n",
      "1067/1070\n",
      "1068/1071\n",
      "1069/1072\n",
      "1070/1073\n",
      "1071/1074\n",
      "1072/1075\n",
      "1073/1076\n",
      "1074/1077\n",
      "1075/1078\n",
      "1076/1079\n",
      "1077/1080\n",
      "1078/1081\n",
      "1079/1082\n",
      "1080/1083\n",
      "1081/1084\n",
      "1082/1085\n",
      "1083/1086\n",
      "1084/1087\n",
      "1085/1088\n",
      "1086/1089\n",
      "1087/1090\n",
      "1088/1091\n",
      "1089/1092\n",
      "1090/1093\n",
      "1091/1094\n",
      "1092/1095\n",
      "1093/1096\n",
      "1094/1097\n",
      "1095/1098\n",
      "1096/1099\n",
      "1097/1100\n",
      "1098/1101\n",
      "1099/1102\n",
      "1100/1103\n",
      "1101/1104\n",
      "1102/1105\n",
      "1103/1106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1104/1107\n",
      "1105/1108\n",
      "1106/1109\n",
      "1107/1110\n",
      "1108/1111\n",
      "1109/1112\n",
      "1110/1113\n",
      "1111/1114\n",
      "1112/1115\n",
      "1113/1116\n",
      "1114/1117\n",
      "1115/1118\n",
      "1116/1119\n",
      "1117/1120\n",
      "1118/1121\n",
      "1119/1122\n",
      "1120/1123\n",
      "1121/1124\n",
      "1122/1125\n",
      "1123/1126\n",
      "1124/1127\n",
      "1125/1128\n",
      "1126/1129\n",
      "1127/1130\n",
      "1128/1131\n",
      "1129/1132\n",
      "1130/1133\n",
      "1131/1134\n",
      "1132/1135\n",
      "1133/1136\n",
      "1134/1137\n",
      "1135/1138\n",
      "1136/1139\n",
      "1137/1140\n",
      "1138/1141\n",
      "1139/1142\n",
      "1140/1143\n",
      "1141/1144\n",
      "1142/1145\n",
      "1143/1146\n",
      "1144/1147\n",
      "1145/1148\n",
      "1146/1149\n",
      "1147/1150\n",
      "1148/1151\n",
      "1149/1152\n",
      "1150/1153\n",
      "1151/1154\n",
      "1152/1155\n",
      "1153/1156\n",
      "1154/1157\n",
      "1155/1158\n",
      "1156/1159\n",
      "1157/1160\n",
      "1158/1161\n",
      "1159/1162\n",
      "1160/1163\n",
      "1161/1164\n",
      "1162/1165\n",
      "1163/1166\n",
      "1164/1167\n",
      "1165/1168\n",
      "1166/1169\n",
      "1167/1170\n",
      "1168/1171\n",
      "1169/1172\n",
      "1170/1173\n",
      "1171/1174\n",
      "1172/1175\n",
      "1173/1176\n",
      "1174/1177\n",
      "1175/1178\n",
      "1176/1179\n",
      "1177/1180\n",
      "1178/1181\n",
      "1179/1182\n",
      "1180/1183\n",
      "1181/1184\n",
      "1182/1185\n",
      "1183/1186\n",
      "1184/1187\n",
      "1185/1188\n",
      "1186/1189\n",
      "1187/1190\n",
      "1188/1191\n",
      "1189/1192\n",
      "1190/1193\n",
      "1191/1194\n",
      "1192/1195\n",
      "1193/1196\n",
      "1194/1197\n",
      "1195/1198\n",
      "1196/1199\n",
      "1197/1200\n",
      "1198/1201\n",
      "1199/1202\n",
      "1200/1203\n",
      "1201/1204\n",
      "1202/1205\n",
      "1203/1206\n",
      "1204/1207\n",
      "1205/1208\n",
      "1206/1209\n",
      "1207/1210\n",
      "1208/1211\n",
      "1209/1212\n",
      "1210/1213\n",
      "1211/1214\n",
      "1212/1215\n",
      "1213/1216\n",
      "1214/1217\n",
      "1215/1218\n",
      "1216/1219\n",
      "1217/1220\n",
      "1218/1221\n",
      "1219/1222\n",
      "1220/1223\n",
      "1221/1224\n",
      "1222/1225\n",
      "1223/1226\n",
      "1224/1227\n",
      "1225/1228\n",
      "1226/1229\n",
      "1227/1230\n",
      "1228/1231\n",
      "1229/1232\n",
      "1230/1233\n",
      "1231/1234\n",
      "1232/1235\n",
      "1233/1236\n",
      "1234/1237\n",
      "1235/1238\n",
      "1236/1239\n",
      "1237/1240\n",
      "1238/1241\n",
      "1239/1242\n",
      "1240/1243\n",
      "1241/1244\n",
      "1242/1245\n",
      "1243/1246\n",
      "1244/1247\n",
      "1245/1248\n",
      "1246/1249\n",
      "1247/1250\n",
      "1248/1251\n",
      "1249/1252\n",
      "1250/1253\n",
      "1251/1254\n",
      "1252/1255\n",
      "1253/1256\n",
      "1254/1257\n",
      "1255/1258\n",
      "1256/1259\n",
      "1257/1260\n",
      "1258/1261\n",
      "1259/1263\n",
      "1260/1264\n",
      "1261/1265\n",
      "1262/1266\n",
      "1263/1267\n",
      "1264/1268\n",
      "1265/1269\n",
      "1266/1270\n",
      "1267/1271\n",
      "1268/1272\n",
      "1269/1273\n",
      "1270/1274\n",
      "1271/1276\n",
      "1272/1277\n",
      "1273/1278\n",
      "1274/1279\n",
      "1275/1280\n",
      "1276/1281\n",
      "1277/1282\n",
      "1278/1283\n",
      "1279/1284\n",
      "1280/1285\n",
      "1281/1286\n",
      "1282/1287\n",
      "1283/1288\n",
      "1284/1289\n",
      "1285/1290\n",
      "1286/1291\n",
      "1287/1292\n",
      "1288/1293\n",
      "1289/1294\n",
      "1290/1295\n",
      "1291/1296\n",
      "1292/1297\n",
      "1293/1298\n",
      "1294/1299\n",
      "1295/1300\n",
      "1296/1301\n",
      "1297/1302\n",
      "1298/1303\n",
      "1299/1304\n",
      "1300/1305\n",
      "1301/1306\n",
      "1302/1307\n",
      "1303/1308\n",
      "1304/1309\n",
      "1305/1310\n",
      "1306/1311\n",
      "1307/1312\n",
      "1308/1313\n",
      "1309/1314\n",
      "1310/1315\n",
      "1311/1316\n",
      "1312/1317\n",
      "1313/1318\n",
      "1314/1319\n",
      "1315/1320\n",
      "1316/1321\n",
      "1317/1322\n",
      "1318/1323\n",
      "1319/1324\n",
      "1320/1325\n",
      "1321/1326\n",
      "1322/1327\n",
      "1323/1328\n",
      "1324/1329\n",
      "1325/1330\n",
      "1326/1331\n",
      "1327/1332\n",
      "1328/1333\n",
      "1329/1334\n",
      "1330/1335\n",
      "1331/1336\n",
      "1332/1337\n",
      "1333/1338\n",
      "1334/1339\n",
      "1335/1340\n",
      "1336/1341\n",
      "1337/1342\n",
      "1338/1343\n",
      "1339/1344\n",
      "1340/1345\n",
      "1341/1346\n",
      "1342/1347\n",
      "1343/1348\n",
      "1344/1349\n",
      "1345/1350\n",
      "1346/1351\n",
      "1347/1352\n",
      "1348/1353\n",
      "1349/1354\n",
      "1350/1355\n",
      "1351/1356\n",
      "1352/1357\n",
      "1353/1358\n",
      "1354/1359\n",
      "1355/1360\n",
      "1356/1361\n",
      "1357/1362\n",
      "1358/1363\n",
      "1359/1364\n",
      "1360/1365\n",
      "1361/1366\n",
      "1362/1367\n",
      "1363/1368\n",
      "1364/1369\n",
      "1365/1370\n",
      "1366/1371\n",
      "1367/1372\n",
      "1368/1373\n",
      "1369/1374\n",
      "1370/1375\n",
      "1371/1376\n",
      "1372/1377\n",
      "1373/1378\n",
      "1374/1379\n",
      "1375/1380\n",
      "1376/1381\n",
      "1377/1382\n",
      "1378/1383\n",
      "1379/1384\n",
      "1380/1385\n",
      "1381/1386\n",
      "1382/1387\n",
      "1383/1388\n",
      "1384/1389\n",
      "1385/1390\n",
      "1386/1391\n",
      "1387/1392\n",
      "1388/1393\n",
      "1389/1394\n",
      "1390/1395\n",
      "1391/1396\n",
      "1392/1397\n",
      "1393/1398\n",
      "1394/1399\n",
      "1395/1400\n",
      "1396/1401\n",
      "1397/1402\n",
      "1398/1403\n",
      "1399/1404\n",
      "1400/1405\n",
      "1401/1406\n",
      "1402/1407\n",
      "1403/1408\n",
      "1404/1409\n",
      "1405/1410\n",
      "1406/1411\n",
      "1407/1412\n",
      "1408/1413\n",
      "1409/1414\n",
      "1410/1415\n",
      "1411/1416\n",
      "1412/1417\n",
      "1413/1418\n",
      "1414/1419\n",
      "1415/1420\n",
      "1416/1421\n",
      "1417/1422\n",
      "1418/1423\n",
      "1419/1424\n",
      "1420/1425\n",
      "1421/1426\n",
      "1422/1427\n",
      "1423/1428\n",
      "1424/1429\n",
      "1425/1430\n",
      "1426/1431\n",
      "1427/1432\n",
      "1428/1433\n",
      "1429/1434\n",
      "1430/1435\n",
      "1431/1436\n",
      "1432/1437\n",
      "1433/1438\n",
      "1434/1439\n",
      "1435/1440\n",
      "1436/1441\n",
      "1437/1442\n",
      "1438/1443\n",
      "1439/1444\n",
      "1440/1445\n",
      "1441/1446\n",
      "1442/1447\n",
      "1443/1448\n",
      "1444/1449\n",
      "1445/1450\n",
      "1446/1451\n",
      "1447/1452\n",
      "1448/1453\n",
      "1449/1454\n",
      "1450/1455\n",
      "1451/1456\n",
      "1452/1457\n",
      "1453/1458\n",
      "1454/1459\n",
      "1455/1460\n",
      "1456/1461\n",
      "1457/1462\n",
      "1458/1463\n",
      "1459/1464\n",
      "1460/1465\n",
      "1461/1466\n",
      "1462/1467\n",
      "1463/1468\n",
      "1464/1469\n",
      "1465/1470\n",
      "1466/1471\n",
      "1467/1472\n",
      "1468/1473\n",
      "1469/1474\n",
      "1470/1475\n",
      "1471/1476\n",
      "1472/1477\n",
      "1473/1478\n",
      "1474/1479\n",
      "1475/1480\n",
      "1476/1481\n",
      "1477/1482\n",
      "1478/1483\n",
      "1479/1484\n",
      "1480/1485\n",
      "1481/1486\n",
      "1482/1487\n",
      "1483/1488\n",
      "1484/1489\n",
      "1485/1490\n",
      "1486/1491\n",
      "1487/1492\n",
      "1488/1493\n",
      "1489/1494\n",
      "1490/1495\n",
      "1491/1496\n",
      "1492/1497\n",
      "1493/1498\n",
      "1494/1499\n",
      "1495/1500\n",
      "1496/1501\n",
      "1497/1502\n",
      "1498/1503\n",
      "1499/1504\n",
      "1500/1505\n",
      "1501/1506\n",
      "1502/1507\n",
      "1503/1508\n",
      "1504/1509\n",
      "1505/1510\n",
      "1506/1511\n",
      "1507/1512\n",
      "1508/1513\n",
      "1509/1514\n",
      "1510/1515\n",
      "1511/1516\n",
      "1512/1517\n",
      "1513/1518\n",
      "1514/1519\n",
      "1515/1520\n",
      "1516/1521\n",
      "1517/1522\n",
      "1518/1523\n",
      "1519/1524\n",
      "1520/1525\n",
      "1521/1526\n",
      "1522/1527\n",
      "1523/1528\n",
      "1524/1529\n",
      "1525/1530\n",
      "1526/1531\n",
      "1527/1532\n",
      "1528/1533\n",
      "1529/1534\n",
      "1530/1535\n",
      "1531/1536\n",
      "1532/1537\n",
      "1533/1538\n",
      "1534/1539\n",
      "1535/1540\n",
      "1536/1541\n",
      "1537/1542\n",
      "1538/1543\n",
      "1539/1544\n",
      "1540/1545\n",
      "1541/1546\n",
      "1542/1547\n",
      "1543/1548\n",
      "1544/1549\n",
      "1545/1550\n",
      "1546/1551\n",
      "1547/1552\n",
      "1548/1553\n",
      "1549/1554\n",
      "1550/1555\n",
      "1551/1556\n",
      "1552/1557\n",
      "1553/1558\n",
      "1554/1559\n",
      "1555/1560\n",
      "1556/1561\n",
      "1557/1562\n",
      "1558/1563\n",
      "1559/1564\n",
      "1560/1565\n",
      "1561/1566\n",
      "1562/1567\n",
      "1563/1568\n",
      "1564/1569\n",
      "1565/1570\n",
      "1566/1571\n",
      "1567/1572\n",
      "1568/1573\n",
      "1569/1574\n",
      "1570/1575\n",
      "1571/1576\n",
      "1572/1577\n",
      "1573/1578\n",
      "1574/1579\n",
      "1575/1580\n",
      "1576/1581\n",
      "1577/1582\n",
      "1578/1583\n",
      "1579/1584\n",
      "1580/1585\n",
      "1581/1586\n",
      "1582/1587\n",
      "1583/1588\n",
      "1584/1589\n",
      "1585/1590\n",
      "1586/1591\n",
      "1587/1592\n",
      "1588/1593\n",
      "1589/1594\n",
      "1590/1595\n",
      "1591/1596\n",
      "1592/1597\n",
      "1593/1598\n",
      "1594/1599\n",
      "1595/1600\n",
      "1596/1601\n",
      "1597/1602\n",
      "1598/1603\n",
      "1599/1604\n",
      "1600/1605\n",
      "1601/1606\n",
      "1602/1607\n",
      "1603/1608\n",
      "1604/1609\n",
      "1605/1610\n",
      "1606/1611\n",
      "1607/1612\n",
      "1608/1613\n",
      "1609/1614\n",
      "1610/1615\n",
      "1611/1616\n",
      "1612/1617\n",
      "1613/1618\n",
      "1614/1619\n",
      "1615/1620\n",
      "1616/1621\n",
      "1617/1622\n",
      "1618/1623\n",
      "1619/1624\n",
      "1620/1625\n",
      "1621/1626\n",
      "1622/1627\n",
      "1623/1628\n",
      "1624/1629\n",
      "1625/1630\n",
      "1626/1631\n",
      "1627/1632\n",
      "1628/1633\n",
      "1629/1634\n",
      "1630/1635\n",
      "1631/1636\n",
      "1632/1637\n",
      "1633/1638\n",
      "1634/1639\n",
      "1635/1640\n",
      "1636/1641\n",
      "1637/1642\n",
      "1638/1643\n",
      "1639/1644\n",
      "1640/1645\n",
      "1641/1646\n",
      "1642/1647\n",
      "1643/1648\n",
      "1644/1649\n",
      "1645/1650\n",
      "1646/1651\n",
      "1647/1652\n",
      "1648/1653\n",
      "1649/1654\n",
      "1650/1655\n",
      "1651/1656\n",
      "1652/1657\n",
      "1653/1658\n",
      "1654/1659\n",
      "1655/1660\n",
      "1656/1661\n",
      "1657/1662\n",
      "1658/1663\n",
      "1659/1664\n",
      "1660/1665\n",
      "1661/1666\n",
      "1662/1667\n",
      "1663/1668\n",
      "1664/1669\n",
      "1665/1671\n",
      "1666/1672\n",
      "1667/1673\n",
      "1668/1674\n",
      "1669/1675\n",
      "1670/1676\n",
      "1671/1677\n",
      "1672/1678\n",
      "1673/1679\n",
      "1674/1680\n",
      "1675/1681\n",
      "1676/1682\n",
      "1677/1683\n",
      "1678/1684\n",
      "1679/1685\n",
      "1680/1686\n",
      "1681/1687\n",
      "1682/1688\n",
      "1683/1689\n",
      "1684/1690\n",
      "1685/1691\n",
      "1686/1692\n",
      "1687/1693\n",
      "1688/1694\n",
      "1689/1695\n",
      "1690/1696\n",
      "1691/1697\n",
      "1692/1698\n",
      "1693/1699\n",
      "1694/1700\n",
      "1695/1701\n",
      "1696/1702\n",
      "1697/1703\n",
      "1698/1704\n",
      "1699/1705\n",
      "1700/1706\n",
      "1701/1707\n",
      "1702/1708\n",
      "1703/1709\n",
      "1704/1710\n",
      "1705/1711\n",
      "1706/1712\n",
      "1707/1713\n",
      "1708/1714\n",
      "1709/1715\n",
      "1710/1716\n",
      "1711/1717\n",
      "1712/1718\n",
      "1713/1719\n",
      "1714/1720\n",
      "1715/1721\n",
      "1716/1722\n",
      "1717/1723\n",
      "1718/1724\n",
      "1719/1725\n",
      "1720/1726\n",
      "1721/1727\n",
      "1722/1728\n",
      "1723/1729\n",
      "1724/1730\n",
      "1725/1731\n",
      "1726/1732\n",
      "1727/1733\n",
      "1728/1734\n",
      "1729/1735\n",
      "1730/1736\n",
      "1731/1737\n",
      "1732/1738\n",
      "1733/1739\n",
      "1734/1740\n",
      "1735/1741\n",
      "1736/1742\n",
      "1737/1743\n",
      "1738/1744\n",
      "1739/1745\n",
      "1740/1746\n",
      "1741/1747\n",
      "1742/1748\n",
      "1743/1749\n",
      "1744/1750\n",
      "1745/1751\n",
      "1746/1752\n",
      "1747/1753\n",
      "1748/1754\n",
      "1749/1755\n",
      "1750/1756\n",
      "1751/1757\n",
      "1752/1758\n",
      "1753/1759\n",
      "1754/1760\n",
      "1755/1761\n",
      "1756/1762\n",
      "1757/1763\n",
      "1758/1764\n",
      "1759/1765\n",
      "1760/1766\n",
      "1761/1767\n",
      "1762/1768\n",
      "1763/1769\n",
      "1764/1770\n",
      "1765/1771\n",
      "1766/1772\n",
      "1767/1773\n",
      "1768/1774\n",
      "1769/1775\n",
      "1770/1776\n",
      "1771/1777\n",
      "1772/1778\n",
      "1773/1779\n",
      "1774/1780\n",
      "1775/1781\n",
      "1776/1782\n",
      "1777/1783\n",
      "1778/1784\n",
      "1779/1785\n",
      "1780/1786\n",
      "1781/1787\n",
      "1782/1788\n",
      "1783/1789\n",
      "1784/1790\n",
      "1785/1791\n",
      "1786/1792\n",
      "1787/1793\n",
      "1788/1794\n",
      "1789/1795\n",
      "1790/1796\n",
      "1791/1797\n",
      "1792/1798\n",
      "1793/1799\n",
      "1794/1800\n",
      "1795/1801\n",
      "1796/1802\n",
      "1797/1803\n",
      "1798/1804\n",
      "1799/1805\n",
      "1800/1806\n",
      "1801/1807\n",
      "1802/1808\n",
      "1803/1809\n",
      "1804/1810\n",
      "1805/1811\n",
      "1806/1812\n",
      "1807/1813\n",
      "1808/1814\n",
      "1809/1816\n",
      "1810/1817\n",
      "1811/1818\n",
      "1812/1819\n",
      "1813/1820\n",
      "1814/1821\n",
      "1815/1822\n",
      "1816/1823\n",
      "1817/1824\n",
      "1818/1825\n",
      "1819/1826\n",
      "1820/1827\n",
      "1821/1828\n",
      "1822/1829\n",
      "1823/1830\n",
      "1824/1831\n",
      "1825/1832\n",
      "1826/1833\n",
      "1827/1834\n",
      "1828/1835\n",
      "1829/1836\n",
      "1830/1837\n",
      "1831/1838\n",
      "1832/1839\n",
      "1833/1840\n",
      "1834/1841\n",
      "1835/1842\n",
      "1836/1843\n",
      "1837/1844\n",
      "1838/1845\n",
      "1839/1846\n",
      "1840/1847\n",
      "1841/1848\n",
      "1842/1849\n",
      "1843/1850\n",
      "1844/1851\n",
      "1845/1852\n",
      "1846/1853\n",
      "1847/1854\n",
      "1848/1855\n",
      "1849/1856\n",
      "1850/1857\n",
      "1851/1858\n",
      "1852/1859\n",
      "1853/1860\n",
      "1854/1861\n",
      "1855/1862\n",
      "1856/1863\n",
      "1857/1864\n",
      "1858/1865\n",
      "1859/1866\n",
      "1860/1867\n",
      "1861/1868\n",
      "1862/1869\n",
      "1863/1870\n",
      "1864/1871\n",
      "1865/1872\n",
      "1866/1873\n",
      "1867/1874\n",
      "1868/1875\n",
      "1869/1876\n",
      "1870/1877\n",
      "1871/1878\n",
      "1872/1880\n",
      "1873/1881\n",
      "1874/1882\n",
      "1875/1883\n",
      "1876/1884\n",
      "1877/1885\n",
      "1878/1886\n",
      "1879/1887\n",
      "1880/1888\n",
      "1881/1889\n",
      "1882/1890\n",
      "1883/1891\n",
      "1884/1892\n",
      "1885/1893\n",
      "1886/1894\n",
      "1887/1895\n",
      "1888/1896\n",
      "1889/1897\n",
      "1890/1898\n",
      "1891/1899\n",
      "1892/1900\n",
      "1893/1901\n",
      "1894/1902\n",
      "1895/1903\n",
      "1896/1904\n",
      "1897/1905\n",
      "1898/1906\n",
      "1899/1907\n",
      "1900/1908\n",
      "1901/1909\n",
      "1902/1910\n",
      "1903/1911\n",
      "1904/1912\n",
      "1905/1913\n",
      "1906/1914\n",
      "1907/1915\n",
      "1908/1916\n",
      "1909/1917\n",
      "1910/1918\n",
      "1911/1919\n",
      "1912/1920\n",
      "1913/1921\n",
      "1914/1922\n",
      "1915/1923\n",
      "1916/1924\n",
      "1917/1925\n",
      "1918/1926\n",
      "1919/1927\n",
      "1920/1928\n",
      "1921/1929\n",
      "1922/1930\n",
      "1923/1931\n",
      "1924/1932\n",
      "1925/1933\n",
      "1926/1934\n",
      "1927/1935\n",
      "1928/1936\n",
      "1929/1937\n",
      "1930/1938\n",
      "1931/1939\n",
      "1932/1940\n",
      "1933/1941\n",
      "1934/1942\n",
      "1935/1943\n",
      "1936/1944\n",
      "1937/1945\n",
      "1938/1946\n",
      "1939/1947\n",
      "1940/1948\n",
      "1941/1949\n",
      "1942/1950\n",
      "1943/1951\n",
      "1944/1952\n",
      "1945/1953\n",
      "1946/1954\n",
      "1947/1955\n",
      "1948/1956\n",
      "1949/1957\n",
      "1950/1958\n",
      "1951/1959\n",
      "1952/1960\n",
      "1953/1961\n",
      "1954/1962\n",
      "1955/1963\n",
      "1956/1964\n",
      "1957/1965\n",
      "1958/1966\n",
      "1959/1967\n",
      "1960/1968\n",
      "1961/1969\n",
      "1962/1970\n",
      "1963/1971\n",
      "1964/1972\n",
      "1965/1973\n",
      "1966/1974\n",
      "1967/1975\n",
      "1968/1976\n",
      "1969/1977\n",
      "1970/1978\n",
      "1971/1979\n",
      "1972/1980\n",
      "1973/1981\n",
      "1974/1982\n",
      "1975/1983\n",
      "1976/1984\n",
      "1977/1985\n",
      "1978/1986\n",
      "1979/1987\n",
      "1980/1988\n",
      "1981/1989\n",
      "1982/1990\n",
      "1983/1991\n",
      "1984/1992\n",
      "1985/1993\n",
      "1986/1994\n",
      "1987/1995\n",
      "1988/1996\n",
      "1989/1997\n",
      "1990/1998\n",
      "1991/1999\n",
      "1992/2000\n",
      "1993/2001\n",
      "1994/2002\n",
      "1995/2003\n",
      "1996/2004\n",
      "1997/2005\n",
      "1998/2006\n",
      "1999/2007\n",
      "2000/2008\n",
      "2001/2009\n",
      "2002/2010\n",
      "2003/2011\n",
      "2004/2012\n",
      "2005/2013\n",
      "2006/2014\n",
      "2007/2015\n",
      "2008/2016\n",
      "2009/2017\n",
      "2010/2018\n",
      "2011/2019\n",
      "2012/2020\n",
      "2013/2021\n",
      "2014/2022\n",
      "2015/2023\n",
      "2016/2024\n",
      "2017/2025\n",
      "2018/2026\n",
      "2019/2027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/2028\n",
      "2021/2029\n",
      "2022/2030\n",
      "2023/2031\n",
      "2024/2032\n",
      "2025/2033\n",
      "2026/2034\n",
      "2027/2035\n",
      "2028/2036\n",
      "2029/2037\n",
      "2030/2038\n",
      "2031/2039\n",
      "2032/2040\n",
      "2033/2041\n",
      "2034/2042\n",
      "2035/2043\n",
      "2036/2044\n",
      "2037/2045\n",
      "2038/2046\n",
      "2039/2047\n",
      "2040/2048\n",
      "2041/2049\n",
      "2042/2050\n",
      "2043/2051\n",
      "2044/2052\n",
      "2045/2053\n",
      "2046/2054\n",
      "2047/2055\n",
      "2048/2056\n",
      "2049/2057\n",
      "2050/2058\n",
      "2051/2059\n",
      "2052/2060\n",
      "2053/2061\n",
      "2054/2062\n",
      "2055/2063\n",
      "2056/2064\n",
      "2057/2065\n",
      "2058/2066\n",
      "2059/2067\n",
      "2060/2068\n",
      "2061/2069\n",
      "2062/2070\n",
      "2063/2071\n",
      "2064/2072\n",
      "2065/2073\n",
      "2066/2074\n",
      "2067/2075\n",
      "2068/2076\n",
      "2069/2077\n",
      "2070/2078\n",
      "2071/2079\n",
      "2072/2080\n",
      "2073/2081\n",
      "2074/2082\n",
      "2075/2083\n",
      "2076/2084\n",
      "2077/2085\n",
      "2078/2086\n",
      "2079/2087\n",
      "2080/2088\n",
      "2081/2089\n",
      "2082/2090\n",
      "2083/2091\n",
      "2084/2092\n",
      "2085/2093\n",
      "2086/2094\n",
      "2087/2095\n",
      "2088/2096\n",
      "2089/2097\n",
      "2090/2098\n",
      "2091/2099\n",
      "2092/2100\n",
      "2093/2101\n",
      "2094/2102\n",
      "2095/2103\n",
      "2096/2104\n",
      "2097/2105\n",
      "2098/2106\n",
      "2099/2107\n",
      "2100/2108\n",
      "2101/2109\n",
      "2102/2110\n",
      "2103/2111\n",
      "2104/2112\n",
      "2105/2113\n",
      "2106/2114\n",
      "2107/2115\n",
      "2108/2116\n",
      "2109/2117\n",
      "2110/2118\n",
      "2111/2119\n",
      "2112/2120\n",
      "2113/2121\n",
      "2114/2122\n",
      "2115/2123\n",
      "2116/2124\n",
      "2117/2125\n",
      "2118/2126\n",
      "2119/2127\n",
      "2120/2128\n",
      "2121/2129\n",
      "2122/2130\n",
      "2123/2131\n",
      "2124/2132\n",
      "2125/2133\n",
      "2126/2134\n",
      "2127/2135\n",
      "2128/2136\n",
      "2129/2137\n",
      "2130/2138\n",
      "2131/2139\n",
      "2132/2140\n",
      "2133/2141\n",
      "2134/2142\n",
      "2135/2143\n",
      "2136/2144\n",
      "2137/2145\n",
      "2138/2146\n",
      "2139/2147\n",
      "2140/2148\n",
      "2141/2149\n",
      "2142/2150\n",
      "2143/2151\n",
      "2144/2152\n",
      "2145/2153\n",
      "2146/2154\n",
      "2147/2155\n",
      "2148/2156\n",
      "2149/2157\n",
      "2150/2158\n",
      "2151/2159\n",
      "2152/2160\n",
      "2153/2161\n",
      "2154/2162\n",
      "2155/2163\n",
      "2156/2164\n",
      "2157/2165\n",
      "2158/2166\n",
      "2159/2167\n",
      "2160/2168\n",
      "2161/2169\n",
      "2162/2170\n",
      "2163/2171\n",
      "2164/2172\n",
      "2165/2173\n",
      "2166/2174\n",
      "2167/2175\n",
      "2168/2176\n",
      "2169/2177\n",
      "2170/2178\n",
      "2171/2179\n",
      "2172/2180\n",
      "2173/2181\n",
      "2174/2182\n",
      "2175/2183\n",
      "2176/2184\n",
      "2177/2185\n",
      "2178/2186\n",
      "2179/2187\n",
      "2180/2188\n",
      "2181/2189\n",
      "2182/2190\n",
      "2183/2191\n",
      "2184/2192\n",
      "2185/2193\n",
      "2186/2194\n",
      "2187/2195\n",
      "2188/2196\n",
      "2189/2197\n",
      "2190/2198\n",
      "2191/2199\n",
      "2192/2200\n",
      "2193/2201\n",
      "2194/2202\n",
      "2195/2203\n",
      "2196/2204\n",
      "2197/2205\n",
      "2198/2206\n",
      "2199/2207\n",
      "2200/2208\n",
      "2201/2209\n",
      "2202/2210\n",
      "2203/2211\n",
      "2204/2212\n",
      "2205/2213\n",
      "2206/2214\n",
      "2207/2215\n",
      "2208/2216\n",
      "2209/2217\n",
      "2210/2218\n",
      "2211/2219\n",
      "2212/2220\n",
      "2213/2221\n",
      "2214/2222\n",
      "2215/2223\n",
      "2216/2224\n",
      "2217/2225\n",
      "2218/2226\n",
      "2219/2227\n",
      "2220/2228\n",
      "2221/2229\n",
      "2222/2230\n",
      "2223/2231\n",
      "2224/2232\n",
      "2225/2233\n",
      "2226/2234\n",
      "2227/2235\n",
      "2228/2236\n",
      "2229/2237\n",
      "2230/2238\n",
      "2231/2239\n",
      "2232/2240\n",
      "2233/2241\n",
      "2234/2242\n",
      "2235/2243\n",
      "2236/2244\n",
      "2237/2245\n",
      "2238/2246\n",
      "2239/2247\n",
      "2240/2248\n",
      "2241/2249\n",
      "2242/2250\n",
      "2243/2251\n",
      "2244/2252\n",
      "2245/2253\n",
      "2246/2254\n",
      "2247/2255\n",
      "2248/2256\n",
      "2249/2257\n",
      "2250/2258\n",
      "2251/2259\n",
      "2252/2260\n",
      "2253/2261\n",
      "2254/2262\n",
      "2255/2263\n",
      "2256/2264\n",
      "2257/2265\n",
      "2258/2266\n",
      "2259/2267\n",
      "2260/2268\n",
      "2261/2269\n",
      "2262/2270\n",
      "2263/2271\n",
      "2264/2272\n",
      "2265/2273\n",
      "2266/2274\n",
      "2267/2275\n",
      "2268/2276\n",
      "2269/2277\n",
      "2270/2278\n",
      "2271/2279\n",
      "2272/2280\n",
      "2273/2281\n",
      "2274/2282\n",
      "2275/2283\n",
      "2276/2284\n",
      "2277/2285\n",
      "2278/2286\n",
      "2279/2287\n",
      "2280/2288\n",
      "2281/2289\n",
      "2282/2290\n",
      "2283/2291\n",
      "2284/2292\n",
      "2285/2293\n",
      "2286/2294\n",
      "2287/2295\n",
      "2288/2296\n",
      "2289/2297\n",
      "2290/2298\n",
      "2291/2299\n",
      "2292/2300\n",
      "2293/2301\n",
      "2294/2302\n",
      "2295/2303\n",
      "2296/2304\n",
      "2297/2305\n",
      "2298/2306\n",
      "2299/2307\n",
      "2300/2308\n",
      "2301/2309\n",
      "2302/2310\n",
      "2303/2311\n",
      "2304/2312\n",
      "2305/2313\n",
      "2306/2314\n",
      "2307/2315\n",
      "2308/2316\n",
      "2309/2317\n",
      "2310/2318\n",
      "2311/2319\n",
      "2312/2320\n",
      "2313/2321\n",
      "2314/2322\n",
      "2315/2323\n",
      "2316/2324\n",
      "2317/2325\n",
      "2318/2326\n",
      "2319/2327\n",
      "2320/2328\n",
      "2321/2329\n",
      "2322/2330\n",
      "2323/2331\n",
      "2324/2332\n",
      "2325/2333\n",
      "2326/2334\n",
      "2327/2335\n",
      "2328/2336\n",
      "2329/2337\n",
      "2330/2338\n",
      "2331/2339\n",
      "2332/2340\n",
      "2333/2341\n",
      "2334/2342\n",
      "2335/2343\n",
      "2336/2344\n",
      "2337/2345\n",
      "2338/2346\n",
      "2339/2347\n",
      "2340/2348\n",
      "2341/2349\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-13c9c87125cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0minclude_random_distractor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mfull_relation_probability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# 0.5 seems to work as well!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         )\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msampled_world\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"distractor_switch_map\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attribute'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-a71a56ddde47>\u001b[0m in \u001b[0;36msample_situations_from_grounded_grammer\u001b[0;34m(self, grammer_pattern, obj_pattern_map, rel_map, obj_map, root, is_plot, include_random_distractor, include_relation_distractor, include_attribute_distractor, include_isomorphism_distractor, full_relation_probability, debug)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_world\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0msituation_snapshot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_world\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_current_situation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         return {\n",
      "\u001b[0;32m/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/copy.py\u001b[0m in \u001b[0;36m_deepcopy_list\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0mappend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0m_keep_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Make sure x lives at least as long as d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/copy.py\u001b[0m in \u001b[0;36m_keep_alive\u001b[0;34m(x, memo)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \"\"\"\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;31m# aha, this is the first one :-)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Simulator robustness tests.\n",
    "random.shuffle(command_structs)\n",
    "simulator = Simulator(\n",
    "    object_vocabulary, vocabulary, \n",
    "    grid_size=6, \n",
    "    n_object_max=10,\n",
    ")\n",
    "count = 0\n",
    "special_count = 0\n",
    "minor_count = 0\n",
    "for test_struct in command_structs[:10000]:\n",
    "    count += 1\n",
    "    if count%100==0:\n",
    "        print(f\"passing rate = {count}/{10000}\")\n",
    "    obj_pattern_map = test_struct[\"obj_pattern_map\"]\n",
    "    rel_map = test_struct[\"rel_map\"]\n",
    "    obj_map = test_struct[\"obj_map\"]\n",
    "    grammer_pattern = test_struct[\"grammer_pattern\"]\n",
    "    verb = test_struct[\"verb\"]\n",
    "    adverb = test_struct[\"adverb\"]\n",
    "\n",
    "    test_unique_find = 0\n",
    "    for i in range(200):\n",
    "        minor_count += 1\n",
    "        sampled_world = simulator.sample_situations_from_grounded_grammer(\n",
    "            copy.deepcopy(grammer_pattern), \n",
    "            copy.deepcopy(obj_pattern_map), \n",
    "            copy.deepcopy(rel_map), \n",
    "            copy.deepcopy(obj_map),\n",
    "            is_plot=False,\n",
    "            include_relation_distractor=True, \n",
    "            include_attribute_distractor=True, \n",
    "            include_isomorphism_distractor=True, \n",
    "            include_random_distractor=True,\n",
    "            full_relation_probability=0.5, # 0.5 seems to work as well!\n",
    "            debug=False\n",
    "        )\n",
    "        if sampled_world[\"distractor_switch_map\"]['attribute'] == True:\n",
    "            special_count += 1\n",
    "            print(f\"{special_count}/{minor_count}\")\n",
    "        assert len(sampled_world['obj_map']) == len(simulator._world.get_current_situation().to_representation()[\"placed_objects\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'obj_pattern_map': {'$OBJ_0': '$SHAPE',\n",
       "  '$OBJ_1': '$SHAPE',\n",
       "  '$OBJ_2': '$COLOR $SHAPE'},\n",
       " 'rel_map': OrderedDict([(('$OBJ_0', '$OBJ_1'), '$SAME_ROW'),\n",
       "              (('$OBJ_0', '$OBJ_2'), '$SAME_COLOR')]),\n",
       " 'obj_map': {'$OBJ_0': 'cylinder',\n",
       "  '$OBJ_1': 'square',\n",
       "  '$OBJ_2': 'green cylinder'},\n",
       " 'grammer_pattern': '$OBJ_0 ^ $OBJ_1 & $OBJ_2',\n",
       " 'adverb': 'while zigzagging',\n",
       " 'verb': 'push'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passing rate = 0/200000\n",
      "{   'distractor_metadata': {   'edge': ('$OBJ_0', '$OBJ_2'),\n",
      "                               'full_set': True,\n",
      "                               'relation_old_type': '$SAME_COLOR'},\n",
      "    'grammer_pattern': '$OBJ_3 ^ $OBJ_4',\n",
      "    'obj_map': OrderedDict([   ('$OBJ_3', 'cylinder'),\n",
      "                               ('$OBJ_4', 'green cylinder')]),\n",
      "    'obj_pattern_map': OrderedDict([   ('$OBJ_3', '$SHAPE'),\n",
      "                                       ('$OBJ_4', '$COLOR $SHAPE')]),\n",
      "    'rel_map': OrderedDict([(('$OBJ_3', '$OBJ_4'), '$SAME_COLOR')]),\n",
      "    'size_map': OrderedDict()}\n",
      "{   'distractor_metadata': {   'edge': ('$OBJ_0', '$OBJ_1'),\n",
      "                               'full_set': True,\n",
      "                               'relation_old_type': '$SAME_ROW'},\n",
      "    'grammer_pattern': '$OBJ_5 ^ $OBJ_6',\n",
      "    'obj_map': OrderedDict([('$OBJ_5', 'cylinder'), ('$OBJ_6', 'square')]),\n",
      "    'obj_pattern_map': OrderedDict([   ('$OBJ_5', '$SHAPE'),\n",
      "                                       ('$OBJ_6', '$SHAPE')]),\n",
      "    'rel_map': OrderedDict([(('$OBJ_5', '$OBJ_6'), '$SAME_ROW')]),\n",
      "    'size_map': OrderedDict()}\n",
      "{   'distractor_metadata': [{'modified_attribute': None, 'modified_obj': None}],\n",
      "    'grammer_pattern': 'DUMMY',\n",
      "    'obj_map': OrderedDict(),\n",
      "    'obj_pattern_map': OrderedDict(),\n",
      "    'rel_map': OrderedDict(),\n",
      "    'size_map': OrderedDict()}\n",
      "{   'distractor_metadata': [   {   'after_pair_obj_str': (   'cylinder',\n",
      "                                                             'green square'),\n",
      "                                   'before_pair_obj_str': (   'square',\n",
      "                                                              'green cylinder'),\n",
      "                                   'color_shuffled': False,\n",
      "                                   'shape_shuffled': True,\n",
      "                                   'size_shuffled': True,\n",
      "                                   'swapped_pair': ('$OBJ_1', '$OBJ_2')}],\n",
      "    'grammer_pattern': '$OBJ_7 ^ $OBJ_8 & $OBJ_9',\n",
      "    'obj_map': OrderedDict([   ('$OBJ_7', 'cylinder'),\n",
      "                               ('$OBJ_8', 'cylinder'),\n",
      "                               ('$OBJ_9', 'green square')]),\n",
      "    'obj_pattern_map': OrderedDict([   ('$OBJ_7', '$SHAPE'),\n",
      "                                       ('$OBJ_8', '$SHAPE'),\n",
      "                                       ('$OBJ_9', '$COLOR $SHAPE')]),\n",
      "    'rel_map': OrderedDict([   (('$OBJ_7', '$OBJ_8'), '$SAME_ROW'),\n",
      "                               (('$OBJ_7', '$OBJ_9'), '$SAME_COLOR')]),\n",
      "    'size_map': OrderedDict()}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_struct = {'obj_pattern_map': {'$OBJ_0': '$SHAPE',\n",
    "  '$OBJ_1': '$SHAPE',\n",
    "  '$OBJ_2': '$COLOR $SHAPE'},\n",
    " 'rel_map': OrderedDict([(('$OBJ_0', '$OBJ_1'), '$SAME_ROW'),\n",
    "              (('$OBJ_0', '$OBJ_2'), '$SAME_COLOR')]),\n",
    " 'obj_map': {'$OBJ_0': 'cylinder',\n",
    "  '$OBJ_1': 'square',\n",
    "  '$OBJ_2': 'green cylinder'},\n",
    " 'grammer_pattern': '$OBJ_0 ^ $OBJ_1 & $OBJ_2',\n",
    " 'adverb': 'while zigzagging',\n",
    " 'verb': 'push'}\n",
    "\n",
    "simulator = Simulator(\n",
    "    object_vocabulary, vocabulary, \n",
    "    grid_size=6, \n",
    "    n_object_max=10,\n",
    ")\n",
    "\n",
    "obj_pattern_map = test_struct[\"obj_pattern_map\"]\n",
    "rel_map = test_struct[\"rel_map\"]\n",
    "obj_map = test_struct[\"obj_map\"]\n",
    "grammer_pattern = test_struct[\"grammer_pattern\"]\n",
    "verb = test_struct[\"verb\"]\n",
    "adverb = test_struct[\"adverb\"]\n",
    "\n",
    "test_unique_find = 0\n",
    "for i in range(100):\n",
    "    if i%10000==0:\n",
    "        print(f\"passing rate = {i}/{200000}\")\n",
    "    sampled_world = simulator.sample_situations_from_grounded_grammer(\n",
    "            copy.deepcopy(grammer_pattern), \n",
    "            copy.deepcopy(obj_pattern_map), \n",
    "            copy.deepcopy(rel_map), \n",
    "            copy.deepcopy(obj_map),\n",
    "            is_plot=False,\n",
    "            include_relation_distractor=True, \n",
    "            include_attribute_distractor=True, \n",
    "            include_isomorphism_distractor=True, \n",
    "            include_random_distractor=True,\n",
    "            full_relation_probability=0.5, # 0.5 seems to work as well!\n",
    "            debug=True\n",
    "        )\n",
    "    _ = simulator._world.render_simple()\n",
    "    assert len(sampled_world['obj_map']) == len(simulator._world.get_current_situation().to_representation()[\"placed_objects\"])\n",
    "    break\n",
    "    \n",
    "    graph = ReaSCANGraph(\n",
    "        objects=sampled_world[\"obj_map\"], \n",
    "        object_patterns=sampled_world[\"obj_pattern_map\"], \n",
    "        vocabulary=vocabulary,\n",
    "        positions=sampled_world[\"pos_map\"], \n",
    "        referred_object=sampled_world[\"referred_obj\"],\n",
    "        debug=False\n",
    "    )\n",
    "\n",
    "    pattern_graph = ReaSCANGraph(\n",
    "        objects=obj_map, \n",
    "        object_patterns=None,\n",
    "        vocabulary=vocabulary,\n",
    "        relations=rel_map, \n",
    "        referred_object='$OBJ_0', \n",
    "        debug=False\n",
    "    )\n",
    "\n",
    "    potential_referent_target = graph.find_referred_object(\n",
    "        pattern_graph, referred_object='$OBJ_0', \n",
    "        debug=False\n",
    "    )\n",
    "\n",
    "    if len(potential_referent_target) == 1:\n",
    "        print(f\"{test_unique_find+1} / {i+1} unique solution find!\")\n",
    "        test_unique_find += 1\n",
    "        \n",
    "        simulator._world.render_simple()\n",
    "        \n",
    "        obj_determiner_map = graph.find_determiners(\n",
    "            pattern_graph, \n",
    "            referred_object='$OBJ_0', \n",
    "            debug=False,\n",
    "        )\n",
    "        \n",
    "        command_str = grammer.repre_str_command(\n",
    "            grammer_pattern, rel_map, obj_map, \n",
    "            obj_determiner_map, \n",
    "            verb,\n",
    "            adverb,\n",
    "        )\n",
    "        \n",
    "        # Get the target command\n",
    "        is_transitive = False\n",
    "        if verb in simulator.vocabulary.get_transitive_verbs():\n",
    "            is_transitive = True\n",
    "        \n",
    "        # Direct walk.\n",
    "        action = \"walk\" # this is definit!\n",
    "        primitive_command = simulator.vocabulary.translate_word(action)\n",
    "        target_position = sampled_world[\"situation\"].target_object.position\n",
    "\n",
    "        simulator._world.go_to_position(\n",
    "            position=target_position, manner=adverb, \n",
    "            primitive_command=primitive_command\n",
    "        )\n",
    "\n",
    "        # Object actions.\n",
    "        if is_transitive:\n",
    "            semantic_action = simulator.vocabulary.translate_word(verb)\n",
    "            simulator._world.move_object_to_wall(action=semantic_action, manner=adverb)\n",
    "        target_commands, _ = simulator._world.get_current_observations()\n",
    "        \n",
    "        task_struct = OrderedDict({\n",
    "            \"command\": \",\".join(command_str.split(\" \")),\n",
    "            \"meaning\": \",\".join(command_str.split(\" \")),\n",
    "            \"derivation\": grammer_pattern,\n",
    "            \"situation\": sampled_world[\"situation\"].to_representation(),\n",
    "            \"target_commands\": \",\".join(target_commands),\n",
    "            \"verb_in_command\": verb,\n",
    "            \"adverb_in_command\": adverb,\n",
    "            \"referred_target\": obj_map[\"$OBJ_0\"],\n",
    "            \"object_pattern_map\": obj_pattern_map,\n",
    "            \"relation_map\": rel_map,\n",
    "            \"object_expression\": obj_map,\n",
    "            \"n_object\": len(sampled_world[\"obj_map\"]),\n",
    "            \"n_distractor\": len(sampled_world[\"obj_map\"])-len(obj_map),\n",
    "            \"full_relation_distractor\": True if len(sampled_world[\"distractor_switch_map\"][\"relation\"]) == len(rel_map) else False,\n",
    "            \"has_relation_distractor\": True if len(sampled_world[\"distractor_switch_map\"][\"relation\"]) > 0 else False,\n",
    "            \"has_attribute_distractor\": sampled_world[\"distractor_switch_map\"][\"attribute\"],\n",
    "            \"has_isomorphism_distractor\": sampled_world[\"distractor_switch_map\"][\"isomorphism\"],\n",
    "            \"has_random_distractor\": True if sampled_world[\"n_random_distractor\"] != -1 else False,\n",
    "            \"n_random_distractor\": sampled_world[\"n_random_distractor\"] if sampled_world[\"n_random_distractor\"] != -1 else 0,\n",
    "            \"relation_distractor_metadata\": sampled_world[\"relation_distractor_metadata\"],\n",
    "            \"attribute_distractor_metadata\": sampled_world[\"attribute_distractor_metadata\"],\n",
    "            \"isomorphism_distractor_metadata\": sampled_world[\"isomorphism_distractor_metadata\"],\n",
    "            \"random_distractor_metadata\": sampled_world[\"random_distractor_metadata\"],\n",
    "        })\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'obj_map': OrderedDict([('$OBJ_0',\n",
       "               Object(size=4, color='green', shape='cylinder')),\n",
       "              ('$OBJ_1', Object(size=4, color='yellow', shape='square')),\n",
       "              ('$OBJ_2', Object(size=3, color='green', shape='cylinder')),\n",
       "              ('$OBJ_3', Object(size=1, color='green', shape='cylinder')),\n",
       "              ('$OBJ_4', Object(size=4, color='green', shape='square')),\n",
       "              ('$OBJ_5', Object(size=4, color='green', shape='cylinder')),\n",
       "              ('$OBJ_8', Object(size=3, color='yellow', shape='cylinder')),\n",
       "              ('$OBJ_9', Object(size=4, color='yellow', shape='circle')),\n",
       "              ('$OBJ_10', Object(size=2, color='yellow', shape='cylinder'))]),\n",
       " 'pos_map': OrderedDict([('$OBJ_0', Position(column=5, row=1)),\n",
       "              ('$OBJ_1', Position(column=0, row=1)),\n",
       "              ('$OBJ_2', Position(column=3, row=1)),\n",
       "              ('$OBJ_3', Position(column=4, row=1)),\n",
       "              ('$OBJ_4', Position(column=1, row=1)),\n",
       "              ('$OBJ_5', Position(column=2, row=1)),\n",
       "              ('$OBJ_8', Position(column=3, row=0)),\n",
       "              ('$OBJ_9', Position(column=2, row=3)),\n",
       "              ('$OBJ_10', Position(column=0, row=4))]),\n",
       " 'obj_pattern_map': {'$OBJ_0': '$SHAPE',\n",
       "  '$OBJ_1': '$SHAPE',\n",
       "  '$OBJ_2': '$COLOR $SHAPE'},\n",
       " 'referred_obj': '$OBJ_0',\n",
       " 'situation': <world.Situation at 0x7faefb0ebd68>,\n",
       " 'distractor_switch_map': OrderedDict([('relation', [True]),\n",
       "              ('attribute', False),\n",
       "              ('isomorphism', True),\n",
       "              ('random', True)]),\n",
       " 'relation_distractor_metadata': [{'distractor_metadata': {'edge': ('$OBJ_0',\n",
       "     '$OBJ_1'),\n",
       "    'relation_old_type': '$SAME_ROW',\n",
       "    'full_set': False},\n",
       "   'obj_map': OrderedDict([('$OBJ_3', 'cylinder'), ('$OBJ_4', 'square')]),\n",
       "   'rel_map': OrderedDict([(('$OBJ_3', '$OBJ_4'), '$SAME_ROW')])}],\n",
       " 'attribute_distractor_metadata': [{'distractor_metadata': [{'modified_obj': '$OBJ_1',\n",
       "     'modified_attribute': '$SHAPE'}],\n",
       "   'obj_map': OrderedDict([('$OBJ_5', 'cylinder'),\n",
       "                ('$OBJ_6', 'yellow circle'),\n",
       "                ('$OBJ_7', 'green cylinder')]),\n",
       "   'rel_map': OrderedDict([(('$OBJ_5', '$OBJ_6'), '$SAME_ROW'),\n",
       "                (('$OBJ_5', '$OBJ_7'), '$SAME_COLOR')])}],\n",
       " 'isomorphism_distractor_metadata': [{'distractor_metadata': [{'swapped_pair': ('$OBJ_1',\n",
       "      '$OBJ_2'),\n",
       "     'before_pair_obj_str': ('square', 'green cylinder'),\n",
       "     'after_pair_obj_str': ('green square', 'cylinder'),\n",
       "     'size_shuffled': False,\n",
       "     'color_shuffled': True,\n",
       "     'shape_shuffled': False}],\n",
       "   'obj_map': OrderedDict([('$OBJ_8', 'cylinder'),\n",
       "                ('$OBJ_9', 'green square'),\n",
       "                ('$OBJ_10', 'cylinder')]),\n",
       "   'rel_map': OrderedDict([(('$OBJ_8', '$OBJ_9'), '$SAME_ROW'),\n",
       "                (('$OBJ_8', '$OBJ_10'), '$SAME_COLOR')])}],\n",
       " 'random_distractor_metadata': [{'$OBJ_9': ' yellow circle'}],\n",
       " 'n_random_distractor': 1}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('$OBJ_0', Object(size=3, color='blue', shape='square')),\n",
       "             ('$OBJ_1', Object(size=3, color='yellow', shape='circle')),\n",
       "             ('$OBJ_2', Object(size=3, color='green', shape='box')),\n",
       "             ('$OBJ_3', Object(size=3, color='green', shape='square')),\n",
       "             ('$OBJ_4', Object(size=3, color='yellow', shape='circle')),\n",
       "             ('$OBJ_6', Object(size=2, color='red', shape='square')),\n",
       "             ('$OBJ_7', Object(size=2, color='green', shape='circle')),\n",
       "             ('$OBJ_8', Object(size=1, color='green', shape='box'))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_world['obj_map']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'vector': '001000100100',\n",
       "  'position': {'row': '2', 'column': '4'},\n",
       "  'object': {'shape': 'square', 'color': 'blue', 'size': '3'}},\n",
       " '1': {'vector': '001010000001',\n",
       "  'position': {'row': '0', 'column': '1'},\n",
       "  'object': {'shape': 'circle', 'color': 'yellow', 'size': '3'}},\n",
       " '2': {'vector': '001000010010',\n",
       "  'position': {'row': '0', 'column': '3'},\n",
       "  'object': {'shape': 'box', 'color': 'green', 'size': '3'}},\n",
       " '3': {'vector': '001000100010',\n",
       "  'position': {'row': '0', 'column': '5'},\n",
       "  'object': {'shape': 'square', 'color': 'green', 'size': '3'}},\n",
       " '4': {'vector': '001010000001',\n",
       "  'position': {'row': '0', 'column': '0'},\n",
       "  'object': {'shape': 'circle', 'color': 'yellow', 'size': '3'}},\n",
       " '5': {'vector': '010000101000',\n",
       "  'position': {'row': '3', 'column': '5'},\n",
       "  'object': {'shape': 'square', 'color': 'red', 'size': '2'}},\n",
       " '6': {'vector': '010010000010',\n",
       "  'position': {'row': '2', 'column': '1'},\n",
       "  'object': {'shape': 'circle', 'color': 'green', 'size': '2'}},\n",
       " '7': {'vector': '001001000010',\n",
       "  'position': {'row': '3', 'column': '2'},\n",
       "  'object': {'shape': 'cylinder', 'color': 'green', 'size': '3'}},\n",
       " '8': {'vector': '100000010010',\n",
       "  'position': {'row': '5', 'column': '3'},\n",
       "  'object': {'shape': 'box', 'color': 'green', 'size': '1'}}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulator._world.get_current_situation().to_representation()[\"placed_objects\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {1:2, 3:4, 5:6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

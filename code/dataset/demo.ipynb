{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple, OrderedDict\n",
    "import itertools\n",
    "import os\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "from typing import List\n",
    "from typing import Dict\n",
    "import random\n",
    "from itertools import product\n",
    "import copy\n",
    "import re\n",
    "import random\n",
    "\n",
    "from utils import one_hot\n",
    "from utils import generate_possible_object_names\n",
    "from utils import numpy_array_to_image\n",
    "\n",
    "from vocabulary import *\n",
    "from object_vocabulary import *\n",
    "from world import *\n",
    "from grammer import *\n",
    "from simulator import *\n",
    "from relation_graph import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test out the vocabulary\n",
    "intransitive_verbs = [\"walk\"]\n",
    "transitive_verbs = [\"push\", \"pull\"]\n",
    "adverbs = [\"while zigzagging\", \"while spinning\", \"cautiously\", \"hesitantly\"]\n",
    "nouns = [\"circle\", \"cylinder\", \"square\", \"box\"]\n",
    "color_adjectives = [\"red\", \"blue\", \"green\", \"yellow\"]\n",
    "size_adjectives = [\"big\", \"small\"]\n",
    "relative_pronouns = [\"that is\"]\n",
    "relation_clauses = [\"in the same row as\", \n",
    "                    \"in the same column as\", \n",
    "                    \"in the same color as\", \n",
    "                    \"in the same shape as\", \n",
    "                    \"in the same size as\",\n",
    "                    \"inside of\"]\n",
    "vocabulary = Vocabulary.initialize(intransitive_verbs=intransitive_verbs,\n",
    "                                   transitive_verbs=transitive_verbs, adverbs=adverbs, nouns=nouns,\n",
    "                                   color_adjectives=color_adjectives,\n",
    "                                   size_adjectives=size_adjectives, \n",
    "                                   relative_pronouns=relative_pronouns, \n",
    "                                   relation_clauses=relation_clauses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test out the object vocab\n",
    "min_object_size = 1\n",
    "max_object_size = 4\n",
    "object_vocabulary = ObjectVocabulary(shapes=vocabulary.get_semantic_shapes(),\n",
    "                                     colors=vocabulary.get_semantic_colors(),\n",
    "                                     min_size=min_object_size, max_size=max_object_size)\n",
    "# object_vocabulary.generate_objects()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Situtation Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test out situation repr\n",
    "TEST_SITUATION_1 = Situation(grid_size=15, agent_position=Position(row=7, column=2), agent_direction=INT_TO_DIR[0],\n",
    "                             target_object=PositionedObject(object=Object(size=2, color='red', shape='circle'),\n",
    "                                                            position=Position(row=10, column=4),\n",
    "                                                            vector=np.array([1, 0, 1])),\n",
    "                             placed_objects=[PositionedObject(object=Object(size=2, color='red', shape='circle'),\n",
    "                                                              position=Position(row=10, column=4),\n",
    "                                                              vector=np.array([1, 0, 1])),\n",
    "                                             PositionedObject(object=Object(size=4, color='green', shape='circle'),\n",
    "                                                              position=Position(row=3, column=12),\n",
    "                                                              vector=np.array([0, 1, 0]))], carrying=None)\n",
    "# TEST_SITUATION_1.to_representation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PositionedObject(object=Object(size=4, color='green', shape='box'), position=Position(column=12, row=3), vector=array([0, 1, 0]), overflow=True, overlap=True)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test out our new object definition\n",
    "PositionedObject(object=Object(size=4, color='green', shape='box'),\n",
    "                 position=Position(row=3, column=12),\n",
    "                 vector=np.array([0, 1, 0]), overflow=True, overlap=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### World Module with Mini-Gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test out the world\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import os\n",
    "os.environ['QT_QPA_PLATFORM']='offscreen'\n",
    "\n",
    "world = World(grid_size=3, colors=vocabulary.get_semantic_colors(),\n",
    "              object_vocabulary=object_vocabulary,\n",
    "              shapes=vocabulary.get_semantic_shapes(),\n",
    "              save_directory=\"./tmp/\")\n",
    "\n",
    "world.place_object(Object(size=2, color=\"green\", shape=\"box\"), position=Position(row=1, column=1))\n",
    "world.place_object(Object(size=2, color=\"red\", shape=\"box\"), position=Position(row=0, column=0))\n",
    "_ = world.render_simple()\n",
    "world.position_taken(position=Position(row=0, column=0), condition=\"box\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "world = World(grid_size=6, colors=vocabulary.get_semantic_colors(),\n",
    "              object_vocabulary=object_vocabulary,\n",
    "              shapes=vocabulary.get_semantic_shapes(),\n",
    "              save_directory=\"./tmp/\")\n",
    "\n",
    "# try to place an object on to the map\n",
    "world.clear_situation()\n",
    "# world.place_object(Object(size=4, color=\"green\", shape=\"box\"), position=Position(row=3, column=3))\n",
    "world.place_object(Object(size=2, color=\"green\", shape=\"box\"), position=Position(row=2, column=2))\n",
    "world.place_object(Object(size=2, color=\"green\", shape=\"box\"), position=Position(row=1, column=1))\n",
    "world.place_object(Object(size=3, color=\"red\", shape=\"cylinder\"), position=Position(row=3, column=2))\n",
    "world.place_agent_at(Position(row=5, column=2))\n",
    "\n",
    "_ = world.render_simple()\n",
    "\n",
    "verb = \"push\"\n",
    "adverb = \"cautiously\"\n",
    "\n",
    "# Direct walk.\n",
    "action = \"walk\" # this is definit!\n",
    "primitive_command = vocabulary.translate_word(action)\n",
    "target_position = Position(row=3, column=2)\n",
    "# simulator._world.get_current_situation().to_dict()[\"target_object\"].position\n",
    "world.go_to_position(position=target_position, manner=adverb, primitive_command=primitive_command)\n",
    "\n",
    "# Object actions.\n",
    "if True:\n",
    "    semantic_action = vocabulary.translate_word(verb)\n",
    "    world.move_object_to_wall(action=semantic_action, manner=adverb)\n",
    "target_commands, target_demonstration = world.get_current_observations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = world.render_simple()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReaSCAN Grammer Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['push', 'pull', 'walk']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammer = Grammer(vocabulary)\n",
    "vocabulary.get_transitive_verbs() + vocabulary.get_intransitive_verbs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammer_pattern = '$OBJ_0 ^ $OBJ_1 & $OBJ_2'\n",
    "\n",
    "relations = grammer.sample_object_relation_grammer(\n",
    "    '$OBJ_0', \n",
    "    grammer.build_dependency_graph(grammer_pattern))\n",
    "\n",
    "command_structs = []\n",
    "for relation in relations:\n",
    "    obj_pattern_map = relation[0]\n",
    "    rel_map = relation[1]\n",
    "    grammer_bindings = grammer.grounding_grammer_with_vocabulary(grammer_pattern, obj_pattern_map, rel_map)\n",
    "    for obj_map in grammer_bindings:\n",
    "        # here, we also sample the verb and adverb bindings!\n",
    "        \n",
    "        command_struct = {\n",
    "            \"obj_pattern_map\" : obj_pattern_map,\n",
    "            \"rel_map\" : rel_map,\n",
    "            \"obj_map\" : obj_map,\n",
    "            \"grammer_pattern\" : grammer_pattern,\n",
    "            \"adverb\" : random.choice(vocabulary.get_adverbs()),\n",
    "            \"verb\" : random.choice(vocabulary.get_transitive_verbs() + vocabulary.get_intransitive_verbs()),\n",
    "        }\n",
    "        command_structs += [command_struct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# command_struct_stats = get_command_struct_statistics(command_structs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReaSCAN Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = Simulator(\n",
    "    object_vocabulary, vocabulary, \n",
    "    grid_size=6, \n",
    "    n_object_max=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_pattern_map = {'$OBJ_0': '$ABS_SHAPE', '$OBJ_1': '$SHAPE', '$OBJ_2': '$SHAPE'}\n",
    "rel_map = {('$OBJ_0', '$OBJ_1'): '$SAME_SHAPE', ('$OBJ_0', '$OBJ_2'): '$IS_INSIDE'}\n",
    "obj_map = {'$OBJ_0': 'object', '$OBJ_1': 'circle', '$OBJ_2': 'box'}\n",
    "grammer_pattern = '$OBJ_0 ^ $OBJ_1 & $OBJ_2'\n",
    "verb = \"push\"\n",
    "adverb = \"slowly\"\n",
    "sampled_world = simulator.sample_situations_from_grounded_grammer(\n",
    "    copy.deepcopy(grammer_pattern), \n",
    "    copy.deepcopy(obj_pattern_map), \n",
    "    copy.deepcopy(rel_map), \n",
    "    copy.deepcopy(obj_map),\n",
    "    is_plot=True,\n",
    "    include_relation_distractor=False, \n",
    "    include_attribute_distractor=False, \n",
    "    include_isomorphism_distractor=False, \n",
    "    include_random_distractor=False,\n",
    "    full_relation_probability=0.5,\n",
    "    debug=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_transitive = False\n",
    "if verb in simulator.vocabulary.get_transitive_verbs():\n",
    "    is_transitive = True\n",
    "\n",
    "# Direct walk.\n",
    "action = \"walk\" # this is definit!\n",
    "primitive_command = simulator.vocabulary.translate_word(action)\n",
    "target_position = sampled_world[\"situation\"].target_object.position\n",
    "\n",
    "simulator._world.go_to_position(position=target_position, manner=adverb, primitive_command=primitive_command)\n",
    "\n",
    "# Object actions.\n",
    "if is_transitive:\n",
    "    semantic_action = simulator.vocabulary.translate_word(verb)\n",
    "    simulator._world.move_object_to_wall(action=semantic_action, manner=adverb)\n",
    "target_commands, target_demonstration = simulator._world.get_current_observations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End-to-end Task Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulator(object):\n",
    "    \"\"\"\n",
    "    This convert generated grammers into a world/situation.\n",
    "    \n",
    "    Sample Situation:\n",
    "    Situation(grid_size=15, agent_position=Position(row=7, column=2), agent_direction=INT_TO_DIR[0],\n",
    "              target_object=PositionedObject(object=Object(size=2, color='red', shape='circle'),\n",
    "                                             position=Position(row=10, column=4),\n",
    "                                             vector=np.array([1, 0, 1])),\n",
    "              placed_objects=[PositionedObject(object=Object(size=2, color='red', shape='circle'),\n",
    "                                               position=Position(row=10, column=4),\n",
    "                                               vector=np.array([1, 0, 1])),\n",
    "                              PositionedObject(object=Object(size=4, color='green', shape='circle'),\n",
    "                                               position=Position(row=3, column=12),\n",
    "                                               vector=np.array([0, 1, 0]))], carrying=None)\n",
    "                                               \n",
    "    Sample Placement in the World:\n",
    "    world.place_object(Object(size=2, color=\"green\", shape=\"box\"), position=Position(row=2, column=2))\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, object_vocabulary, vocabulary, grid_size=6, \n",
    "                 n_object_min=6,\n",
    "                 n_object_max=12,\n",
    "                 save_directory=\"./tmp/\"):\n",
    "        self.object_vocabulary = object_vocabulary\n",
    "        self.vocabulary = vocabulary\n",
    "        self.grid_size = grid_size\n",
    "        self.n_object_min = n_object_min\n",
    "        self.n_object_max = n_object_max\n",
    "\n",
    "        self._world = World(grid_size=grid_size, colors=vocabulary.get_semantic_colors(),\n",
    "                            object_vocabulary=object_vocabulary,\n",
    "                            shapes=vocabulary.get_semantic_shapes(),\n",
    "                            save_directory=save_directory)\n",
    "        self._world.clear_situation()\n",
    "    \n",
    "    def sample_object_shape(\n",
    "        self, obj_grammer, obj_pattern, obj_str, rel_map, \n",
    "        is_root, shape_map\n",
    "    ):\n",
    "        obj_pattern = obj_pattern.split(\" \")\n",
    "        obj_str = obj_str.split(\" \")\n",
    "        shape = None\n",
    "        if len(obj_str) == 3:\n",
    "            shape = obj_str[2]\n",
    "        elif len(obj_str) == 2:\n",
    "            shape = obj_str[1]\n",
    "        elif len(obj_str) == 1:\n",
    "            # it must be the object\n",
    "            shape = obj_str[0]\n",
    "        # Final handling for the shape.\n",
    "        if shape == \"object\":\n",
    "            shape = self.object_vocabulary.sample_shape()\n",
    "            \n",
    "        # Override size, color and shape based on relations.\n",
    "        if not is_root:\n",
    "            # Go through the rel.\n",
    "            for pair, rel in rel_map.items():\n",
    "                if obj_grammer == pair[-1]:\n",
    "                    if pair[0] in shape_map.keys():\n",
    "                        # if this obj is acting as a child node\n",
    "                        # then have to complain with parent node\n",
    "                        if rel == \"$SAME_SHAPE\":\n",
    "                            shape = shape_map[pair[0]]\n",
    "                        elif rel == \"$IS_INSIDE\":\n",
    "                            shape = \"box\"\n",
    "        return shape\n",
    "    \n",
    "    def sample_object_spec(\n",
    "        self, obj_grammer, obj_pattern, obj_str, rel_map, \n",
    "        is_root, obj_placed_map, \n",
    "        size_restriction_map=None,\n",
    "        mentioned_shapes=None\n",
    "    ):\n",
    "        obj_pattern = obj_pattern.split(\" \")\n",
    "        obj_str = obj_str.split(\" \")\n",
    "        color = None\n",
    "        size = None\n",
    "        shape = None\n",
    "        if len(obj_str) == 3:\n",
    "            size = self.object_vocabulary.sample_size_with_prior(prior=obj_str[0])\n",
    "            color = obj_str[1]\n",
    "            shape = obj_str[2]\n",
    "        elif len(obj_str) == 2:\n",
    "            if \"$COLOR\" in obj_pattern: # color + shape.\n",
    "                size = self.object_vocabulary.sample_size()\n",
    "                color = obj_str[0]\n",
    "                shape = obj_str[1]\n",
    "            elif \"$SIZE\" in obj_pattern: # size + shape.\n",
    "                size = self.object_vocabulary.sample_size_with_prior(prior=obj_str[0])\n",
    "                color = self.object_vocabulary.sample_color()\n",
    "                shape = obj_str[1]\n",
    "        elif len(obj_str) == 1:\n",
    "            # it must be the object\n",
    "            size = self.object_vocabulary.sample_size()\n",
    "            color = self.object_vocabulary.sample_color()\n",
    "            shape = obj_str[0]\n",
    "        # Final handling for the shape.\n",
    "        if shape == \"object\":\n",
    "            # WARNING: this is a corner case you will hit\n",
    "            # if your logic chain is long, you may need to\n",
    "            # consider remove object option!\n",
    "            if mentioned_shapes != None and len(mentioned_shapes) == self.object_vocabulary._shapes:\n",
    "                assert False\n",
    "            if is_root:\n",
    "                shape = self.object_vocabulary.sample_shape() # _exclude=mentioned_shapes\n",
    "            else:\n",
    "                shape = self.object_vocabulary.sample_shape()\n",
    "                \n",
    "        return Object(color=color,size=size,shape=shape)\n",
    "                    \n",
    "    def sample_object_position(\n",
    "        self, sampled_obj, root, obj_grammer, \n",
    "        rel_map, obj_placed_map, \n",
    "        obj_position_map\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Return:\n",
    "        -1: No position can be sampled.\n",
    "        \"\"\"\n",
    "        # If it is the first node, we directly return.\n",
    "        if sampled_obj.shape != \"box\":\n",
    "            obj_random_pos = self._world.sample_position_complex(\n",
    "                condition=\"normal\", sample_one=True\n",
    "            )\n",
    "        else:\n",
    "            obj_random_pos = self._world.sample_position_complex(\n",
    "                condition=\"box\", box_size=sampled_obj.size, sample_one=True\n",
    "            )\n",
    "        if obj_grammer == root:\n",
    "            return obj_random_pos # for this round, the root node can be placed anywhere!\n",
    "        \n",
    "        # For some relations, we might need to resample positions!\n",
    "        for pair, rel in rel_map.items():\n",
    "            if obj_grammer == pair[-1]:\n",
    "                if not pair[0] in obj_placed_map.keys():\n",
    "                    assert False # this should never be the case! the position sampling in from top to bottom!\n",
    "\n",
    "                # if this obj is acting as a child node\n",
    "                # then have to complain with parent node\n",
    "                if rel == \"$SAME_ROW\":\n",
    "                    row = obj_position_map[pair[0]].row\n",
    "                    for i in range(0, self.grid_size):\n",
    "                        proposed_position = Position(row=row, column=i)\n",
    "                        if not self._world.position_taken(proposed_position, condition=\"normal\"):\n",
    "                            return proposed_position\n",
    "                    return -1 # too many objs\n",
    "                if rel == \"$SAME_COLUMN\":\n",
    "                    col = obj_position_map[pair[0]].column\n",
    "                    for i in range(0, self.grid_size):\n",
    "                        proposed_position = Position(row=i, column=col)\n",
    "                        if not self._world.position_taken(proposed_position, condition=\"normal\"):\n",
    "                            return proposed_position\n",
    "                    return -1 # too many objs\n",
    "                elif rel == \"$IS_INSIDE\":\n",
    "                    # we need to make sure enclosure\n",
    "                    assert sampled_obj.shape == \"box\"\n",
    "                    size = sampled_obj.size\n",
    "                    potential_positions = []\n",
    "                    row = obj_position_map[pair[0]].row\n",
    "                    col = obj_position_map[pair[0]].column\n",
    "                    for i in range(0, self.grid_size-size+1):\n",
    "                        for j in range(0, self.grid_size-size+1):\n",
    "                            # we need to cover the is inside obj\n",
    "                            if row >= i and row < i + sampled_obj.size and \\\n",
    "                                col >= j and col < j + sampled_obj.size:\n",
    "                                proposed_position = Position(row=i, column=j)\n",
    "                                if not self._world.position_taken(proposed_position, condition=\"box\"):\n",
    "                                    potential_positions.append(Position(row=i, column=j))\n",
    "                    random.shuffle(potential_positions)\n",
    "                    if len(potential_positions) < 1:\n",
    "                        return -1\n",
    "                    return potential_positions[0]\n",
    "\n",
    "        return obj_random_pos\n",
    "    \n",
    "    def sample_random_object_spec(\n",
    "        self, \n",
    "        size_exclude=None, \n",
    "        color_exclude=None, shape_exclude=None\n",
    "    ):\n",
    "        d_size = self.object_vocabulary.sample_size(_exclude=size_exclude)\n",
    "        d_color = self.object_vocabulary.sample_color(_exclude=color_exclude)\n",
    "        d_shape = self.object_vocabulary.sample_shape(_exclude=shape_exclude)\n",
    "        return Object(color=d_color,size=d_size,shape=d_shape)\n",
    "    \n",
    "    def place_distractor_from_dict(\n",
    "        self, distractors_dict, \n",
    "        obj_placed_map, obj_position_map, \n",
    "        debug=False, \n",
    "        special_shape_size_bound=None,\n",
    "        mentioned_shapes=None,\n",
    "    ):\n",
    "        if debug:\n",
    "            import pprint\n",
    "            pp = pprint.PrettyPrinter(indent=4)\n",
    "            pp.pprint(distractors_dict)\n",
    "        distractor_root = f\"$OBJ_{len(obj_placed_map)}\"\n",
    "        success = True\n",
    "        distractors_obj_map = distractors_dict[\"obj_map\"]\n",
    "        distractors_rel_map = distractors_dict[\"rel_map\"]\n",
    "        distractors_obj_pattern_map = distractors_dict[\"obj_pattern_map\"]\n",
    "        distractors_size_map = distractors_dict[\"size_map\"]\n",
    "        \n",
    "        distractors_sampled_obj_map = {}\n",
    "        for dis_grammer, dis_str in distractors_obj_map.items():\n",
    "            # 1. Sample object.\n",
    "            sampled_dis = self.sample_object_spec(\n",
    "                dis_grammer,\n",
    "                distractors_obj_pattern_map[dis_grammer], \n",
    "                dis_str, distractors_rel_map, \n",
    "                is_root=dis_grammer==distractor_root, \n",
    "                obj_placed_map=obj_placed_map,\n",
    "                mentioned_shapes=mentioned_shapes,\n",
    "            )\n",
    "            # 1.1. Update the size of the object if needed.\n",
    "            if dis_grammer in distractors_size_map.keys():\n",
    "                sampled_dis = Object(\n",
    "                    color=sampled_dis.color,\n",
    "                    size=distractors_size_map[dis_grammer],\n",
    "                    shape=sampled_dis.shape\n",
    "                )\n",
    "            # 1.2. Another pass of override by using global constraints.\n",
    "            special_shape_super = sampled_dis.shape\n",
    "            special_shape_sub = sampled_dis.color + \" \" + sampled_dis.shape\n",
    "            # e.g., small circle exists in the command, then any colored circle needs to be constrain\n",
    "            if special_shape_super in special_shape_size_bound.keys():\n",
    "                if \"small\" in dis_str:\n",
    "                    updated_size = special_shape_size_bound[special_shape_super][0]\n",
    "                else:\n",
    "                    updated_size = special_shape_size_bound[special_shape_super][1]\n",
    "                sampled_dis = Object(\n",
    "                    color=sampled_dis.color,\n",
    "                    size=updated_size,\n",
    "                    shape=sampled_dis.shape\n",
    "                )\n",
    "            elif special_shape_sub in special_shape_size_bound.keys():\n",
    "                if \"small\" in dis_str:\n",
    "                    updated_size = special_shape_size_bound[special_shape_sub][0]\n",
    "                else:\n",
    "                    updated_size = special_shape_size_bound[special_shape_sub][1]\n",
    "                sampled_dis = Object(\n",
    "                    color=sampled_dis.color,\n",
    "                    size=updated_size,\n",
    "                    shape=sampled_dis.shape\n",
    "                )\n",
    "            else:\n",
    "                pass # Do nothing.\n",
    "            distractors_sampled_obj_map[dis_grammer] = sampled_dis\n",
    "        \n",
    "        # 2. Update it using relationships.\n",
    "        for pair, rel in distractors_rel_map.items():\n",
    "            if rel == \"$SAME_SHAPE\":\n",
    "                pass\n",
    "            elif rel == \"$SAME_COLOR\":\n",
    "                pass\n",
    "            elif rel == \"$SAME_SIZE\":\n",
    "                # Update the src node size information.\n",
    "                size = distractors_sampled_obj_map[pair[1]].size\n",
    "                distractors_sampled_obj_map[pair[0]] = Object(\n",
    "                    color=distractors_sampled_obj_map[pair[0]].color,\n",
    "                    size=size,\n",
    "                    shape=distractors_sampled_obj_map[pair[0]].shape\n",
    "                )\n",
    "            elif rel == \"$IS_INSIDE\":\n",
    "                pass # Do nothing!\n",
    "\n",
    "        placed_dis_grammer = []\n",
    "        for dis_grammer, sampled_dis in distractors_sampled_obj_map.items():\n",
    "            # 2. Place on the world map.\n",
    "            sampled_pos = self.sample_object_position(\n",
    "                sampled_dis, distractor_root, \n",
    "                dis_grammer, distractors_rel_map, \n",
    "                obj_placed_map, obj_position_map\n",
    "            )\n",
    "\n",
    "            if sampled_dis == -1 or sampled_pos == -1:\n",
    "                # We allow partial placement as they add difficulties!\n",
    "                return False\n",
    "\n",
    "            return_code = self._world.place_object(\n",
    "                sampled_dis, \n",
    "                position=sampled_pos, target=False # Distractor is never the target!\n",
    "            )\n",
    "            if return_code == -1:\n",
    "                print(obj_placed_map)\n",
    "                print(obj_position_map)\n",
    "                print(distractors_dict)\n",
    "                print(self._world.grid.get(sampled_pos.column, sampled_pos.row))\n",
    "                FAIL()\n",
    "            obj_placed_map[dis_grammer] = sampled_dis\n",
    "            obj_position_map[dis_grammer] = sampled_pos\n",
    "            \n",
    "        return True\n",
    "    \n",
    "    def sample_situations_from_grounded_grammer(\n",
    "        self, grammer_pattern, \n",
    "        obj_pattern_map, rel_map, obj_map, root=\"$OBJ_0\", \n",
    "        is_plot=False, \n",
    "        include_random_distractor=False, \n",
    "        include_relation_distractor=False, \n",
    "        include_attribute_distractor=False, \n",
    "        include_isomorphism_distractor=False, \n",
    "        full_relation_probability=0.5,\n",
    "        debug=False,\n",
    "    ):\n",
    "        # Clear current world.\n",
    "        self._world.clear_situation()\n",
    "        \n",
    "        # Start placing objects with specs.\n",
    "        obj_placed_map = OrderedDict({})\n",
    "        obj_position_map = OrderedDict({})\n",
    "        referred_obj = root\n",
    "        \n",
    "        # Preliminary size check!\n",
    "        \"\"\"\n",
    "        Here is a list of potential internal conflicts:\n",
    "        (1) ... to a small box ... to a yellow box ...\n",
    "        Explain: we need to adjust the size of two boxes\n",
    "        so that small box has 1 size, and all other boxes \n",
    "        have the same other size.\n",
    "        There will at max two different size of same type objects.\n",
    "        \n",
    "        So this is the rule:\n",
    "        For 1 type of shape, max two different sizes.\n",
    "        \"\"\"\n",
    "        # Ok, we need to determine shapes first!\n",
    "        # Even there is any abstract object, the\n",
    "        # shape is now determined.\n",
    "        object_map = {}\n",
    "        mentioned_shapes = set([]) # this is used to sample shapes for object.\n",
    "        for obj_grammer, obj_str in obj_map.items():\n",
    "            shape = self.extract_shape(obj_str)\n",
    "            if shape != \"\":\n",
    "                mentioned_shapes.add(shape)\n",
    "        for obj_grammer, obj_str in obj_map.items():\n",
    "            # 1. Sample object.\n",
    "            sampled_obj = self.sample_object_spec(\n",
    "                obj_grammer,\n",
    "                obj_pattern_map[obj_grammer], obj_str, rel_map, \n",
    "                is_root=obj_grammer==root, \n",
    "                obj_placed_map=object_map,\n",
    "                mentioned_shapes=mentioned_shapes,\n",
    "            )\n",
    "            object_map[obj_grammer] = sampled_obj\n",
    "        \n",
    "        # Next, we update all of them based on relations.\n",
    "        # Final pass, we need to change attributes of objects based\n",
    "        # on relations.\n",
    "        # Here, we only change size!\n",
    "        for pair, rel in rel_map.items():\n",
    "            if rel == \"$SAME_SHAPE\":\n",
    "                # Update the src node shape information.\n",
    "                shape = object_map[pair[1]].shape\n",
    "                object_map[pair[0]] = Object(\n",
    "                    color=object_map[pair[0]].color,\n",
    "                    size=object_map[pair[0]].size,\n",
    "                    shape=shape\n",
    "                )\n",
    "                pass\n",
    "            elif rel == \"$SAME_COLOR\":\n",
    "                # Update the src node color information.\n",
    "                color = object_map[pair[1]].color\n",
    "                object_map[pair[0]] = Object(\n",
    "                    color=color,\n",
    "                    size=object_map[pair[0]].size,\n",
    "                    shape=object_map[pair[0]].shape\n",
    "                )\n",
    "                pass\n",
    "            elif rel == \"$SAME_SIZE\":\n",
    "                # Update the src node size information.\n",
    "                size = object_map[pair[1]].size\n",
    "                object_map[pair[0]] = Object(\n",
    "                    color=object_map[pair[0]].color,\n",
    "                    size=size,\n",
    "                    shape=object_map[pair[0]].shape\n",
    "                )\n",
    "            elif rel == \"$IS_INSIDE\":\n",
    "                pass\n",
    "            \n",
    "        # Then, we will determine size bounds.\n",
    "        special_shape_size_bound = {}\n",
    "        for obj_grammer, obj_pattern in obj_pattern_map.items():\n",
    "            \n",
    "            small_size = random.randint(\n",
    "                self.object_vocabulary._min_size, \n",
    "                self.object_vocabulary._max_size-1\n",
    "            )\n",
    "            big_size = random.randint(\n",
    "                small_size+1, \n",
    "                self.object_vocabulary._max_size\n",
    "            )\n",
    "            \n",
    "            if \"$SIZE\" in obj_pattern and \"$COLOR\" in obj_pattern:\n",
    "                special_shape = object_map[obj_grammer].color + \" \" + object_map[obj_grammer].shape\n",
    "                if object_map[obj_grammer].shape in special_shape_size_bound.keys():\n",
    "                    # e.g., small circle exists\n",
    "                    special_shape_size_bound[special_shape] = special_shape_size_bound[object_map[obj_grammer].shape]\n",
    "                else:\n",
    "                    # e.g., small yellow circle\n",
    "                    special_shape_size_bound[special_shape] = [small_size, big_size]\n",
    "            elif \"$SIZE\" in obj_pattern and not \"$COLOR\" in obj_pattern:\n",
    "                # e.g., small circle\n",
    "                # overwrite any existing bounds.\n",
    "                special_shape = object_map[obj_grammer].shape\n",
    "                for ss, bound in special_shape_size_bound.items():\n",
    "                    if special_shape in ss:\n",
    "                        special_shape_size_bound[ss] = [small_size, big_size]\n",
    "                # for shape, it adds.\n",
    "                special_shape_size_bound[special_shape] = [small_size, big_size]\n",
    "                # for non-sized shape, it also adds as long as shape is the same.\n",
    "                for obj_grammer, obj_pattern in obj_pattern_map.items():\n",
    "                    if special_shape in obj_map[obj_grammer]:\n",
    "                        if \"$COLOR\" in obj_pattern:\n",
    "                            special_shape = object_map[obj_grammer].color + \" \" + object_map[obj_grammer].shape\n",
    "                            special_shape_size_bound[special_shape] = [small_size, big_size]\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        # Update object size based on global scanning results.\n",
    "        updated_object_map = {}\n",
    "        for obj_grammer, obj_pattern in obj_pattern_map.items():\n",
    "\n",
    "            special_shape_super = object_map[obj_grammer].shape\n",
    "            special_shape_sub = object_map[obj_grammer].color + \" \" + object_map[obj_grammer].shape\n",
    "            \n",
    "            # e.g., small circle exists in the command, then any colored circle needs to be constrain\n",
    "            if special_shape_super in special_shape_size_bound.keys():\n",
    "                if \"small\" in obj_map[obj_grammer]:\n",
    "                    updated_size = special_shape_size_bound[special_shape_super][0]\n",
    "                else:\n",
    "                    updated_size = special_shape_size_bound[special_shape_super][1]\n",
    "                updated_object_map[obj_grammer] = Object(\n",
    "                    color=object_map[obj_grammer].color,\n",
    "                    size=updated_size,\n",
    "                    shape=object_map[obj_grammer].shape\n",
    "                )\n",
    "            elif special_shape_sub in special_shape_size_bound.keys():\n",
    "                if \"small\" in obj_map[obj_grammer]:\n",
    "                    updated_size = special_shape_size_bound[special_shape_sub][0]\n",
    "                else:\n",
    "                    updated_size = special_shape_size_bound[special_shape_sub][1]\n",
    "                updated_object_map[obj_grammer] = Object(\n",
    "                    color=object_map[obj_grammer].color,\n",
    "                    size=updated_size,\n",
    "                    shape=object_map[obj_grammer].shape\n",
    "                )\n",
    "            else:\n",
    "                # If nothing exists in the special size map, then we don't need\n",
    "                # to alter the size.\n",
    "                updated_object_map[obj_grammer] = object_map[obj_grammer]\n",
    "\n",
    "        # Final pass, we need to change attributes of objects based\n",
    "        # on relations.\n",
    "        # Here, we only change size!\n",
    "        for pair, rel in rel_map.items():\n",
    "            if rel == \"$SAME_SHAPE\":\n",
    "                pass\n",
    "            elif rel == \"$SAME_COLOR\":\n",
    "                pass\n",
    "            elif rel == \"$SAME_SIZE\":\n",
    "                # Update the src node size information.\n",
    "                size = updated_object_map[pair[1]].size\n",
    "                updated_object_map[pair[0]] = Object(\n",
    "                    color=object_map[pair[0]].color,\n",
    "                    size=size,\n",
    "                    shape=object_map[pair[0]].shape\n",
    "                )\n",
    "            elif rel == \"$IS_INSIDE\":\n",
    "                pass\n",
    "        \n",
    "        # Next, we sample positions of all objects and place them.\n",
    "        for obj_grammer, obj_str in obj_map.items():\n",
    "            # 1. Sample object (bu fetching the updated one).\n",
    "            sampled_obj = updated_object_map[obj_grammer]\n",
    "            \n",
    "            # 2. Place on the world map.\n",
    "            sampled_pos = self.sample_object_position(\n",
    "                sampled_obj, root, obj_grammer, rel_map, \n",
    "                obj_placed_map, obj_position_map\n",
    "            )\n",
    "            \n",
    "            if sampled_obj == -1 or sampled_pos == -1:\n",
    "                assert False # we can assert false as it is impossible!\n",
    "        \n",
    "            self._world.place_object(\n",
    "                sampled_obj, \n",
    "                position=sampled_pos, target=obj_grammer==root\n",
    "            )\n",
    "            obj_placed_map[obj_grammer] = sampled_obj\n",
    "            obj_position_map[obj_grammer] = sampled_pos\n",
    "            \n",
    "        \"\"\"\n",
    "        Distractor Sampling Strategies and Design\n",
    "        \n",
    "        Giving a complex command as:\n",
    "        \"the small red circle(1) that is in the same row(a) \n",
    "        as a big green square(2) and that is in the same column(b) \n",
    "        as a small yellow cylinder(3).\"\n",
    "        \n",
    "        We have 4 types of distractors (objects):\n",
    "        - Attribute-based Distractors\n",
    "        - Relation-based Distractors\n",
    "        - Sytax-based Distractors\n",
    "        - Random Distractors\n",
    "        \n",
    "        For each type of distractors, we will modify the command\n",
    "        to generate a new command for distractors. Then, we will\n",
    "        ensure such every command-world pair needs to reason about\n",
    "        attribute, relation and syntax. \n",
    "        \n",
    "        There are some caveats around this design. Due to the \n",
    "        complexity of the command, to make sure\n",
    "        every attribute/relation is necessary becomes unfeasible. For\n",
    "        example, if we want to make \"small\" in \"the small red circle (1)\"\n",
    "        necessary, then, we need to put another non-\"small\" \"red circle\".\n",
    "        This is easy. However, if we want to make \"big\" in \"the big\n",
    "        green square\" necessary, we essentially need to sample another\n",
    "        set of objects (at max 3) that complies with a modified command\n",
    "        \"the small red circle(1) that is in the same row(a) \n",
    "        as a small green square(2*) and that is in the same column(b) \n",
    "        as a small yellow cylinder(3).\"\n",
    "        \n",
    "        Following this logic, if we want to make sure *every descriptor*\\\n",
    "        (i.e., every adjective) is necessary to identity the referent\n",
    "        target, we could flood the system easily with way too many\n",
    "        distractors that cannot fit in our grid world.\n",
    "        \n",
    "        On the other hand, the goal of having the distractors is to\n",
    "        have the system learn the importantce of relations, attributes\n",
    "        and linguistic syntax. So, are these distractors necessary?\n",
    "        Do we need to actually have an exhaustive list of distractors\n",
    "        for each command-world pair in order to have the model to learn\n",
    "        this? We propose the answer is No, but Yes in the dataset level. In\n",
    "        the command level, we will not make sure *every descriptor* is\n",
    "        necessary, but in the command level, we will make sure \n",
    "        *every descriptor* matters for at least some of the command.\n",
    "        Otherwise, the model may just completely ignores one part of\n",
    "        the command and relies on the rest.\n",
    "        \n",
    "        In our design, we ensure for each command-world pair, some attribute\n",
    "        and some relation and some syntax are needed. In the dataset\n",
    "        level, we ensure different attribute, relation and syntax are \n",
    "        weighted equally.\n",
    "        \n",
    "        We propose to sample distractors following the design below:\n",
    "        \n",
    "        For a command such as\n",
    "        \"A that is X B and that is Y C\"\n",
    "        (1) We generate two distractor commands: \"A that X B\"; and \"A that Y C\"\n",
    "        without guarantee all relations in the original command. This samples\n",
    "        4 distractors. This ensures X and Y are necessary!\n",
    "        \n",
    "        (2) Next, we need to ensure that if we change some descriptors for\n",
    "        A, B or C, referent target cannot be identified. For example, if\n",
    "        we change B from \"yellow square\" to \"blue square\" the referent target\n",
    "        should change. In this case, we need to sample a new set of {A,B,C}.\n",
    "        And if we do this for each object, this results in 9 new distractors.\n",
    "        If size is not selected, we potentially need 3 more distractors to\n",
    "        ground the size aspects.\n",
    "        \n",
    "        (3) Next, to ensure model learns linguistic syntax, instead of simple\n",
    "        BoW approach to represent the command, we would perform swap attributes\n",
    "        between objects. We pick a pair of objects, and swap attributes \n",
    "        randomly. This results in 3 more distractors.\n",
    "        \n",
    "        (1) + (2) + (3) results in at max 19 distractors for each command-world pair.\n",
    "        Plus the original 3 objects, we have in total 21 distractors.\n",
    "        This is still a lot higher than gSCAN which is at max about 12.\n",
    "        \n",
    "        Then, we design another way to sample distractors:\n",
    "        (1) We pick 1 relations from {X, Y}, and generate distracotrs: 3 distractors.\n",
    "        \n",
    "        (2) We pick 1 object from {A, B, C} and modify its attribute, sample 3 distractors.\n",
    "        if size is not selected for any object, we need to randomly sample non-relational\n",
    "        counterparts, at max 3.\n",
    "        \n",
    "        (3) Same, so 3.\n",
    "        \n",
    "        (1) + (2) + (3) results in 3 + 3 + 3 + 3 = 12, 12 + 3 -> at max 15. Is this doable?\n",
    "        \n",
    "        Test set. global v.s. local compositional generalization. In the test set, we \n",
    "        can pick different/more aspect of differeent/more obj that matter for the\n",
    "        correctly reasonings, and generate test cases with  more distractors.\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        Calling in this way to create distractors:\n",
    "\n",
    "        simulator.sample_distractor_grammer_by_relation(\n",
    "            grammer_pattern, \n",
    "            obj_pattern_map, \n",
    "            rel_map, \n",
    "            obj_map, \n",
    "            sampled_world\n",
    "        )\n",
    "        \"\"\"\n",
    "        temp_sampled_world = {\n",
    "            \"obj_map\" : obj_placed_map,\n",
    "            \"pos_map\" : obj_position_map,\n",
    "            \"referred_obj\" : referred_obj,\n",
    "            \"situation\" : copy.deepcopy(self._world.get_current_situation())\n",
    "        }\n",
    "        \n",
    "        # Three types of distractor sampling for different purposes:\n",
    "        # sample_distractor_grammer_by_relation()\n",
    "        # - We will edit one leaf node, so that it makes sure\n",
    "        #   the command is necessary!\n",
    "        # sample_distractor_grammer_by_size()\n",
    "        # - Size relatives need to be meaningful. We will add relational\n",
    "        #   objects to make sure.\n",
    "        # sample_distractor_grammer_by_isomorphism()\n",
    "        # - This is to ensure syntax learning.\n",
    "        \n",
    "        distractor_switch_map = OrderedDict({\n",
    "            \"relation\" : [],\n",
    "            \"attribute\" : False,\n",
    "            \"isomorphism\" : False, \n",
    "            \"random\" : False,\n",
    "        })\n",
    "        relation_distractors_dicts = [{\n",
    "            \"distractor_metadata\": {}\n",
    "        }]\n",
    "        attribute_distractors_dicts = [{\n",
    "            \"distractor_metadata\": {}\n",
    "        }]\n",
    "        isomorphism_distractors_dicts = [{\n",
    "            \"distractor_metadata\": {}\n",
    "        }]\n",
    "        \n",
    "        if random.random() < full_relation_probability:\n",
    "            full_relation_set=True\n",
    "        else:\n",
    "            full_relation_set=False\n",
    "            \n",
    "        obj_drafted_count = len(obj_placed_map)\n",
    "        if include_relation_distractor:\n",
    "            \"\"\"\n",
    "            Relation Distractors: Count=3*n, at max 6.\n",
    "            Relation Distractors (fast): Count=2*n, at max 4.\n",
    "            \"\"\"\n",
    "            relation_distractors_dicts = self.sample_distractor_grammer_by_relation_fast(\n",
    "                grammer_pattern, \n",
    "                obj_pattern_map, \n",
    "                rel_map, \n",
    "                obj_map, \n",
    "                temp_sampled_world,\n",
    "                obj_base_count=len(obj_placed_map),\n",
    "                full_set=full_relation_set,\n",
    "            )\n",
    "            if len(relation_distractors_dicts) == 0:\n",
    "                pass # Size distractor is not applicable \n",
    "            else:\n",
    "                distractor_switch = []\n",
    "                is_full_relation = True\n",
    "                for distractors_dict in relation_distractors_dicts:\n",
    "                    obj_drafted_count += len(distractors_dict[\"obj_map\"])\n",
    "                    succeed = self.place_distractor_from_dict(\n",
    "                        distractors_dict, \n",
    "                        obj_placed_map, \n",
    "                        obj_position_map,\n",
    "                        debug=debug,\n",
    "                        special_shape_size_bound=special_shape_size_bound,\n",
    "                        mentioned_shapes=mentioned_shapes,\n",
    "                        # This is needed as maybe distractors also \n",
    "                        # need to be bounded by global constraints.\n",
    "                    )\n",
    "                    if succeed:\n",
    "                        distractor_switch_map[\"relation\"].append(True)\n",
    "                    else:\n",
    "                        distractor_switch_map[\"relation\"].append(False)\n",
    "\n",
    "        if include_attribute_distractor:\n",
    "            \"\"\"\n",
    "            Attribution Distractors: Count=3-6.\n",
    "            \"\"\"\n",
    "            # If the command is small, we can overwrite this\n",
    "            if len(rel_map) <= 1:\n",
    "                full_set = True\n",
    "            else:\n",
    "                full_set = not full_relation_set\n",
    "            attribute_distractors_dicts = self.sample_distractor_grammer_by_attribute(\n",
    "                grammer_pattern, \n",
    "                obj_pattern_map, \n",
    "                rel_map, \n",
    "                obj_map, \n",
    "                temp_sampled_world,\n",
    "                special_shape_size_bound,\n",
    "                obj_base_count=obj_drafted_count, # This is important, as previous draft may success but placement can fail!\n",
    "                full_set=full_set,\n",
    "            )\n",
    "            if len(attribute_distractors_dicts) == 0:\n",
    "                pass # Size distractor is not applicable \n",
    "            else:\n",
    "                obj_drafted_count += len(attribute_distractors_dicts[0][\"obj_map\"])\n",
    "                succeed = self.place_distractor_from_dict(\n",
    "                    attribute_distractors_dicts[0], \n",
    "                    obj_placed_map, \n",
    "                    obj_position_map,\n",
    "                    debug=debug,\n",
    "                    special_shape_size_bound=special_shape_size_bound,\n",
    "                    mentioned_shapes=mentioned_shapes,\n",
    "                    # This is needed as maybe distractors also \n",
    "                    # need to be bounded by global constraints.\n",
    "                )\n",
    "                if succeed:\n",
    "                    distractor_switch_map[\"attribute\"] = True # If one time it is true, it is true.\n",
    "                else:\n",
    "                    pass\n",
    "        \n",
    "        if include_isomorphism_distractor:\n",
    "            \"\"\"\n",
    "            Syntax Distractors: Count=3.\n",
    "            \"\"\"\n",
    "            isomorphism_distractors_dicts = self.sample_distractor_grammer_by_isomorphism(\n",
    "                grammer_pattern, \n",
    "                obj_pattern_map, \n",
    "                rel_map, \n",
    "                obj_map, \n",
    "                temp_sampled_world,\n",
    "                obj_base_count=obj_drafted_count # This is important, as previous draft may success but placement can fail!\n",
    "            )\n",
    "            if len(isomorphism_distractors_dicts) == 0:\n",
    "                pass # Size distractor is not applicable \n",
    "            else:\n",
    "                obj_drafted_count += len(isomorphism_distractors_dicts[0][\"obj_map\"])\n",
    "                succeed = self.place_distractor_from_dict(\n",
    "                    isomorphism_distractors_dicts[0], \n",
    "                    obj_placed_map, \n",
    "                    obj_position_map,\n",
    "                    debug=debug,\n",
    "                    special_shape_size_bound=special_shape_size_bound,\n",
    "                    mentioned_shapes=mentioned_shapes,\n",
    "                    # This is needed as maybe distractors also \n",
    "                    # need to be bounded by global constraints.\n",
    "                )\n",
    "                if succeed:\n",
    "                    distractor_switch_map[\"isomorphism\"] = True\n",
    "        \n",
    "        # Probably never need this!\n",
    "        \"\"\"\n",
    "        Random Distractors.\n",
    "        \"\"\"\n",
    "        # Place random distractors. These are gSCAN like distractors\n",
    "        # which are often not very meaningful for testing agents language\n",
    "        # knowledge. We recommand always turn this off and use other\n",
    "        # relation-based distractor sampling strategies.\n",
    "        \n",
    "        random_distractor_metadata = {}\n",
    "        n_random_distractor = -1\n",
    "        if include_random_distractor:\n",
    "            if len(obj_placed_map) >= self.n_object_max or len(mentioned_shapes) == len(self.vocabulary.get_semantic_shapes())-1:\n",
    "                pass # Do nothing!\n",
    "            else:\n",
    "                n_distractor = min(4, self.n_object_max-len(obj_placed_map)) # at max 2 random, how about?\n",
    "                n_random_distractor = n_distractor\n",
    "                core_obj_count = obj_drafted_count\n",
    "                for i in range(0, n_distractor):\n",
    "                    distractor_idx = core_obj_count+i\n",
    "                    distractor_name = f\"$OBJ_{distractor_idx}\"\n",
    "                    \n",
    "                    # Let us only sample shapes that are not exist\n",
    "                    sampled_distractor = self.sample_random_object_spec(\n",
    "                        shape_exclude=list(mentioned_shapes)\n",
    "                    )\n",
    "                    \n",
    "                    # Ok, we need to consider global size constraint!\n",
    "                    special_shape_super = sampled_distractor.shape\n",
    "                    special_shape_sub = sampled_distractor.color + \" \" +sampled_distractor.shape\n",
    "\n",
    "                    # e.g., small circle exists in the command, then any colored circle needs to be constrain\n",
    "                    size_idx = -1\n",
    "                    if special_shape_super in special_shape_size_bound.keys():\n",
    "                        size_idx = random.randint(0,1)\n",
    "                        updated_size = special_shape_size_bound[special_shape_super][size_idx]\n",
    "                        sampled_distractor = Object(\n",
    "                            color=sampled_distractor.color,\n",
    "                            size=updated_size,\n",
    "                            shape=sampled_distractor.shape\n",
    "                        )\n",
    "                    elif special_shape_sub in special_shape_size_bound.keys():\n",
    "                        size_idx = random.randint(0,1)\n",
    "                        updated_size = special_shape_size_bound[special_shape_sub][size_idx]\n",
    "                        sampled_distractor = Object(\n",
    "                            color=sampled_distractor.color,\n",
    "                            size=updated_size,\n",
    "                            shape=sampled_distractor.shape\n",
    "                        )\n",
    "                    \n",
    "                    if sampled_distractor.shape == \"box\":\n",
    "                        sampled_dis_pos = self._world.sample_position_complex(\n",
    "                            condition=\"box\", box_size=sampled_distractor.size, sample_one=True\n",
    "                        )\n",
    "                    else:\n",
    "                        sampled_dis_pos = self._world.sample_position_complex(\n",
    "                            condition=\"normal\", sample_one=True\n",
    "                        )\n",
    "                    \n",
    "                    self._world.place_object(\n",
    "                        sampled_distractor, \n",
    "                        position=sampled_dis_pos, target=False\n",
    "                    )\n",
    "                    obj_placed_map[distractor_name] = sampled_distractor\n",
    "                    obj_position_map[distractor_name] = sampled_dis_pos\n",
    "                    size_str = \"\"\n",
    "                    if size_idx != -1:\n",
    "                        size_str = \"big\" if size_idx == 1 else \"small\"\n",
    "                    random_distractor_metadata[distractor_name] = \" \".join([\n",
    "                        size_str,\n",
    "                        sampled_distractor.color,\n",
    "                        sampled_distractor.shape\n",
    "                    ])\n",
    "                distractor_switch_map[\"random\"] = True\n",
    "\n",
    "        agent_position = self._world.sample_position_complex(\n",
    "                            condition=\"normal\", sample_one=True\n",
    "                        )\n",
    "        self._world.place_agent_at(agent_position)\n",
    "        if is_plot:\n",
    "            _ = self._world.render_simple()\n",
    "        \n",
    "        situation_snapshot = copy.deepcopy(self._world.get_current_situation())\n",
    "        \n",
    "        return {\n",
    "            \"obj_map\" : obj_placed_map,\n",
    "            \"pos_map\" : obj_position_map,\n",
    "            \"obj_pattern_map\" : obj_pattern_map,\n",
    "            \"referred_obj\" : referred_obj,\n",
    "            \"situation\" : situation_snapshot, \n",
    "            \"distractor_switch_map\" : distractor_switch_map,\n",
    "            \"relation_distractor_metadata\" : [\n",
    "                {\n",
    "                    \"distractor_metadata\": md[\"distractor_metadata\"],\n",
    "                    \"obj_map\": md[\"obj_map\"],\n",
    "                    \"rel_map\": md[\"rel_map\"],\n",
    "                } for md in relation_distractors_dicts\n",
    "            ],\n",
    "            \"attribute_distractor_metadata\" : [\n",
    "                {\n",
    "                    \"distractor_metadata\": md[\"distractor_metadata\"],\n",
    "                    \"obj_map\": md[\"obj_map\"],\n",
    "                    \"rel_map\": md[\"rel_map\"],\n",
    "                } for md in attribute_distractors_dicts\n",
    "            ],\n",
    "            \"isomorphism_distractor_metadata\" : [\n",
    "                {\n",
    "                    \"distractor_metadata\": md[\"distractor_metadata\"],\n",
    "                    \"obj_map\": md[\"obj_map\"],\n",
    "                    \"rel_map\": md[\"rel_map\"],\n",
    "                } for md in isomorphism_distractors_dicts\n",
    "            ],\n",
    "            \"random_distractor_metadata\" : [random_distractor_metadata],\n",
    "            \"n_random_distractor\" : n_random_distractor\n",
    "        }\n",
    "    \n",
    "    def get_action_list(\n",
    "        self,\n",
    "        verb=None,\n",
    "        adverb=None,\n",
    "    ):\n",
    "        pass\n",
    "    \n",
    "    def extract_size(self, obj_str):\n",
    "        obj_descriptors = obj_str.split(\" \")\n",
    "        for descriptor in obj_descriptors:\n",
    "            if descriptor in [\"small\", \"big\"]:\n",
    "                return descriptor\n",
    "        return \"\"\n",
    "\n",
    "    def extract_color(self, obj_str):\n",
    "        obj_descriptors = obj_str.split(\" \")\n",
    "        for descriptor in obj_descriptors:\n",
    "            if descriptor in self.object_vocabulary.object_colors:\n",
    "                return descriptor\n",
    "        return \"\"\n",
    "    \n",
    "    def extract_shape(self, obj_str):\n",
    "        obj_descriptors = obj_str.split(\" \")\n",
    "        for descriptor in obj_descriptors:\n",
    "            if descriptor in self.object_vocabulary.object_shapes:\n",
    "                return descriptor\n",
    "        return \"\"\n",
    "\n",
    "    def convert_object_str_to_grammer(self, obj_str):\n",
    "        size_g = False\n",
    "        color_g = False\n",
    "        abs_shape_g = False\n",
    "\n",
    "        obj_descriptors = obj_str.split(\" \")\n",
    "        for descriptor in obj_descriptors:\n",
    "            if descriptor in [\"small\", \"big\"]:\n",
    "                size_g = True\n",
    "            elif descriptor in self.object_vocabulary.object_colors:\n",
    "                color_g = True\n",
    "            elif descriptor in self.object_vocabulary.object_shapes:\n",
    "                pass\n",
    "            elif descriptor == \"object\":\n",
    "                abs_shape_g = True\n",
    "\n",
    "        grammer = []\n",
    "        if size_g:\n",
    "            grammer.append(\"$SIZE\")\n",
    "        if color_g:\n",
    "            grammer.append(\"$COLOR\")\n",
    "        if abs_shape_g:\n",
    "            grammer.append(\"$ABS_SHAPE\") # Mark as deprecated!\n",
    "        else:\n",
    "            grammer.append(\"$SHAPE\")\n",
    "        \n",
    "        return \" \".join(grammer)\n",
    "\n",
    "    def snap_pattern_to_referent_map(self, distractor_grammer_pattern, base_count):\n",
    "        distractor_grammer_pattern_snapped = []\n",
    "        for item in distractor_grammer_pattern.split(\" \"):\n",
    "            if item.startswith(\"$\"):\n",
    "                new_id = int(item.split(\"_\")[1])+base_count\n",
    "                distractor_grammer_pattern_snapped.append(f\"$OBJ_{new_id}\")\n",
    "            else:\n",
    "                distractor_grammer_pattern_snapped.append(item)\n",
    "        return \" \".join(distractor_grammer_pattern_snapped)\n",
    "\n",
    "    def snap_object_map_to_referent_map(self, distractor_map, base_count):\n",
    "        distractor_map_snapped = OrderedDict({})\n",
    "        for obj_name, item in distractor_map.items():\n",
    "            new_id = int(obj_name.split(\"_\")[1])+base_count\n",
    "            new_obj_name = f\"$OBJ_{new_id}\"\n",
    "            distractor_map_snapped[new_obj_name] = item\n",
    "        return distractor_map_snapped\n",
    "\n",
    "    def snap_relation_map_to_referent_map(self, distractor_rel_map, base_count):\n",
    "        distractor_rel_map_snapped = OrderedDict({})\n",
    "        for edge, item in distractor_rel_map.items():\n",
    "            if edge[0].startswith(\"$\"):\n",
    "                new_id_left = int(edge[0].split(\"_\")[1])+base_count\n",
    "                new_obj_name_left = f\"$OBJ_{new_id_left}\"\n",
    "            else:\n",
    "                new_obj_name_left = edge[0]\n",
    "            \n",
    "            if edge[1].startswith(\"$\"):\n",
    "                new_id_right = int(edge[1].split(\"_\")[1])+base_count\n",
    "                new_obj_name_right = f\"$OBJ_{new_id_right}\"\n",
    "            else:\n",
    "                new_obj_name_right = edge[1]\n",
    "            distractor_rel_map_snapped[(new_obj_name_left, new_obj_name_right)] = item\n",
    "        return distractor_rel_map_snapped\n",
    "\n",
    "    def sample_distractor_grammer_by_relation_fast(\n",
    "        self, \n",
    "        referent_grammer_pattern, \n",
    "        referent_obj_pattern_map,\n",
    "        referent_rel_map,\n",
    "        referent_obj_map, \n",
    "        sampled_world,\n",
    "        obj_base_count=0,\n",
    "        full_set=True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        You can choose between two versions.\n",
    "        In this fast version, we only sample objects for the \n",
    "        selected edge.\n",
    "        \"\"\"\n",
    "        distractors_dicts = []\n",
    "        # We first collect all the relations\n",
    "        relation_edges = []\n",
    "        for edge, relation in referent_rel_map.items():\n",
    "            relation_edges.append(edge)\n",
    "        random.shuffle(relation_edges)\n",
    "        if full_set:\n",
    "            pass\n",
    "        else:\n",
    "            relation_edges = relation_edges[:1] # select only the first element.\n",
    "        \n",
    "        existing_relations = set([v for k, v in referent_rel_map.items()])\n",
    "\n",
    "        for selected_leaf_edge in relation_edges:\n",
    "\n",
    "            distractor_metadata = {\n",
    "                \"edge\" : selected_leaf_edge,\n",
    "                \"relation_old_type\" : referent_rel_map[selected_leaf_edge],\n",
    "                \"full_set\" : full_set,\n",
    "            }\n",
    "\n",
    "            distractor_size_map = {}\n",
    "            # First, let us make copies.\n",
    "            distractor_grammer_pattern = \"$OBJ_0 ^ $OBJ_1\"\n",
    "            distractor_obj_pattern_map = {}\n",
    "            node_left = selected_leaf_edge[0]\n",
    "            node_right = selected_leaf_edge[1]\n",
    "\n",
    "            distractor_obj_pattern_map[\"$OBJ_0\"] = referent_obj_pattern_map[node_left]\n",
    "            distractor_obj_pattern_map[\"$OBJ_1\"] = referent_obj_pattern_map[node_right]\n",
    "            distractor_rel_map = OrderedDict({})\n",
    "            distractor_rel_map[(\"$OBJ_0\", \"$OBJ_1\")] = referent_rel_map[selected_leaf_edge]\n",
    "            distractor_obj_map = {}\n",
    "            distractor_obj_map[\"$OBJ_0\"] = referent_obj_map[node_left]\n",
    "            distractor_obj_map[\"$OBJ_1\"] = referent_obj_map[node_right]\n",
    "            \n",
    "            # We need to increment the object counters.\n",
    "            distractors_dicts += [{\n",
    "                                    \"grammer_pattern\" : self.snap_pattern_to_referent_map(\n",
    "                                        distractor_grammer_pattern,\n",
    "                                        obj_base_count\n",
    "                                    ),\n",
    "                                    \"obj_pattern_map\" : self.snap_object_map_to_referent_map(\n",
    "                                        distractor_obj_pattern_map,\n",
    "                                        obj_base_count\n",
    "                                    ),\n",
    "                                    \"rel_map\" : self.snap_relation_map_to_referent_map(\n",
    "                                        distractor_rel_map,\n",
    "                                        obj_base_count\n",
    "                                    ),\n",
    "                                    \"obj_map\" : self.snap_object_map_to_referent_map(\n",
    "                                        distractor_obj_map,\n",
    "                                        obj_base_count\n",
    "                                    ),\n",
    "                                    \"size_map\" : self.snap_object_map_to_referent_map(\n",
    "                                        distractor_size_map,\n",
    "                                        obj_base_count\n",
    "                                    ),\n",
    "                                    \"distractor_metadata\" : distractor_metadata\n",
    "                                }]\n",
    "            obj_base_count += len(distractor_obj_pattern_map)\n",
    "\n",
    "        return distractors_dicts\n",
    "            \n",
    "            \n",
    "    def sample_distractor_grammer_by_relation(\n",
    "        self, \n",
    "        referent_grammer_pattern, \n",
    "        referent_obj_pattern_map,\n",
    "        referent_rel_map,\n",
    "        referent_obj_map, \n",
    "        sampled_world,\n",
    "        obj_base_count=0,\n",
    "        full_set=True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        This will select 1 relation mentioned in the command\n",
    "        and modify it to a new one. Then, sample distractors\n",
    "        based on that command (sampling step is outside of \n",
    "        this function). This function only construct the semantics\n",
    "        of distractors.\n",
    "        \"\"\"\n",
    "\n",
    "        distractors_dicts = []\n",
    "        # We first collect all the relations\n",
    "        relation_edges = []\n",
    "        for edge, relation in referent_rel_map.items():\n",
    "            relation_edges.append(edge)\n",
    "        random.shuffle(relation_edges)\n",
    "        if full_set:\n",
    "            pass\n",
    "        else:\n",
    "            relation_edges = relation_edges[:1] # select only the first element.\n",
    "        \n",
    "        existing_relations = set([v for k, v in referent_rel_map.items()])\n",
    "        # print(referent_rel_map)\n",
    "        for selected_leaf_edge in relation_edges:\n",
    "\n",
    "            # First, let us make copies.\n",
    "            distractor_grammer_pattern = copy.deepcopy(referent_grammer_pattern)\n",
    "            distractor_obj_pattern_map = copy.deepcopy(referent_obj_pattern_map)\n",
    "            distractor_rel_map = copy.deepcopy(referent_rel_map)\n",
    "            distractor_obj_map = copy.deepcopy(referent_obj_map)\n",
    "\n",
    "            # We may need to enforce the size of the distractor due to size descriptors!\n",
    "            distractor_size_map = {}\n",
    "        \n",
    "            selected_surgery = \"REL_ADJUST\" # Dummy\n",
    "\n",
    "            distractor_metadata = {\n",
    "                \"edge\" : selected_leaf_edge,\n",
    "                \"relation_old_type\" : distractor_rel_map[selected_leaf_edge]\n",
    "            }\n",
    "\n",
    "            if selected_surgery == \"REL_ADJUST\":\n",
    "                # Determine the new relation as not the same one as the current one.\n",
    "                new_rels = [\"$SAME_ROW\", \"$SAME_COLUMN\", \"$SAME_SHAPE\", \"$SAME_COLOR\", \"$SAME_SIZE\", \"$IS_INSIDE\"]\n",
    "                new_rels = set(new_rels) - existing_relations # make this very strict!\n",
    "                # There are something else do not make sense to sample!\n",
    "                # if \"$SIZE\" in distractor_obj_pattern_map[selected_leaf_edge[0]]:\n",
    "                #     new_rels -= set([\"$SAME_SIZE\"])\n",
    "                # if \"$COLOR\" in distractor_obj_pattern_map[selected_leaf_edge[0]]:\n",
    "                #     new_rels -= set([\"$SAME_COLOR\"])\n",
    "                # if \"$SHAPE\" in distractor_obj_pattern_map[selected_leaf_edge[0]]:\n",
    "                #    new_rels -= set([\"$SAME_SHAPE\"])\n",
    "                new_rel = random.choice(list(new_rels))\n",
    "                existing_relations.add(new_rel)\n",
    "                distractor_metadata[\"relation_new_type\"] = new_rel\n",
    "                distractor_rel_map[selected_leaf_edge] = new_rel\n",
    "                if new_rel == \"$IS_INSIDE\":\n",
    "                    # We can still try to keep the color and size the same.\n",
    "                    distractor_size_map[selected_leaf_edge[1]] = sampled_world[\"obj_map\"][selected_leaf_edge[1]].size\n",
    "                    distractor_obj_map[selected_leaf_edge[1]] = sampled_world[\"obj_map\"][selected_leaf_edge[1]].color + \" box\"\n",
    "                    distractor_obj_pattern_map[selected_leaf_edge[1]] = '$COLOR $SHAPE'\n",
    "                else:\n",
    "                    distractor_size_map[selected_leaf_edge[1]] = sampled_world[\"obj_map\"][selected_leaf_edge[1]].size\n",
    "                    if \"box\" in distractor_obj_map[selected_leaf_edge[1]]:\n",
    "                        # it used to box type object.\n",
    "                        distractor_size_map[selected_leaf_edge[1]] = sampled_world[\"obj_map\"][selected_leaf_edge[1]].size\n",
    "                        distractor_obj_map[selected_leaf_edge[1]] = sampled_world[\"obj_map\"][selected_leaf_edge[1]].color + \" object\"\n",
    "                        distractor_obj_pattern_map[selected_leaf_edge[1]] = '$COLOR $ABS_SHAPE'\n",
    "                    else:\n",
    "                        distractor_size_map[selected_leaf_edge[1]] = sampled_world[\"obj_map\"][selected_leaf_edge[1]].size\n",
    "                        distractor_obj_map[selected_leaf_edge[1]] = \\\n",
    "                            sampled_world[\"obj_map\"][selected_leaf_edge[1]].color + \" \" + \\\n",
    "                            sampled_world[\"obj_map\"][selected_leaf_edge[1]].shape\n",
    "                        distractor_obj_pattern_map[selected_leaf_edge[1]] = '$COLOR $SHAPE'\n",
    "            else:\n",
    "                assert False\n",
    "        \n",
    "            # We need to increment the object counters.\n",
    "            distractors_dicts += [{\n",
    "                                    \"grammer_pattern\" : self.snap_pattern_to_referent_map(\n",
    "                                        distractor_grammer_pattern,\n",
    "                                        obj_base_count\n",
    "                                    ),\n",
    "                                    \"obj_pattern_map\" : self.snap_object_map_to_referent_map(\n",
    "                                        distractor_obj_pattern_map,\n",
    "                                        obj_base_count\n",
    "                                    ),\n",
    "                                    \"rel_map\" : self.snap_relation_map_to_referent_map(\n",
    "                                        distractor_rel_map,\n",
    "                                        obj_base_count\n",
    "                                    ),\n",
    "                                    \"obj_map\" : self.snap_object_map_to_referent_map(\n",
    "                                        distractor_obj_map,\n",
    "                                        obj_base_count\n",
    "                                    ),\n",
    "                                    \"size_map\" : self.snap_object_map_to_referent_map(\n",
    "                                        distractor_size_map,\n",
    "                                        obj_base_count\n",
    "                                    ),\n",
    "                                    \"distractor_metadata\" : distractor_metadata\n",
    "                                }]\n",
    "            obj_base_count += len(distractor_obj_pattern_map)\n",
    "\n",
    "        return distractors_dicts\n",
    "\n",
    "    def sample_distractor_grammer_by_isomorphism(\n",
    "        self,\n",
    "        referent_grammer_pattern, \n",
    "        referent_obj_pattern_map,\n",
    "        referent_rel_map,\n",
    "        referent_obj_map, \n",
    "        sampled_world,\n",
    "        obj_base_count=0,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        This set of distractors are for learning syntax and grammers.\n",
    "        If you simply use BoW approach, it will not work because we \n",
    "        always instill confusing targets for you with isomorphism of the\n",
    "        referent graph.\n",
    "\n",
    "        For example, if the original grounded command is:\n",
    "        Go to the red square that is inside of the yellow box.\n",
    "\n",
    "        We can do a isomorphism which is\n",
    "        Go to the yellow square that is inside of the red box.\n",
    "\n",
    "        If the model is not understanding the language correctly,\n",
    "        it will not able to find the referent target correctly.\n",
    "        \"\"\"\n",
    "        # First, let us make copies.\n",
    "        distractor_grammer_pattern = copy.deepcopy(referent_grammer_pattern)\n",
    "        distractor_obj_pattern_map = copy.deepcopy(referent_obj_pattern_map)\n",
    "        distractor_rel_map = copy.deepcopy(referent_rel_map)\n",
    "        distractor_obj_map = copy.deepcopy(referent_obj_map)\n",
    "        # We may need to enforce the size of the distractor due to size descriptors!\n",
    "        distractor_size_map = {}\n",
    "\n",
    "        shufflable_objects = []\n",
    "        for obj_name, obj_str in distractor_obj_map.items():\n",
    "            if obj_name == \"$OBJ_0\":\n",
    "                continue # We need to sample distractors of object 0, thus, we keep it intact!\n",
    "            obj_descriptors = obj_str.split(\" \")\n",
    "            # if this is a box, we don't swap it\n",
    "            if \"box\" in obj_descriptors:\n",
    "                continue\n",
    "            if \"object\" in obj_descriptors:\n",
    "                # \"object\" itself is not shufflable!\n",
    "                if len(obj_descriptors) > 1:\n",
    "                    shufflable_objects.append((obj_name, obj_str))\n",
    "            else:\n",
    "                shufflable_objects.append((obj_name, obj_str))\n",
    "        if len(shufflable_objects) > 2:\n",
    "            random.shuffle(shufflable_objects)\n",
    "        shufflable_objects = shufflable_objects[:2]\n",
    "        \n",
    "        if len(shufflable_objects) == 1:\n",
    "            return [] # We simply don't have enough objects to do this.\n",
    "\n",
    "        # We will shuffle attributes between two objects.\n",
    "        # We actually shuffle by looking at their relations.\n",
    "        obj_name_left = shufflable_objects[0][0]\n",
    "        obj_name_right = shufflable_objects[1][0]\n",
    "        swap_color = True\n",
    "        swap_size = False # Let us stop swapping size for now.\n",
    "        swap_shape = True\n",
    "        if (obj_name_left, obj_name_right) in distractor_rel_map.keys() or \\\n",
    "            (obj_name_right, obj_name_left) in distractor_rel_map.keys():\n",
    "            if ((obj_name_left, obj_name_right) in distractor_rel_map.keys() and \\\n",
    "                    distractor_rel_map[(obj_name_left, obj_name_right)] == \"SameColor\") or \\\n",
    "                ((obj_name_right, obj_name_left) in distractor_rel_map.keys() and \\\n",
    "                     distractor_rel_map[(obj_name_right, obj_name_left)] == \"SameColor\"):\n",
    "                swap_color = False\n",
    "            elif ((obj_name_left, obj_name_right) in distractor_rel_map.keys() and \\\n",
    "                    distractor_rel_map[(obj_name_left, obj_name_right)] == \"SameSize\") or \\\n",
    "                ((obj_name_right, obj_name_left) in distractor_rel_map.keys() and \\\n",
    "                     distractor_rel_map[(obj_name_right, obj_name_left)] == \"SameSize\"):\n",
    "                swap_size = False\n",
    "            elif ((obj_name_left, obj_name_right) in distractor_rel_map.keys() and \\\n",
    "                    distractor_rel_map[(obj_name_left, obj_name_right)] == \"SameShape\") or \\\n",
    "                ((obj_name_right, obj_name_left) in distractor_rel_map.keys() and \\\n",
    "                     distractor_rel_map[(obj_name_right, obj_name_left)] == \"SameShape\"):\n",
    "                swap_shape = False\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        size_left = self.extract_size(shufflable_objects[0][1])\n",
    "        size_right = self.extract_size(shufflable_objects[1][1])\n",
    "        color_left = self.extract_color(shufflable_objects[0][1])\n",
    "        color_right = self.extract_color(shufflable_objects[1][1])\n",
    "        shape_left = self.extract_shape(shufflable_objects[0][1])\n",
    "        shape_right = self.extract_shape(shufflable_objects[1][1])\n",
    "        \n",
    "        if size_left == \"\" and size_right == \"\":\n",
    "            swap_size = False\n",
    "        if color_left == \"\" and color_right == \"\":\n",
    "            swap_color = False\n",
    "        if shape_left == \"\" and shape_right == \"\":\n",
    "            swap_shape = False\n",
    "        if shape_left == \"box\" or shape_right == \"box\":\n",
    "            swap_shape = False\n",
    "        \n",
    "        if not swap_color and not swap_size and not swap_shape:\n",
    "            return []\n",
    "        \n",
    "        swapping_attribute = []\n",
    "        if swap_color:\n",
    "            swapping_attribute += [\"color\"]\n",
    "        if swap_size and swap_shape:\n",
    "            swapping_attribute += [\"size+shape\"]\n",
    "        if not swap_size and swap_shape:\n",
    "            swapping_attribute += [\"size+shape\"]\n",
    "        swapping_attribute = random.choice(swapping_attribute)\n",
    "\n",
    "        left_rebuild = []\n",
    "        right_rebuild = []\n",
    "        \n",
    "        size_shuffled = False\n",
    "        color_shuffled = False\n",
    "        shape_shuffled = False\n",
    "        if swapping_attribute == \"color\":\n",
    "            tmp = color_left\n",
    "            color_left = color_right\n",
    "            color_right = tmp\n",
    "            color_shuffled = True\n",
    "        elif swapping_attribute == \"shape\":\n",
    "            tmp = shape_left\n",
    "            shape_left = shape_right\n",
    "            shape_right = tmp\n",
    "            shape_shuffled = True\n",
    "        elif swapping_attribute == \"size+shape\":\n",
    "            tmp = shape_left\n",
    "            shape_left = shape_right\n",
    "            shape_right = tmp\n",
    "            shape_shuffled = True\n",
    "            \n",
    "            tmp = size_left\n",
    "            size_left = size_right\n",
    "            size_right = tmp\n",
    "            size_shuffled = True\n",
    "            \n",
    "        # We don't swap size!\n",
    "        if size_left != \"\":\n",
    "            left_rebuild.append(size_left)\n",
    "        if size_right != \"\":\n",
    "            right_rebuild.append(size_right)\n",
    "            \n",
    "        if color_left != \"\":\n",
    "            left_rebuild.append(color_left)\n",
    "        if color_right != \"\":\n",
    "            right_rebuild.append(color_right)\n",
    "\n",
    "        if shape_left != \"\":\n",
    "            left_rebuild.append(shape_left)\n",
    "        else:\n",
    "            left_rebuild.append(\"object\")\n",
    "        if shape_right != \"\":\n",
    "            right_rebuild.append(shape_right)\n",
    "        else:\n",
    "            right_rebuild.append(\"object\")\n",
    "        \n",
    "        if not color_shuffled and not shape_shuffled:\n",
    "            return []\n",
    "                \n",
    "        left_rebuild = \" \".join(left_rebuild)\n",
    "        right_rebuild = \" \".join(right_rebuild)\n",
    "        left_grammer_rebuild = self.convert_object_str_to_grammer(left_rebuild)\n",
    "        right_grammer_rebuild = self.convert_object_str_to_grammer(right_rebuild)\n",
    "        \n",
    "        # It seems like it is possible with our case\n",
    "        # You need extra cautious of you want to extend for longer logics\n",
    "        # if left_rebuild == shufflable_objects[1][1] or right_rebuild == shufflable_objects[0][1]:\n",
    "        #     return [] # we don't allow complete swap!\n",
    "        \n",
    "        distractor_obj_pattern_map[obj_name_left] = left_grammer_rebuild \n",
    "        distractor_obj_pattern_map[obj_name_right] = right_grammer_rebuild \n",
    "        distractor_obj_map[obj_name_left] = left_rebuild\n",
    "        distractor_obj_map[obj_name_right] = right_rebuild\n",
    "        \n",
    "        distractor_metadata = {\n",
    "            \"swapped_pair\" : (obj_name_left, obj_name_right),\n",
    "            \"before_pair_obj_str\" : (shufflable_objects[0][1], shufflable_objects[1][1]),\n",
    "            \"after_pair_obj_str\" : (left_rebuild, right_rebuild),\n",
    "            \"size_shuffled\" : size_shuffled,\n",
    "            \"color_shuffled\" : color_shuffled,\n",
    "            \"shape_shuffled\" : shape_shuffled\n",
    "        }\n",
    "        \n",
    "        return [{\n",
    "                    \"grammer_pattern\" : self.snap_pattern_to_referent_map(\n",
    "                        distractor_grammer_pattern,\n",
    "                        obj_base_count\n",
    "                    ),\n",
    "                    \"obj_pattern_map\" : self.snap_object_map_to_referent_map(\n",
    "                        distractor_obj_pattern_map,\n",
    "                        obj_base_count\n",
    "                    ),\n",
    "                    \"rel_map\" : self.snap_relation_map_to_referent_map(\n",
    "                        distractor_rel_map,\n",
    "                        obj_base_count\n",
    "                    ),\n",
    "                    \"obj_map\" : self.snap_object_map_to_referent_map(\n",
    "                        distractor_obj_map,\n",
    "                        obj_base_count\n",
    "                    ),\n",
    "                    \"size_map\" : self.snap_object_map_to_referent_map(\n",
    "                        distractor_size_map,\n",
    "                        obj_base_count\n",
    "                    ),\n",
    "                    \"distractor_metadata\" : [distractor_metadata]\n",
    "                }]\n",
    "\n",
    "    def sample_distractor_grammer_by_attribute(\n",
    "        self,\n",
    "        referent_grammer_pattern, \n",
    "        referent_obj_pattern_map,\n",
    "        referent_rel_map,\n",
    "        referent_obj_map, \n",
    "        sampled_world,\n",
    "        special_shape_size_bound,\n",
    "        obj_base_count=0,\n",
    "        full_set=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        We randomly select 1 object and 1 attribute\n",
    "        that exists in the command to do the attack.\n",
    "        \n",
    "        Then, for all objects if size attribute exists\n",
    "        this function is also responsible for sampling\n",
    "        dummy size distractors!\n",
    "        \"\"\"\n",
    "        # First, let us make copies.\n",
    "        distractor_grammer_pattern = copy.deepcopy(referent_grammer_pattern)\n",
    "        distractor_obj_pattern_map = copy.deepcopy(referent_obj_pattern_map)\n",
    "        distractor_rel_map = copy.deepcopy(referent_rel_map)\n",
    "        distractor_obj_map = copy.deepcopy(referent_obj_map)\n",
    "        # We may need to enforce the size of the distractor due to size descriptors!\n",
    "        distractor_size_map = OrderedDict({})\n",
    "        sizing_covered = []\n",
    "        if full_set:\n",
    "            obj_pool = []\n",
    "            for obj_name, obj_grammer in referent_obj_pattern_map.items():\n",
    "                if \"$ABS_SHAPE\" in obj_grammer or \"box\" in distractor_obj_map[obj_name]:\n",
    "                    continue\n",
    "                obj_pool += [obj_name]\n",
    "            obj_selected = random.choice(obj_pool)\n",
    "            attribute_pool = referent_obj_pattern_map[obj_selected].split(\" \")\n",
    "            attribute_pool = list(set(attribute_pool)-set([\"$ABS_SHAPE\"]))\n",
    "            attribute_selected = random.choice(attribute_pool)\n",
    "\n",
    "            distractor_metadata = {\n",
    "                \"modified_obj\" : obj_selected,\n",
    "                \"modified_attribute\" : attribute_selected,\n",
    "            }\n",
    "\n",
    "            if attribute_selected == \"$SIZE\":\n",
    "                sizing_covered.append(obj_selected)\n",
    "                obj_name = obj_selected\n",
    "                original_object_str = distractor_obj_map[obj_name]\n",
    "                obj_grammer = distractor_obj_pattern_map[obj_name]\n",
    "                original_object = sampled_world['obj_map'][obj_name]\n",
    "                original_object_size = original_object.size\n",
    "                if \"$COLOR\" in obj_grammer:\n",
    "                    special_shape = \\\n",
    "                        sampled_world['obj_map'][obj_name].color + \\\n",
    "                        \" \" + sampled_world['obj_map'][obj_name].shape\n",
    "                else:\n",
    "                    special_shape = sampled_world['obj_map'][obj_name].shape\n",
    "                \n",
    "                if \"small\" in original_object_str:\n",
    "                    distractor_size = special_shape_size_bound[special_shape][1]\n",
    "                elif \"big\" in original_object_str:\n",
    "                    distractor_size = special_shape_size_bound[special_shape][0]\n",
    "                distractor_size_map[obj_name] = distractor_size\n",
    "                distractor_shape = original_object.shape\n",
    "                tmp_name = \"\"\n",
    "                if \"$COLOR\" in obj_grammer:\n",
    "                    distractor_color = original_object.color\n",
    "                    new_object_grammer = \"$SIZE $COLOR $SHAPE\" # $SIZE is a must right?\n",
    "                    tmp_name = distractor_color + \" \" + distractor_shape\n",
    "                else:\n",
    "                    distractor_color = self.object_vocabulary.sample_color()\n",
    "                    new_object_grammer = \"$SIZE $SHAPE\"\n",
    "                    tmp_name = distractor_shape\n",
    "                if \"small\" in original_object_str:\n",
    "                    tmp_name = \"big\" + \" \" + tmp_name\n",
    "                elif \"big\" in original_object_str:\n",
    "                    tmp_name = \"small\" + \" \" + tmp_name\n",
    "                else:\n",
    "                    pass # Not Implemented\n",
    "                distractor_obj_map[obj_name] = tmp_name\n",
    "                distractor_obj_pattern_map[obj_name] = new_object_grammer\n",
    "\n",
    "                # Then, we will also consider other object sizes. Basically,\n",
    "                # we keep them the same, unless they form SameShape relation\n",
    "                # with our core object.\n",
    "                for _obj_name, _obj in sampled_world['obj_map'].items():\n",
    "                    if _obj_name != obj_name:\n",
    "                        if (_obj_name, obj_name) in referent_rel_map and \\\n",
    "                            referent_rel_map[(_obj_name, obj_name)] == \"SameSize\":\n",
    "                            distractor_size_map[_obj_name] = distractor_size\n",
    "                        elif (obj_name, _obj_name) in referent_rel_map and \\\n",
    "                            referent_rel_map[(obj_name, _obj_name)] == \"SameSize\":\n",
    "                            distractor_size_map[_obj_name] = distractor_size\n",
    "                        else:\n",
    "                            distractor_size_map[_obj_name] = _obj.size\n",
    "            elif attribute_selected == \"$COLOR\":\n",
    "                original_object_name = obj_selected\n",
    "                original_object_str = distractor_obj_map[original_object_name]\n",
    "                original_object = sampled_world['obj_map'][original_object_name]\n",
    "                new_color = self.object_vocabulary.sample_color(_exclude=[original_object.color])\n",
    "                new_object_str = new_color + \" \" + original_object.shape\n",
    "                new_object_grammer = \"$COLOR $SHAPE\"\n",
    "                distractor_obj_map[original_object_name] = new_object_str\n",
    "                distractor_obj_pattern_map[original_object_name] = new_object_grammer\n",
    "            elif attribute_selected == \"$SHAPE\":\n",
    "\n",
    "                original_object_name = obj_selected\n",
    "                original_object_str = distractor_obj_map[original_object_name]\n",
    "                original_object = sampled_world['obj_map'][original_object_name]\n",
    "                new_shape = self.object_vocabulary.sample_shape(_exclude=[original_object.shape])\n",
    "                new_object_str = original_object.color + \" \" + new_shape\n",
    "                new_object_grammer = \"$COLOR $SHAPE\"\n",
    "                distractor_obj_map[original_object_name] = new_object_str\n",
    "                distractor_obj_pattern_map[original_object_name] = new_object_grammer\n",
    "                \n",
    "            # Now for all other objects with size attribute, we need\n",
    "            # to ground them even if it is not relational.\n",
    "            base_distractor_count = len(list(distractor_obj_map.keys()))\n",
    "            for obj_name, obj_grammer in referent_obj_pattern_map.items():\n",
    "                if \"$SIZE\" in obj_grammer:\n",
    "                    if obj_name not in sizing_covered:\n",
    "                        # Just sample a single one.\n",
    "                        new_obj_name = f\"OBJ_{base_distractor_count}\"\n",
    "                        original_object_str = referent_obj_map[obj_name]\n",
    "\n",
    "                        tmp_name = \" \".join(original_object_str.split(\" \")[1:])\n",
    "                        if \"small\" in original_object_str:\n",
    "                            tmp_name = \"big\" + \" \" + tmp_name\n",
    "                        elif \"big\" in original_object_str:\n",
    "                            tmp_name = \"small\" + \" \" + tmp_name\n",
    "                        else:\n",
    "                            pass # Not Implemented\n",
    "\n",
    "                        if \"$COLOR\" in obj_grammer:\n",
    "                            special_shape = \\\n",
    "                                sampled_world['obj_map'][obj_name].color + \\\n",
    "                                \" \" + sampled_world['obj_map'][obj_name].shape\n",
    "                        else:\n",
    "                            special_shape = sampled_world['obj_map'][obj_name].shape\n",
    "                        if \"small\" in original_object_str:\n",
    "                            distractor_size = special_shape_size_bound[special_shape][1]\n",
    "                        elif \"big\" in original_object_str:\n",
    "                            distractor_size = special_shape_size_bound[special_shape][0]\n",
    "                        # the above size if the proposed size!\n",
    "\n",
    "                        # Let us iterate through the map, if there is\n",
    "                        # already a shape working as the size counterparts\n",
    "                        # we don't need it!\n",
    "                        color = self.extract_color(original_object_str)\n",
    "                        shape = self.extract_shape(original_object_str)\n",
    "                        if color != \"\" and shape != \"object\":\n",
    "                            found = False\n",
    "                            for obj_str, obj in sampled_world['obj_map'].items():\n",
    "                                if obj.color == color and obj.shape == shape:\n",
    "                                    if obj.size == distractor_size:\n",
    "                                        found = True\n",
    "                                        break\n",
    "                            if found:\n",
    "                                continue\n",
    "                        elif color != \"\" and shape == \"object\":\n",
    "                            found = False\n",
    "                            for obj_str, obj in sampled_world['obj_map'].items():\n",
    "                                if obj.color == color:\n",
    "                                    if obj.size == distractor_size:\n",
    "                                        found = True\n",
    "                                        break\n",
    "                            if found:\n",
    "                                continue\n",
    "                        elif color == \"\" and shape == \"object\":\n",
    "                            found = False\n",
    "                            for obj_str, obj in sampled_world['obj_map'].items():\n",
    "                                if obj.size == distractor_size:\n",
    "                                    found = True\n",
    "                                    break\n",
    "                            if found:\n",
    "                                continue\n",
    "                        elif color == \"\" and shape != \"object\":\n",
    "                            found = False\n",
    "                            for obj_str, obj in sampled_world['obj_map'].items():\n",
    "                                if obj.shape == shape:\n",
    "                                    if obj.size == distractor_size:\n",
    "                                        found = True\n",
    "                                        break\n",
    "                            if found:\n",
    "                                continue\n",
    "\n",
    "                        distractor_obj_map[new_obj_name] = tmp_name\n",
    "                        distractor_obj_pattern_map[new_obj_name] = obj_grammer\n",
    "                        distractor_size_map[new_obj_name] = distractor_size\n",
    "                        base_distractor_count += 1\n",
    "                \n",
    "        else:\n",
    "            # We cleanup, and simply place random objects.\n",
    "            distractor_grammer_pattern = \"DUMMY\"\n",
    "            distractor_obj_pattern_map.clear()\n",
    "            distractor_rel_map.clear()\n",
    "            distractor_obj_map.clear()\n",
    "            \n",
    "            distractor_metadata = {\n",
    "                \"modified_obj\" : None,\n",
    "                \"modified_attribute\" : None,\n",
    "            }\n",
    "            # Now for all other objects with size attribute, we need\n",
    "            # to ground them even if it is not relational.\n",
    "            base_distractor_count = len(list(distractor_obj_map.keys()))\n",
    "            for obj_name, obj_grammer in referent_obj_pattern_map.items():\n",
    "                if \"$SIZE\" in obj_grammer:\n",
    "                    if obj_name not in sizing_covered:\n",
    "                        # Just sample a single one.\n",
    "                        new_obj_name = f\"OBJ_{base_distractor_count}\"\n",
    "                        original_object_str = referent_obj_map[obj_name]\n",
    "                        \n",
    "                        tmp_name = \" \".join(original_object_str.split(\" \")[1:])\n",
    "                        if \"small\" in original_object_str:\n",
    "                            tmp_name = \"big\" + \" \" + tmp_name\n",
    "                        elif \"big\" in original_object_str:\n",
    "                            tmp_name = \"small\" + \" \" + tmp_name\n",
    "                        else:\n",
    "                            pass # Not Implemented\n",
    "\n",
    "                        if \"$COLOR\" in obj_grammer:\n",
    "                            special_shape = \\\n",
    "                                sampled_world['obj_map'][obj_name].color + \\\n",
    "                                \" \" + sampled_world['obj_map'][obj_name].shape\n",
    "                        else:\n",
    "                            special_shape = sampled_world['obj_map'][obj_name].shape\n",
    "                        \n",
    "                        # We need to be a little careful when\n",
    "                        # dealing with abstract shape object\n",
    "                        # for example, big object -> small object.\n",
    "                            \n",
    "                        if \"small\" in original_object_str:\n",
    "                            distractor_size = special_shape_size_bound[special_shape][1]\n",
    "                        elif \"big\" in original_object_str:\n",
    "                            distractor_size = special_shape_size_bound[special_shape][0]\n",
    "                        # the above size if the proposed size!\n",
    "                        \n",
    "                        # Let us iterate through the map, if there is\n",
    "                        # already a shape working as the size counterparts\n",
    "                        # we don't need it!\n",
    "                        color = self.extract_color(original_object_str)\n",
    "                        shape = self.extract_shape(original_object_str)\n",
    "                        if color != \"\" and shape != \"object\":\n",
    "                            found = False\n",
    "                            for obj_str, obj in sampled_world['obj_map'].items():\n",
    "                                if obj.color == color and obj.shape == shape:\n",
    "                                    if obj.size == distractor_size:\n",
    "                                        found = True\n",
    "                                        break\n",
    "                            if found:\n",
    "                                continue\n",
    "                        elif color != \"\" and shape == \"object\":\n",
    "                            found = False\n",
    "                            for obj_str, obj in sampled_world['obj_map'].items():\n",
    "                                if obj.color == color:\n",
    "                                    if obj.size == distractor_size:\n",
    "                                        found = True\n",
    "                                        break\n",
    "                            if found:\n",
    "                                continue\n",
    "                        elif color == \"\" and shape == \"object\":\n",
    "                            found = False\n",
    "                            for obj_str, obj in sampled_world['obj_map'].items():\n",
    "                                if obj.size == distractor_size:\n",
    "                                    found = True\n",
    "                                    break\n",
    "                            if found:\n",
    "                                continue\n",
    "                        elif color == \"\" and shape != \"object\":\n",
    "                            found = False\n",
    "                            for obj_str, obj in sampled_world['obj_map'].items():\n",
    "                                if obj.shape == shape:\n",
    "                                    if obj.size == distractor_size:\n",
    "                                        found = True\n",
    "                                        break\n",
    "                            if found:\n",
    "                                continue\n",
    "                            \n",
    "                        distractor_obj_map[new_obj_name] = tmp_name\n",
    "                        distractor_obj_pattern_map[new_obj_name] = obj_grammer\n",
    "                        distractor_size_map[new_obj_name] = distractor_size\n",
    "                        base_distractor_count += 1\n",
    "        return [{\n",
    "            \"grammer_pattern\" : self.snap_pattern_to_referent_map(\n",
    "                distractor_grammer_pattern,\n",
    "                obj_base_count\n",
    "            ),\n",
    "            \"obj_pattern_map\" : self.snap_object_map_to_referent_map(\n",
    "                distractor_obj_pattern_map,\n",
    "                obj_base_count\n",
    "            ),\n",
    "            \"rel_map\" : self.snap_relation_map_to_referent_map(\n",
    "                distractor_rel_map,\n",
    "                obj_base_count\n",
    "            ),\n",
    "            \"obj_map\" : self.snap_object_map_to_referent_map(\n",
    "                distractor_obj_map,\n",
    "                obj_base_count\n",
    "            ),\n",
    "            \"size_map\" : self.snap_object_map_to_referent_map(\n",
    "                distractor_size_map,\n",
    "                obj_base_count\n",
    "            ),\n",
    "            \"distractor_metadata\" : [distractor_metadata]\n",
    "        }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passing rate = 1/10000\n",
      "passing rate = 2/10000\n",
      "passing rate = 3/10000\n",
      "passing rate = 4/10000\n",
      "passing rate = 5/10000\n",
      "passing rate = 6/10000\n",
      "passing rate = 7/10000\n",
      "passing rate = 8/10000\n",
      "passing rate = 9/10000\n",
      "passing rate = 10/10000\n",
      "passing rate = 11/10000\n",
      "passing rate = 12/10000\n",
      "passing rate = 13/10000\n",
      "passing rate = 14/10000\n",
      "passing rate = 15/10000\n",
      "passing rate = 16/10000\n",
      "passing rate = 17/10000\n",
      "passing rate = 18/10000\n",
      "passing rate = 19/10000\n",
      "passing rate = 20/10000\n",
      "passing rate = 21/10000\n",
      "passing rate = 22/10000\n",
      "passing rate = 23/10000\n",
      "passing rate = 24/10000\n",
      "passing rate = 25/10000\n",
      "passing rate = 26/10000\n",
      "passing rate = 27/10000\n",
      "passing rate = 28/10000\n",
      "passing rate = 29/10000\n",
      "passing rate = 30/10000\n",
      "passing rate = 31/10000\n",
      "passing rate = 32/10000\n",
      "passing rate = 33/10000\n",
      "passing rate = 34/10000\n",
      "passing rate = 35/10000\n",
      "passing rate = 36/10000\n",
      "passing rate = 37/10000\n",
      "passing rate = 38/10000\n",
      "passing rate = 39/10000\n",
      "passing rate = 40/10000\n",
      "passing rate = 41/10000\n",
      "passing rate = 42/10000\n",
      "passing rate = 43/10000\n",
      "passing rate = 44/10000\n",
      "passing rate = 45/10000\n",
      "passing rate = 46/10000\n",
      "passing rate = 47/10000\n",
      "passing rate = 48/10000\n",
      "passing rate = 49/10000\n",
      "passing rate = 50/10000\n",
      "passing rate = 51/10000\n",
      "passing rate = 52/10000\n",
      "passing rate = 53/10000\n",
      "passing rate = 54/10000\n",
      "passing rate = 55/10000\n",
      "passing rate = 56/10000\n",
      "passing rate = 57/10000\n",
      "passing rate = 58/10000\n",
      "passing rate = 59/10000\n",
      "passing rate = 60/10000\n",
      "passing rate = 61/10000\n",
      "passing rate = 62/10000\n",
      "passing rate = 63/10000\n",
      "passing rate = 64/10000\n",
      "passing rate = 65/10000\n",
      "passing rate = 66/10000\n",
      "passing rate = 67/10000\n",
      "passing rate = 68/10000\n",
      "passing rate = 69/10000\n",
      "passing rate = 70/10000\n",
      "passing rate = 71/10000\n",
      "passing rate = 72/10000\n",
      "passing rate = 73/10000\n",
      "passing rate = 74/10000\n",
      "passing rate = 75/10000\n",
      "passing rate = 76/10000\n",
      "passing rate = 77/10000\n",
      "passing rate = 78/10000\n",
      "passing rate = 79/10000\n",
      "passing rate = 80/10000\n",
      "passing rate = 81/10000\n",
      "passing rate = 82/10000\n",
      "passing rate = 83/10000\n",
      "passing rate = 84/10000\n",
      "passing rate = 85/10000\n",
      "passing rate = 86/10000\n",
      "passing rate = 87/10000\n",
      "passing rate = 88/10000\n",
      "passing rate = 89/10000\n",
      "passing rate = 90/10000\n",
      "passing rate = 91/10000\n",
      "passing rate = 92/10000\n",
      "passing rate = 93/10000\n",
      "passing rate = 94/10000\n",
      "passing rate = 95/10000\n",
      "passing rate = 96/10000\n",
      "passing rate = 97/10000\n",
      "passing rate = 98/10000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-f4611344350b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0minclude_random_distractor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mfull_relation_probability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# 0.5 seems to work as well!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         )\n\u001b[1;32m     35\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_world\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'obj_map'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_world\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_current_situation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_representation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"placed_objects\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-aff7e6a5335c>\u001b[0m in \u001b[0;36msample_situations_from_grounded_grammer\u001b[0;34m(self, grammer_pattern, obj_pattern_map, rel_map, obj_map, root, is_plot, include_random_distractor, include_relation_distractor, include_attribute_distractor, include_isomorphism_distractor, full_relation_probability, debug)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mspecial_shape_size_bound\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspecial_shape_size_bound\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m                     \u001b[0mmentioned_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmentioned_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m                     \u001b[0;31m# This is needed as maybe distractors also\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                     \u001b[0;31m# need to be bounded by global constraints.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-aff7e6a5335c>\u001b[0m in \u001b[0;36mplace_distractor_from_dict\u001b[0;34m(self, distractors_dict, obj_placed_map, obj_position_map, debug, special_shape_size_bound, mentioned_shapes)\u001b[0m\n\u001b[1;32m    281\u001b[0m             return_code = self._world.place_object(\n\u001b[1;32m    282\u001b[0m                 \u001b[0msampled_dis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m                 \u001b[0mposition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampled_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;31m# Distractor is never the target!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m             )\n\u001b[1;32m    285\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreturn_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/Reason-SCAN/code/dataset/world.py\u001b[0m in \u001b[0;36mplace_object\u001b[0;34m(self, object_spec, position, target)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         object_vector = self._object_vocabulary.get_object_vector(shape=object_spec.shape, color=object_spec.color,\n\u001b[0;32m--> 483\u001b[0;31m                                                                   size=object_spec.size)\n\u001b[0m\u001b[1;32m    484\u001b[0m         \u001b[0mpositioned_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPositionedObject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         self.place_obj(self.create_object(object_spec, object_vector, target=target),\n",
      "\u001b[0;32m~/Dropbox/Reason-SCAN/code/dataset/object_vocabulary.py\u001b[0m in \u001b[0;36mget_object_vector\u001b[0;34m(self, shape, color, size)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mget_object_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Trying to get an unavailable object vector from the vocabulary/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object_vectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Simulator robustness tests.\n",
    "random.shuffle(command_structs)\n",
    "simulator = Simulator(\n",
    "    object_vocabulary, vocabulary, \n",
    "    grid_size=6, \n",
    "    n_object_max=10,\n",
    ")\n",
    "count = 0\n",
    "for test_struct in command_structs[:10000]:\n",
    "    count += 1\n",
    "    if count%1==0:\n",
    "        print(f\"passing rate = {count}/{10000}\")\n",
    "    obj_pattern_map = test_struct[\"obj_pattern_map\"]\n",
    "    rel_map = test_struct[\"rel_map\"]\n",
    "    obj_map = test_struct[\"obj_map\"]\n",
    "    grammer_pattern = test_struct[\"grammer_pattern\"]\n",
    "    verb = test_struct[\"verb\"]\n",
    "    adverb = test_struct[\"adverb\"]\n",
    "\n",
    "    test_unique_find = 0\n",
    "    for i in range(200):\n",
    "        sampled_world = simulator.sample_situations_from_grounded_grammer(\n",
    "            copy.deepcopy(grammer_pattern), \n",
    "            copy.deepcopy(obj_pattern_map), \n",
    "            copy.deepcopy(rel_map), \n",
    "            copy.deepcopy(obj_map),\n",
    "            is_plot=False,\n",
    "            include_relation_distractor=True, \n",
    "            include_attribute_distractor=True, \n",
    "            include_isomorphism_distractor=True, \n",
    "            include_random_distractor=True,\n",
    "            full_relation_probability=0.5, # 0.5 seems to work as well!\n",
    "            debug=False\n",
    "        )\n",
    "        assert len(sampled_world['obj_map']) == len(simulator._world.get_current_situation().to_representation()[\"placed_objects\"])\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'obj_pattern_map': {'$OBJ_0': '$SHAPE',\n",
       "  '$OBJ_1': '$SHAPE',\n",
       "  '$OBJ_2': '$COLOR $SHAPE'},\n",
       " 'rel_map': OrderedDict([(('$OBJ_0', '$OBJ_1'), '$SAME_ROW'),\n",
       "              (('$OBJ_0', '$OBJ_2'), '$SAME_COLOR')]),\n",
       " 'obj_map': {'$OBJ_0': 'cylinder',\n",
       "  '$OBJ_1': 'square',\n",
       "  '$OBJ_2': 'green cylinder'},\n",
       " 'grammer_pattern': '$OBJ_0 ^ $OBJ_1 & $OBJ_2',\n",
       " 'adverb': 'while zigzagging',\n",
       " 'verb': 'push'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passing rate = 0/200000\n",
      "passing rate = 10000/200000\n",
      "passing rate = 20000/200000\n",
      "passing rate = 30000/200000\n",
      "passing rate = 40000/200000\n",
      "passing rate = 50000/200000\n",
      "passing rate = 60000/200000\n",
      "passing rate = 70000/200000\n",
      "passing rate = 80000/200000\n",
      "passing rate = 90000/200000\n",
      "passing rate = 100000/200000\n",
      "passing rate = 110000/200000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-53446f3cd392>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0minclude_random_distractor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mfull_relation_probability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# 0.5 seems to work as well!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         )\n\u001b[1;32m     43\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_world\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'obj_map'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_world\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_current_situation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_representation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"placed_objects\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-aff7e6a5335c>\u001b[0m in \u001b[0;36msample_situations_from_grounded_grammer\u001b[0;34m(self, grammer_pattern, obj_pattern_map, rel_map, obj_map, root, is_plot, include_random_distractor, include_relation_distractor, include_attribute_distractor, include_isomorphism_distractor, full_relation_probability, debug)\u001b[0m\n\u001b[1;32m    820\u001b[0m             \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_world\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m         \u001b[0msituation_snapshot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_world\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_current_situation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m         return {\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0mdeep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemo\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_struct = {'obj_pattern_map': {'$OBJ_0': '$SHAPE',\n",
    "  '$OBJ_1': '$SHAPE',\n",
    "  '$OBJ_2': '$COLOR $SHAPE'},\n",
    " 'rel_map': OrderedDict([(('$OBJ_0', '$OBJ_1'), '$SAME_ROW'),\n",
    "              (('$OBJ_0', '$OBJ_2'), '$SAME_COLOR')]),\n",
    " 'obj_map': {'$OBJ_0': 'cylinder',\n",
    "  '$OBJ_1': 'square',\n",
    "  '$OBJ_2': 'green cylinder'},\n",
    " 'grammer_pattern': '$OBJ_0 ^ $OBJ_1 & $OBJ_2',\n",
    " 'adverb': 'while zigzagging',\n",
    " 'verb': 'push'}\n",
    "\n",
    "simulator = Simulator(\n",
    "    object_vocabulary, vocabulary, \n",
    "    grid_size=6, \n",
    "    n_object_max=10,\n",
    ")\n",
    "\n",
    "obj_pattern_map = test_struct[\"obj_pattern_map\"]\n",
    "rel_map = test_struct[\"rel_map\"]\n",
    "obj_map = test_struct[\"obj_map\"]\n",
    "grammer_pattern = test_struct[\"grammer_pattern\"]\n",
    "verb = test_struct[\"verb\"]\n",
    "adverb = test_struct[\"adverb\"]\n",
    "\n",
    "test_unique_find = 0\n",
    "for i in range(200000):\n",
    "    if i%10000==0:\n",
    "        print(f\"passing rate = {i}/{200000}\")\n",
    "    sampled_world = simulator.sample_situations_from_grounded_grammer(\n",
    "            copy.deepcopy(grammer_pattern), \n",
    "            copy.deepcopy(obj_pattern_map), \n",
    "            copy.deepcopy(rel_map), \n",
    "            copy.deepcopy(obj_map),\n",
    "            is_plot=False,\n",
    "            include_relation_distractor=True, \n",
    "            include_attribute_distractor=True, \n",
    "            include_isomorphism_distractor=True, \n",
    "            include_random_distractor=True,\n",
    "            full_relation_probability=0.5, # 0.5 seems to work as well!\n",
    "            debug=False\n",
    "        )\n",
    "    assert len(sampled_world['obj_map']) == len(simulator._world.get_current_situation().to_representation()[\"placed_objects\"])\n",
    "    continue\n",
    "    \n",
    "    graph = ReaSCANGraph(\n",
    "        objects=sampled_world[\"obj_map\"], \n",
    "        object_patterns=sampled_world[\"obj_pattern_map\"], \n",
    "        vocabulary=vocabulary,\n",
    "        positions=sampled_world[\"pos_map\"], \n",
    "        referred_object=sampled_world[\"referred_obj\"],\n",
    "        debug=False\n",
    "    )\n",
    "\n",
    "    pattern_graph = ReaSCANGraph(\n",
    "        objects=obj_map, \n",
    "        object_patterns=None,\n",
    "        vocabulary=vocabulary,\n",
    "        relations=rel_map, \n",
    "        referred_object='$OBJ_0', \n",
    "        debug=False\n",
    "    )\n",
    "\n",
    "    potential_referent_target = graph.find_referred_object(\n",
    "        pattern_graph, referred_object='$OBJ_0', \n",
    "        debug=False\n",
    "    )\n",
    "\n",
    "    if len(potential_referent_target) == 1:\n",
    "        print(f\"{test_unique_find+1} / {i+1} unique solution find!\")\n",
    "        test_unique_find += 1\n",
    "        \n",
    "        simulator._world.render_simple()\n",
    "        \n",
    "        obj_determiner_map = graph.find_determiners(\n",
    "            pattern_graph, \n",
    "            referred_object='$OBJ_0', \n",
    "            debug=False,\n",
    "        )\n",
    "        \n",
    "        command_str = grammer.repre_str_command(\n",
    "            grammer_pattern, rel_map, obj_map, \n",
    "            obj_determiner_map, \n",
    "            verb,\n",
    "            adverb,\n",
    "        )\n",
    "        \n",
    "        # Get the target command\n",
    "        is_transitive = False\n",
    "        if verb in simulator.vocabulary.get_transitive_verbs():\n",
    "            is_transitive = True\n",
    "        \n",
    "        # Direct walk.\n",
    "        action = \"walk\" # this is definit!\n",
    "        primitive_command = simulator.vocabulary.translate_word(action)\n",
    "        target_position = sampled_world[\"situation\"].target_object.position\n",
    "\n",
    "        simulator._world.go_to_position(\n",
    "            position=target_position, manner=adverb, \n",
    "            primitive_command=primitive_command\n",
    "        )\n",
    "\n",
    "        # Object actions.\n",
    "        if is_transitive:\n",
    "            semantic_action = simulator.vocabulary.translate_word(verb)\n",
    "            simulator._world.move_object_to_wall(action=semantic_action, manner=adverb)\n",
    "        target_commands, _ = simulator._world.get_current_observations()\n",
    "        \n",
    "        task_struct = OrderedDict({\n",
    "            \"command\": \",\".join(command_str.split(\" \")),\n",
    "            \"meaning\": \",\".join(command_str.split(\" \")),\n",
    "            \"derivation\": grammer_pattern,\n",
    "            \"situation\": sampled_world[\"situation\"].to_representation(),\n",
    "            \"target_commands\": \",\".join(target_commands),\n",
    "            \"verb_in_command\": verb,\n",
    "            \"adverb_in_command\": adverb,\n",
    "            \"referred_target\": obj_map[\"$OBJ_0\"],\n",
    "            \"object_pattern_map\": obj_pattern_map,\n",
    "            \"relation_map\": rel_map,\n",
    "            \"object_expression\": obj_map,\n",
    "            \"n_object\": len(sampled_world[\"obj_map\"]),\n",
    "            \"n_distractor\": len(sampled_world[\"obj_map\"])-len(obj_map),\n",
    "            \"full_relation_distractor\": True if len(sampled_world[\"distractor_switch_map\"][\"relation\"]) == len(rel_map) else False,\n",
    "            \"has_relation_distractor\": True if len(sampled_world[\"distractor_switch_map\"][\"relation\"]) > 0 else False,\n",
    "            \"has_attribute_distractor\": sampled_world[\"distractor_switch_map\"][\"attribute\"],\n",
    "            \"has_isomorphism_distractor\": sampled_world[\"distractor_switch_map\"][\"isomorphism\"],\n",
    "            \"has_random_distractor\": True if sampled_world[\"n_random_distractor\"] != -1 else False,\n",
    "            \"n_random_distractor\": sampled_world[\"n_random_distractor\"] if sampled_world[\"n_random_distractor\"] != -1 else 0,\n",
    "            \"relation_distractor_metadata\": sampled_world[\"relation_distractor_metadata\"],\n",
    "            \"attribute_distractor_metadata\": sampled_world[\"attribute_distractor_metadata\"],\n",
    "            \"isomorphism_distractor_metadata\": sampled_world[\"isomorphism_distractor_metadata\"],\n",
    "            \"random_distractor_metadata\": sampled_world[\"random_distractor_metadata\"],\n",
    "        })\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'obj_map': OrderedDict([('$OBJ_0',\n",
       "               Object(size=4, color='green', shape='cylinder')),\n",
       "              ('$OBJ_1', Object(size=4, color='yellow', shape='square')),\n",
       "              ('$OBJ_2', Object(size=3, color='green', shape='cylinder')),\n",
       "              ('$OBJ_3', Object(size=1, color='green', shape='cylinder')),\n",
       "              ('$OBJ_4', Object(size=4, color='green', shape='square')),\n",
       "              ('$OBJ_5', Object(size=4, color='green', shape='cylinder')),\n",
       "              ('$OBJ_8', Object(size=3, color='yellow', shape='cylinder')),\n",
       "              ('$OBJ_9', Object(size=4, color='yellow', shape='circle')),\n",
       "              ('$OBJ_10', Object(size=2, color='yellow', shape='cylinder'))]),\n",
       " 'pos_map': OrderedDict([('$OBJ_0', Position(column=5, row=1)),\n",
       "              ('$OBJ_1', Position(column=0, row=1)),\n",
       "              ('$OBJ_2', Position(column=3, row=1)),\n",
       "              ('$OBJ_3', Position(column=4, row=1)),\n",
       "              ('$OBJ_4', Position(column=1, row=1)),\n",
       "              ('$OBJ_5', Position(column=2, row=1)),\n",
       "              ('$OBJ_8', Position(column=3, row=0)),\n",
       "              ('$OBJ_9', Position(column=2, row=3)),\n",
       "              ('$OBJ_10', Position(column=0, row=4))]),\n",
       " 'obj_pattern_map': {'$OBJ_0': '$SHAPE',\n",
       "  '$OBJ_1': '$SHAPE',\n",
       "  '$OBJ_2': '$COLOR $SHAPE'},\n",
       " 'referred_obj': '$OBJ_0',\n",
       " 'situation': <world.Situation at 0x7faefb0ebd68>,\n",
       " 'distractor_switch_map': OrderedDict([('relation', [True]),\n",
       "              ('attribute', False),\n",
       "              ('isomorphism', True),\n",
       "              ('random', True)]),\n",
       " 'relation_distractor_metadata': [{'distractor_metadata': {'edge': ('$OBJ_0',\n",
       "     '$OBJ_1'),\n",
       "    'relation_old_type': '$SAME_ROW',\n",
       "    'full_set': False},\n",
       "   'obj_map': OrderedDict([('$OBJ_3', 'cylinder'), ('$OBJ_4', 'square')]),\n",
       "   'rel_map': OrderedDict([(('$OBJ_3', '$OBJ_4'), '$SAME_ROW')])}],\n",
       " 'attribute_distractor_metadata': [{'distractor_metadata': [{'modified_obj': '$OBJ_1',\n",
       "     'modified_attribute': '$SHAPE'}],\n",
       "   'obj_map': OrderedDict([('$OBJ_5', 'cylinder'),\n",
       "                ('$OBJ_6', 'yellow circle'),\n",
       "                ('$OBJ_7', 'green cylinder')]),\n",
       "   'rel_map': OrderedDict([(('$OBJ_5', '$OBJ_6'), '$SAME_ROW'),\n",
       "                (('$OBJ_5', '$OBJ_7'), '$SAME_COLOR')])}],\n",
       " 'isomorphism_distractor_metadata': [{'distractor_metadata': [{'swapped_pair': ('$OBJ_1',\n",
       "      '$OBJ_2'),\n",
       "     'before_pair_obj_str': ('square', 'green cylinder'),\n",
       "     'after_pair_obj_str': ('green square', 'cylinder'),\n",
       "     'size_shuffled': False,\n",
       "     'color_shuffled': True,\n",
       "     'shape_shuffled': False}],\n",
       "   'obj_map': OrderedDict([('$OBJ_8', 'cylinder'),\n",
       "                ('$OBJ_9', 'green square'),\n",
       "                ('$OBJ_10', 'cylinder')]),\n",
       "   'rel_map': OrderedDict([(('$OBJ_8', '$OBJ_9'), '$SAME_ROW'),\n",
       "                (('$OBJ_8', '$OBJ_10'), '$SAME_COLOR')])}],\n",
       " 'random_distractor_metadata': [{'$OBJ_9': ' yellow circle'}],\n",
       " 'n_random_distractor': 1}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('$OBJ_0', Object(size=3, color='blue', shape='square')),\n",
       "             ('$OBJ_1', Object(size=3, color='yellow', shape='circle')),\n",
       "             ('$OBJ_2', Object(size=3, color='green', shape='box')),\n",
       "             ('$OBJ_3', Object(size=3, color='green', shape='square')),\n",
       "             ('$OBJ_4', Object(size=3, color='yellow', shape='circle')),\n",
       "             ('$OBJ_6', Object(size=2, color='red', shape='square')),\n",
       "             ('$OBJ_7', Object(size=2, color='green', shape='circle')),\n",
       "             ('$OBJ_8', Object(size=1, color='green', shape='box'))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_world['obj_map']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'vector': '001000100100',\n",
       "  'position': {'row': '2', 'column': '4'},\n",
       "  'object': {'shape': 'square', 'color': 'blue', 'size': '3'}},\n",
       " '1': {'vector': '001010000001',\n",
       "  'position': {'row': '0', 'column': '1'},\n",
       "  'object': {'shape': 'circle', 'color': 'yellow', 'size': '3'}},\n",
       " '2': {'vector': '001000010010',\n",
       "  'position': {'row': '0', 'column': '3'},\n",
       "  'object': {'shape': 'box', 'color': 'green', 'size': '3'}},\n",
       " '3': {'vector': '001000100010',\n",
       "  'position': {'row': '0', 'column': '5'},\n",
       "  'object': {'shape': 'square', 'color': 'green', 'size': '3'}},\n",
       " '4': {'vector': '001010000001',\n",
       "  'position': {'row': '0', 'column': '0'},\n",
       "  'object': {'shape': 'circle', 'color': 'yellow', 'size': '3'}},\n",
       " '5': {'vector': '010000101000',\n",
       "  'position': {'row': '3', 'column': '5'},\n",
       "  'object': {'shape': 'square', 'color': 'red', 'size': '2'}},\n",
       " '6': {'vector': '010010000010',\n",
       "  'position': {'row': '2', 'column': '1'},\n",
       "  'object': {'shape': 'circle', 'color': 'green', 'size': '2'}},\n",
       " '7': {'vector': '001001000010',\n",
       "  'position': {'row': '3', 'column': '2'},\n",
       "  'object': {'shape': 'cylinder', 'color': 'green', 'size': '3'}},\n",
       " '8': {'vector': '100000010010',\n",
       "  'position': {'row': '5', 'column': '3'},\n",
       "  'object': {'shape': 'box', 'color': 'green', 'size': '1'}}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulator._world.get_current_situation().to_representation()[\"placed_objects\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {1:2, 3:4, 5:6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrips for generating splits\n",
    "This script assums you have the main ReaSCAN generated by the generate_ReaSCAN.py script. After that, you can use this file to generate/extrapolate different splits. In the future, we may consolidate two files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple, OrderedDict\n",
    "import os\n",
    "from typing import List\n",
    "from typing import Tuple\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def isnotebook():\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return True   # Jupyter notebook or qtconsole\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            return False  # Terminal running IPython\n",
    "        else:\n",
    "            return False  # Other type (?)\n",
    "    except NameError:\n",
    "        return False      # Probably standard Python interpreter\n",
    "if isnotebook():\n",
    "    device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "FORMAT = \"%(asctime)-15s %(message)s\"\n",
    "logging.basicConfig(format=FORMAT, level=logging.INFO,\n",
    "                    datefmt=\"%Y-%m-%d %H:%M\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from world import *\n",
    "from vocabulary import Vocabulary as ReaSCANVocabulary\n",
    "from object_vocabulary import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"../../data-files/ReaSCAN-compositional/data-train.txt\"\n",
    "logger.info(f\"Reading dataset from file: {path_to_data}...\")\n",
    "data_json = json.load(open(path_to_data, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544579"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_fake_train = data_json[\"examples\"][\"train\"]\n",
    "# for dev and test, it is simple, let us just shuffle, and random select.\n",
    "len(all_fake_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For generating the splits, we actually have to go through compositional splits first\n",
    "# and then consider random splits like dev and test. Because, we don't want things mixed up\n",
    "# in the dev and test. Dev and test should only contain commands that appear in the train,\n",
    "# so a total random partition at the end should work.\n",
    "\n",
    "# We do the splits step-by-step!\n",
    "id_example_map = OrderedDict({})\n",
    "id_splits_map = OrderedDict({})\n",
    "index = 0\n",
    "for example in data_json[\"examples\"][\"train\"]:\n",
    "    id_example_map[index] = example\n",
    "    id_splits_map[index] = set([]) # set of splits that this example belongs to.\n",
    "    \n",
    "    # gscan_yellow_square_command_target_only\n",
    "    if \"yellow,square\" in example['command'].split(\"that\")[0]:\n",
    "        id_splits_map[index].add(\"gscan_yellow_square_command_target_only\")\n",
    "\n",
    "    # gscan_yellow_square_command\n",
    "    if \"yellow,square\" in example['command']:\n",
    "        id_splits_map[index].add(\"gscan_yellow_square_command\")\n",
    "    \n",
    "    # gscan_red_box_visual\n",
    "    if \"red,box\" in example['command'] or \\\n",
    "        ((example['situation']['placed_objects']['1']['object']['shape'] == \"box\" and \\\n",
    "        example['situation']['placed_objects']['1']['object']['color'] == \"red\") or \\\n",
    "        (example['situation']['placed_objects']['2']['object']['shape'] == \"box\" and \\\n",
    "        example['situation']['placed_objects']['2']['object']['color'] == \"red\")):\n",
    "        id_splits_map[index].add(\"gscan_red_box_visual\")\n",
    "    \n",
    "    # gscan_small_cylinder_command_target_only\n",
    "    if \"small,cylinder\" in example['command'].split(\"that\")[0] or \\\n",
    "        \"small,red,cylinder\" in example['command'].split(\"that\")[0] or \\\n",
    "        \"small,blue,cylinder\" in example['command'].split(\"that\")[0] or \\\n",
    "        \"small,yellow,cylinder\" in example['command'].split(\"that\")[0] or \\\n",
    "        \"small,green,cylinder\" in example['command'].split(\"that\")[0]:\n",
    "        id_splits_map[index].add(\"gscan_small_cylinder_command_target_only\")\n",
    "    \n",
    "    # novel_yellow_square_blue_circle_coexist_shape\n",
    "    if \"yellow,square\" in example['command'] and \"blue,circle\" in example['command']:\n",
    "        id_splits_map[index].add(\"novel_yellow_square_blue_circle_coexist_shape\")\n",
    "    \n",
    "    # novel_green_circle_box_coexist (must be down side objects)\n",
    "    if \"green,circle\" not in example['command'].split(\"that\")[0] and \\\n",
    "        \"green,circle\" in example['command'] and \"box\" in example['command']:\n",
    "        id_splits_map[index].add(\"novel_green_circle_box_coexist_box_shape\")\n",
    "\n",
    "    # novel_same_shape_is_inside_coexist_relation\n",
    "    if \"same,shape\" in example['command'] and \"is,inside\" in example['command']:\n",
    "        id_splits_map[index].add(\"novel_same_shape_is_inside_coexist_relation\")\n",
    "        \n",
    "    # novel_inside_of_as_yellow_box\n",
    "    if \"is,inside,of,a,yellow,box\" in example['command'] or \\\n",
    "        \"is,inside,of,the,yellow,box\" in example['command'] or \\\n",
    "        \"is,inside,of,a,small,yellow,box\" in example['command'] or \\\n",
    "        \"is,inside,of,the,small,yellow,box\" in example['command']:\n",
    "        id_splits_map[index].add(\"novel_inside_of_as_yellow_box\")\n",
    "    \n",
    "    # few_shot_single_clause_logic\n",
    "    if example['grammer_pattern'] == \"$OBJ_0 ^ $OBJ_1\":\n",
    "        id_splits_map[index].add(\"few_shot_single_clause_logic\")\n",
    "        \n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_distribution = OrderedDict({})\n",
    "splits_assignment = OrderedDict({})\n",
    "for index, splits in id_splits_map.items():\n",
    "    if len(splits) == 0:\n",
    "        split = \"train\" # let us split this up later!\n",
    "        if split in splits_distribution.keys():\n",
    "            splits_distribution[split] += 1\n",
    "        else:\n",
    "            splits_distribution[split] = 1\n",
    "        \n",
    "        if split in splits_assignment:\n",
    "            splits_assignment[split].append(index)\n",
    "        else:\n",
    "            splits_assignment[split] = [index]\n",
    "    else:   \n",
    "        for split in splits:\n",
    "            if split in splits_distribution.keys():\n",
    "                splits_distribution[split] += 1\n",
    "            else:\n",
    "                splits_distribution[split] = 1\n",
    "                \n",
    "            if split in splits_assignment:\n",
    "                splits_assignment[split].append(index)\n",
    "            else:\n",
    "                splits_assignment[split] = [index]\n",
    "\n",
    "# Let us further segment train into dev and test!\n",
    "gscan_dev_size = 3716\n",
    "gscan_test_size = 19282\n",
    "all_example_id = splits_assignment[\"train\"]\n",
    "random.shuffle(all_example_id)\n",
    "train_example_id = all_example_id[:(-3716-19282)]\n",
    "dev_example_id = all_example_id[(-3716-19282):-3716]\n",
    "test_example_id = all_example_id[-3716:]\n",
    "splits_assignment[\"train\"] = train_example_id\n",
    "splits_assignment[\"dev\"] = dev_example_id\n",
    "splits_assignment[\"test\"] = test_example_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for train split, we have 315421 examples.\n",
      "for novel_inside_of_as_yellow_box split, we have 15950 examples.\n",
      "for gscan_yellow_square_command_target_only split, we have 21801 examples.\n",
      "for gscan_yellow_square_command split, we have 76979 examples.\n",
      "for gscan_red_box_visual split, we have 52433 examples.\n",
      "for novel_green_circle_box_coexist_box_shape split, we have 13700 examples.\n",
      "for gscan_small_cylinder_command_target_only split, we have 31867 examples.\n",
      "for novel_yellow_square_blue_circle_coexist_shape split, we have 8450 examples.\n",
      "for novel_same_shape_is_inside_coexist_relation split, we have 4698 examples.\n",
      "for few_shot_single_clause_logic split, we have 49511 examples.\n",
      "for dev split, we have 19282 examples.\n",
      "for test split, we have 3716 examples.\n"
     ]
    }
   ],
   "source": [
    "for split, all_ids in splits_assignment.items():\n",
    "    print(f\"for {split} split, we have {len(all_ids)} examples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remake our data file accordingly.\n",
    "updated_examples = OrderedDict({})\n",
    "for split, all_ids in splits_assignment.items():\n",
    "    updated_examples[split] = []\n",
    "    for _id in all_ids:\n",
    "        updated_examples[split].append(id_example_map[_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it to the disk\n",
    "data_json[\"examples\"] = updated_examples\n",
    "with open(\"../../data-files/ReaSCAN-compositional/data-compositional-splits.txt\", \"w\") as fd:\n",
    "    json.dump(data_json, fd, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
